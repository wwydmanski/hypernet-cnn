{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfde2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1005bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db453527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/hypernet\n"
     ]
    }
   ],
   "source": [
    "%cd hypernet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ef57058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3439415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment, Optimizer\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f81b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "411db77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabular_hypernet as hp\n",
    "from tabular_hypernet.mask_design import feature_variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbc97da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35fd81c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UXrV5UxyhTK3cyQNG6BDuc4bE'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['COMET_KEY'] = 'UXrV5UxyhTK3cyQNG6BDuc4bE'\n",
    "os.environ.get(\"COMET_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884b2bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9fd4cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# TabSSLCrossEntropyLoss if confidence is high for both masks, add selfsl loss\n",
    "\n",
    "# Verify if masks always divided into pairs the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc4dc449",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSLCELossWithThreshold(torch.nn.Module):\n",
    "    def __init__(self, beta=0.1, unsup_target_wrapper=torch.nn.functional.softmax, threshold=None):\n",
    "        super(SSLCELossWithThreshold, self).__init__()\n",
    "        \n",
    "        self.y_f1 = torch.nn.CrossEntropyLoss()\n",
    "        self.y_f2 = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.f1_f2 = torch.nn.CrossEntropyLoss()\n",
    "        self.f2_f1 = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.beta = beta\n",
    "        self.unsup_target_wrapper = unsup_target_wrapper\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def is_observ_above_threshold(self, data):\n",
    "        mask = torch.any(data >= self.threshold, dim=1)\n",
    "        \n",
    "        return mask\n",
    "        \n",
    "    \n",
    "    def forward(self, sup_input, unsup_input):\n",
    "        sup_outputs1, sup_outputs2, sup_labels = sup_input\n",
    "        unsup_outputs1, unsup_outputs2 = unsup_input\n",
    "        \n",
    "        self.supervised_loss = self.y_f1(sup_outputs1, sup_labels) + self.y_f2(sup_outputs2, sup_labels)\n",
    "        \n",
    "        self.self_supervised_loss = 0\n",
    "        if self.beta:\n",
    "\n",
    "            if self.threshold:\n",
    "                unsup_outputs1_target = torch.nn.functional.softmax(unsup_outputs1, dim=1)\n",
    "                mask1 = self.is_observ_above_threshold(unsup_outputs1_target)\n",
    "\n",
    "                if len(unsup_outputs1_target[mask1]):\n",
    "                    unsup_outputs1_target = torch.argmax(unsup_outputs1_target[mask1], dim=1)\n",
    "                    self.self_supervised_loss += self.f2_f1(unsup_outputs2[mask1], unsup_outputs1_target)\n",
    "\n",
    "                unsup_outputs2_target = torch.nn.functional.softmax(unsup_outputs2, dim=1)\n",
    "                mask2 = self.is_observ_above_threshold(unsup_outputs2_target)\n",
    "\n",
    "                if len(unsup_outputs2_target[mask2]):\n",
    "                    unsup_outputs2_target = torch.argmax(unsup_outputs2_target[mask2], dim=1)\n",
    "                    self.self_supervised_loss += self.f1_f2(unsup_outputs1[mask2], unsup_outputs2_target)\n",
    "\n",
    "            else:\n",
    "                self.self_supervised_loss = self.f1_f2(unsup_outputs1, self.unsup_target_wrapper(unsup_outputs2, dim=1)) \\\n",
    "                                    + self.f2_f1(unsup_outputs2, self.unsup_target_wrapper(unsup_outputs1, dim=1))      \n",
    "        \n",
    "        return self.supervised_loss + self.beta * self.self_supervised_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6c13ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "688384bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950554cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1573678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ee48bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96856f28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0616625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71897e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8d68a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237406b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "816d6a48",
   "metadata": {},
   "source": [
    "### Exploration of dataset variances over features and analisys of best temp schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6065cae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fv = feature_variances(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69cdca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bb5571",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_scheduler = IncByOneTempScheduler(1, n=mask_size, max_temp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186f3c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_scheduler.available_temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e02052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ad2564",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(mask_size):\n",
    "\n",
    "    temp = temp_scheduler.update_temp(i)\n",
    "    \n",
    "    probs = torch.nn.functional.softmax(fv / temp, dtype=torch.float32, dim=0).numpy()\n",
    "\n",
    "    print('temp', temp)\n",
    "    print('max', np.max(probs))\n",
    "    print('min', np.min(probs))\n",
    "    print('abs delta', np.max(probs) - np.min(probs))\n",
    "    print('max bigger than min', np.max(probs) / np.min(probs), 'times')\n",
    "    plt.clf()\n",
    "    plt.plot(probs)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823cc754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec000d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ee5e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e2b355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8c2df55",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd37710",
   "metadata": {},
   "source": [
    "# Setup for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afbc4d3",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59940b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fa50ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77a2b909",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5162270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = hp.semisl.get_train_test_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf1f46a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ce322f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "masks_no = 100\n",
    "\n",
    "\n",
    "results = defaultdict(list)\n",
    "size = (100, 59900)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68697821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "748e0f11",
   "metadata": {},
   "source": [
    "### New mask selector: Variance with temp scheduler "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07edaab7",
   "metadata": {},
   "source": [
    "### Temp scheduler 1..20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d8ebebf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lr \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3e-5\u001b[39m]:\n\u001b[1;32m      4\u001b[0m     temp_scheduler \u001b[38;5;241m=\u001b[39m IncByOneTempScheduler(\u001b[38;5;241m1\u001b[39m, n\u001b[38;5;241m=\u001b[39mmask_size, max_temp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     mask_selector \u001b[38;5;241m=\u001b[39m VarianceWithSoftmaxMasksSelector(\u001b[43mfeature_variances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m, mask_size, temp_scheduler)\n\u001b[1;32m      7\u001b[0m     criterion \u001b[38;5;241m=\u001b[39m SSLCELossWithThreshold(beta\u001b[38;5;241m=\u001b[39mbeta, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n",
      "File \u001b[0;32m~/hypernet-cnn/hypernet/tabular_hypernet/mask_design.py:5\u001b[0m, in \u001b[0;36mfeature_variances\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeature_variances\u001b[39m(data):\n\u001b[1;32m      4\u001b[0m     trainset, _ \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m----> 5\u001b[0m     stacked_set \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([x \u001b[38;5;28;01mfor\u001b[39;00m x, _ \u001b[38;5;129;01min\u001b[39;00m trainset])\n\u001b[1;32m      7\u001b[0m     feature_variances \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mvar(stacked_set, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m feature_variances\n",
      "File \u001b[0;32m~/hypernet-cnn/hypernet/tabular_hypernet/mask_design.py:5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeature_variances\u001b[39m(data):\n\u001b[1;32m      4\u001b[0m     trainset, _ \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m----> 5\u001b[0m     stacked_set \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([x \u001b[38;5;28;01mfor\u001b[39;00m x, _ \u001b[38;5;129;01min\u001b[39;00m trainset])\n\u001b[1;32m      7\u001b[0m     feature_variances \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mvar(stacked_set, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m feature_variances\n",
      "File \u001b[0;32m~/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/torchvision/transforms/transforms.py:135\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/torchvision/transforms/functional.py:151\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    150\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n\u001b[0;32m--> 151\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetbands\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[1;32m    153\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for beta in [0.]:\n",
    "    for lr in [3e-5]:\n",
    "        \n",
    "        temp_scheduler = IncByOneTempScheduler(1, n=mask_size, max_temp=20)\n",
    "        mask_selector = VarianceWithSoftmaxMasksSelector(feature_variances(dataset), mask_size, temp_scheduler)\n",
    "\n",
    "        criterion = SSLCELossWithThreshold(beta=beta, threshold=None)\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        # dataset\n",
    "\n",
    "\n",
    "        hypernet = hp.Hypernetwork(\n",
    "            architecture=torch.nn.Sequential(\n",
    "                torch.nn.Linear(784, 64), \n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(64, 256),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(256, 128),\n",
    "            ),\n",
    "            target_architecture=[(mask_size, 20), (20, 10)],\n",
    "            test_nodes=masks_no,\n",
    "        ).cuda()\n",
    "        \n",
    "        hypernet._create_mask = None\n",
    "        hypernet.test_mask = mask_selector(hypernet, hypernet.test_nodes)\n",
    "        \n",
    "\n",
    "        hypernet = hypernet.train()\n",
    "\n",
    "\n",
    "\n",
    "        optimizer = torch.optim.Adam(hypernet.parameters(), lr=lr)\n",
    "\n",
    "        # loaders\n",
    "        sup_trainloader, unsup_trainloader, testloader = hp.semisl.get_dataloaders(dataset=dataset, size=size, batch_size=32, test_batch_size=64)\n",
    "        trainloader = hp.semisl.TrainDataLoaderSemi(sup_trainloader, unsup_trainloader)\n",
    "\n",
    "        results[size].append(hp.semisl.train_semisl(hypernet,\n",
    "                                          optimizer,\n",
    "                                          criterion,\n",
    "                                          (trainloader, testloader), \n",
    "                                          size,\n",
    "                                          epochs,\n",
    "                                          masks_no,\n",
    "                                          changing_beta=None,\n",
    "                                          log_to_comet=False,\n",
    "                                          project_name=\"mask-selection\",\n",
    "                                          tags=['best hyperparam'],\n",
    "                                          description=\"\"\"\n",
    "                                          masks are selected based on feature variance with softmax and temp\n",
    "                                          \"\"\",\n",
    "                                        log_params={'seed': seed, 'temp scheduler': 'inc by one 1..20', 'max_temp' : 20}\n",
    "                                        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfee945d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d84ad709",
   "metadata": {},
   "source": [
    "### Temp scheduler 1..11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86d0be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for beta in [0.]:\n",
    "    for lr in [3e-5]:\n",
    "        \n",
    "        temp_scheduler = IncByOneTempScheduler(1, n=mask_size, max_temp=11)\n",
    "        mask_selector = VarianceWithSoftmaxMasksSelector(feature_variances(dataset), mask_size, temp_scheduler)\n",
    "\n",
    "        criterion = SSLCELossWithThreshold(beta=beta, threshold=None)\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        # dataset\n",
    "\n",
    "\n",
    "        hypernet = hp.Hypernetwork(\n",
    "            architecture=torch.nn.Sequential(\n",
    "                torch.nn.Linear(784, 64), \n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(64, 256),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(256, 128),\n",
    "            ),\n",
    "            target_architecture=[(mask_size, 10), (10, 10)],\n",
    "            test_nodes=masks_no,\n",
    "        ).cuda()\n",
    "        hypernet._create_mask = None\n",
    "        hypernet.test_mask = mask_selector(hypernet, hypernet.test_nodes)\n",
    "\n",
    "        hypernet = hypernet.train()\n",
    "\n",
    "\n",
    "\n",
    "        optimizer = torch.optim.Adam(hypernet.parameters(), lr=lr)\n",
    "\n",
    "        # loaders\n",
    "        sup_trainloader, unsup_trainloader, testloader = hp.semisl.get_dataloaders(dataset=dataset, size=size, batch_size=32, test_batch_size=64)\n",
    "        trainloader = hp.semisl.TrainDataLoaderSemi(sup_trainloader, unsup_trainloader)\n",
    "\n",
    "        results[size].append(hp.semisl.train_semisl(hypernet,\n",
    "                                          optimizer,\n",
    "                                          criterion,\n",
    "                                          (trainloader, testloader), \n",
    "                                          size,\n",
    "                                          epochs,\n",
    "                                          masks_no,\n",
    "                                          changing_beta=None,\n",
    "                                          log_to_comet=True,\n",
    "                                          project_name=\"mask-selection\",\n",
    "                                          tags=['best hyperparam'],\n",
    "                                          description=\"\"\"\n",
    "                                          masks are selected based on feature variance with softmax and temp\n",
    "                                          \"\"\",\n",
    "                                        log_params={'seed': seed, 'temp scheduler': 'inc by one 1..11', 'max_temp' : 11}\n",
    "                                        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd182aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d7b39ef",
   "metadata": {},
   "source": [
    "### Temp scheduler 1..1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f8f740",
   "metadata": {},
   "outputs": [],
   "source": [
    "for beta in [0.]:\n",
    "    for lr in [3e-5]:\n",
    "        \n",
    "        temp_scheduler = IncByOneTempScheduler(1, n=mask_size, max_temp=1)\n",
    "        mask_selector = VarianceWithSoftmaxMasksSelector(feature_variances(dataset), mask_size, temp_scheduler)\n",
    "\n",
    "        criterion = SSLCELossWithThreshold(beta=beta, threshold=None)\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        # dataset\n",
    "\n",
    "\n",
    "        hypernet = hp.Hypernetwork(\n",
    "            architecture=torch.nn.Sequential(\n",
    "                torch.nn.Linear(784, 64), \n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(64, 256),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(256, 128),\n",
    "            ),\n",
    "            target_architecture=[(mask_size, 10), (10, 10)],\n",
    "            test_nodes=masks_no,\n",
    "        ).cuda()\n",
    "        hypernet._create_mask = None\n",
    "        hypernet.test_mask = mask_selector(hypernet, hypernet.test_nodes)\n",
    "\n",
    "        hypernet = hypernet.train()\n",
    "\n",
    "\n",
    "\n",
    "        optimizer = torch.optim.Adam(hypernet.parameters(), lr=lr)\n",
    "\n",
    "        # loaders\n",
    "        sup_trainloader, unsup_trainloader, testloader = hp.semisl.get_dataloaders(dataset=dataset, size=size, batch_size=32, test_batch_size=64)\n",
    "        trainloader = hp.semisl.TrainDataLoaderSemi(sup_trainloader, unsup_trainloader)\n",
    "\n",
    "        results[size].append(hp.semisl.train_semisl(hypernet,\n",
    "                                          optimizer,\n",
    "                                          criterion,\n",
    "                                          (trainloader, testloader), \n",
    "                                          size,\n",
    "                                          epochs,\n",
    "                                          masks_no,\n",
    "                                          changing_beta=None,\n",
    "                                          log_to_comet=True,\n",
    "                                          project_name=\"mask-selection\",\n",
    "                                          tags=['best hyperparam'],\n",
    "                                          description=\"\"\"\n",
    "                                          masks are selected based on feature variance with softmax and temp\n",
    "                                          \"\"\",\n",
    "                                        log_params={'seed': seed, 'temp scheduler': '1..1', 'max_temp' : 1}\n",
    "                                        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830de5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15abe61a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16db4463",
   "metadata": {},
   "source": [
    "### Half half temp scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bdce02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc6cb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077407c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for beta in [0.]:\n",
    "    for lr in [3e-5]:\n",
    "        \n",
    "        temp_scheduler = HalfHalfTempScheduler(1, n=mask_size, max_temp=11)\n",
    "        mask_selector = VarianceWithSoftmaxMasksSelector(feature_variances(dataset), mask_size, temp_scheduler)\n",
    "\n",
    "        criterion = SSLCELossWithThreshold(beta=beta, threshold=None)\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        # dataset\n",
    "\n",
    "\n",
    "        hypernet = hp.Hypernetwork(\n",
    "            architecture=torch.nn.Sequential(\n",
    "                torch.nn.Linear(784, 64), \n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(64, 256),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(256, 128),\n",
    "            ),\n",
    "            target_architecture=[(mask_size, 10), (10, 10)],\n",
    "            test_nodes=masks_no,\n",
    "        ).cuda()\n",
    "        hypernet._create_mask = None\n",
    "        hypernet.test_mask = mask_selector(hypernet, hypernet.test_nodes)\n",
    "\n",
    "        hypernet = hypernet.train()\n",
    "\n",
    "\n",
    "\n",
    "        optimizer = torch.optim.Adam(hypernet.parameters(), lr=lr)\n",
    "\n",
    "        # loaders\n",
    "        sup_trainloader, unsup_trainloader, testloader = hp.semisl.get_dataloaders(dataset=dataset, size=size, batch_size=32, test_batch_size=64)\n",
    "        trainloader = hp.semisl.TrainDataLoaderSemi(sup_trainloader, unsup_trainloader)\n",
    "\n",
    "        results[size].append(hp.semisl.train_semisl(hypernet,\n",
    "                                          optimizer,\n",
    "                                          criterion,\n",
    "                                          (trainloader, testloader), \n",
    "                                          size,\n",
    "                                          epochs,\n",
    "                                          masks_no,\n",
    "                                          changing_beta=None,\n",
    "                                          log_to_comet=True,\n",
    "                                          project_name=\"mask-selection\",\n",
    "                                          tags=['best hyperparam'],\n",
    "                                          description=\"\"\"\n",
    "                                          masks are selected based on feature variance with softmax and temp\n",
    "                                          \"\"\",\n",
    "                                        log_params={'seed': seed, 'temp scheduler': 'half half', 'max_temp' : 11}\n",
    "                                        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527b9d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#68.6   1.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40950f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fea68c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29ef9778",
   "metadata": {},
   "source": [
    "### No feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd1d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "for beta in [0.]:\n",
    "\n",
    "    for lr in [3e-5]:\n",
    "\n",
    "\n",
    "        criterion = SSLCELossWithThreshold(beta=beta, threshold=None)\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        # dataset\n",
    "\n",
    "\n",
    "        hypernet = hp.Hypernetwork(\n",
    "            architecture=torch.nn.Sequential(\n",
    "                torch.nn.Linear(784, 64), \n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(64, 256),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(256, 128),\n",
    "            ),\n",
    "            target_architecture=[(mask_size, 10), (10, 10)],\n",
    "            test_nodes=masks_no,\n",
    "        ).cuda()\n",
    "        \n",
    "        hypernet = hypernet.train()\n",
    "\n",
    "\n",
    "\n",
    "        optimizer = torch.optim.Adam(hypernet.parameters(), lr=lr)\n",
    "\n",
    "        # loaders\n",
    "        sup_trainloader, unsup_trainloader, testloader = hp.semisl.get_dataloaders(dataset=dataset, size=size, batch_size=32, test_batch_size=64)\n",
    "        trainloader = hp.semisl.TrainDataLoaderSemi(sup_trainloader, unsup_trainloader)\n",
    "\n",
    "        results[size].append(hp.semisl.train_semisl(hypernet,\n",
    "                                          optimizer,\n",
    "                                          criterion,\n",
    "                                          (trainloader, testloader), \n",
    "                                          size,\n",
    "                                          epochs,\n",
    "                                          masks_no,\n",
    "                                          changing_beta=None,\n",
    "                                          log_to_comet=True,\n",
    "                                          project_name=\"mask-selection\",\n",
    "                                          tags=['best hyperparam'],\n",
    "                                          description=\"\"\"\n",
    "                                          masks are selected based on feature variance with softmax and temp\n",
    "                                          \"\"\",\n",
    "                                        log_params={'seed': seed, 'temp scheduler': 'none', 'mask selection': 'none'}\n",
    "                                        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39753de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fcb953",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

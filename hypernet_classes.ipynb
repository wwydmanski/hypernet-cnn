{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92783e7e-6365-4c18-a113-0ab96e908c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093e1cfc-0554-4973-bc83-734bf882b7ea",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "84aefe8b-dd1a-48c7-91a4-dc53355c8745",
   "metadata": {},
   "outputs": [],
   "source": [
    "mods = [transforms.ToTensor(), \n",
    "        transforms.Normalize((0.1307,), (0.3081,)),    #mean and std of MNIST\n",
    "        transforms.Lambda(lambda x: torch.flatten(x))]\n",
    "mods = transforms.Compose(mods)\n",
    "\n",
    "trainset = datasets.MNIST(root='./data/train', train=True, download=True, transform=mods)\n",
    "testset = datasets.MNIST(root='./data/test', train=False, download=True, transform=mods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b268577-494d-42e4-9d86-f2bfd280e89a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Subset the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ec7af190-a405-4aca-97a0-e5be73be4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = torch.arange(100)\n",
    "# trainset = data_utils.Subset(trainset, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dfe29125-e9dd-453f-95c3-c24e7f9d97b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f662bab8-15f8-4ea7-bc93-5ba1708f7ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(trainset[0][0].reshape((28, 28)));\n",
    "plt.title(trainset[0][1]);\n",
    "plt.xticks([])\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67f07f8-aba0-4186-9a10-2c2f78964afd",
   "metadata": {},
   "source": [
    "## Prepare a single network module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e3683f15-19a0-4a50-acc5-4defea5000e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNetwork(torch.nn.Module):\n",
    "    def __init__(self, inp_size, layers=[100]):\n",
    "        super().__init__()\n",
    "        self.layers = []\n",
    "        \n",
    "        self.inp = torch.nn.Linear(inp_size, layers[0])\n",
    "        self.output = torch.nn.Linear(layers[0], 10)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.inp(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.output(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a1c7a4aa-32eb-49bc-b13d-a54c81390a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net, optimizer, epochs, verbose=False):\n",
    "    for epoch in range(epochs): \n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        net.train()\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            correct += (outputs.argmax(1)==labels).float().sum()\n",
    "            total += outputs.shape[0]\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 0:    # print every 100 mini-batches\n",
    "                if verbose:\n",
    "                    print('[%d, %5d] loss: %.3f acc: %.3f%%' %\n",
    "                          (epoch + 1, i, running_loss / 100, correct/total*100))\n",
    "                running_loss = 0.0\n",
    "                correct = 0\n",
    "                total=0\n",
    "\n",
    "        correct = 0\n",
    "        test_loss = 0\n",
    "        net.eval()\n",
    "        for i, data in enumerate(testloader):\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "        print(f\"Test acc: {correct/len(testset)*100}, loss: {test_loss/i:.3f}\")\n",
    "        \n",
    "    return correct/len(testset)*100, test_loss/i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75022978-980e-4acb-9b40-3963cd0de80b",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c333be1c-e0b4-49ae-9e2c-c203b86f26fe",
   "metadata": {},
   "source": [
    "#### Full network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a4f0ef37-5964-405a-ae93-16fe050fca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleNetwork(784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a74c7b50-57bb-4aff-b2b1-9e27081c6518",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "31c8b792-931c-4097-870f-ae89bb637a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 96.3, loss: 0.120\n",
      "Test acc: 96.86, loss: 0.109\n",
      "Test acc: 96.66, loss: 0.114\n",
      "Test acc: 96.89, loss: 0.115\n",
      "Test acc: 97.24000000000001, loss: 0.103\n",
      "Test acc: 98.08, loss: 0.077\n",
      "Test acc: 98.02, loss: 0.077\n",
      "Test acc: 98.07000000000001, loss: 0.076\n",
      "Test acc: 98.08, loss: 0.077\n",
      "Test acc: 97.97, loss: 0.081\n",
      "CPU times: user 5min 39s, sys: 7.84 s, total: 5min 46s\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=3e-3)\n",
    "train_net(net, optimizer, 5)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=3e-4)\n",
    "final_loss = train_net(net, optimizer, 5)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce339da-00ac-4ce3-a36b-7f58e406d0e1",
   "metadata": {},
   "source": [
    "#### Masked input (for further benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b8df1d1a-2372-408d-9aaa-dbac84d7d23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "mask_size = 700\n",
    "\n",
    "np.random.seed(42)\n",
    "template = np.zeros(input_size)\n",
    "mask_idx = np.random.choice(len(template), mask_size, False)\n",
    "template[mask_idx] = 1\n",
    "mask = torch.from_numpy(template).to(torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9a89d5a3-1c39-4475-ad87-188628964c26",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([598, 590, 209, 637, 174, 213, 429, 259, 593, 204, 576, 244, 235,\n",
       "       218, 770, 155, 516,  67, 579, 109,  66, 522,  78, 473,  23, 211,\n",
       "       706, 445, 644,  39, 332,  86, 137, 653, 656, 442, 525, 515, 334,\n",
       "       630, 342, 780, 118, 652, 260, 779, 352, 432,  77, 691, 483, 682,\n",
       "        49, 518, 168, 326, 377, 375, 568, 309, 629,  30, 361,  33,  31,\n",
       "       627, 558, 405, 254, 412, 739, 486, 266, 331, 422, 231, 333, 357,\n",
       "       620, 265,  54, 735, 514,  97, 506, 294, 234, 749, 311, 351, 120,\n",
       "       436,  84,  10, 624, 464, 192, 530, 199,  29, 470, 323,  65, 350,\n",
       "       659, 239,  81, 485, 291, 487, 264, 715, 535, 519,  76, 388, 523,\n",
       "       570,  72, 693, 409, 208, 585,  63, 314, 672, 302, 750, 363, 393,\n",
       "       752, 367, 705,   7, 533, 101, 428, 765, 745,   2, 398, 527, 764,\n",
       "       196, 641, 729, 493, 448, 215, 425, 581, 417,  79, 148, 335, 247,\n",
       "       559, 762, 133, 648,  55, 411, 597, 675, 545, 617, 720, 296, 362,\n",
       "        60, 741, 360, 440, 662, 426, 383, 327, 584, 286,  90, 382, 181,\n",
       "       443, 618, 158,  69, 446, 131,  44,  70, 210, 340, 300, 275, 135,\n",
       "       740, 165, 164,  28, 639, 193, 220, 534, 306, 136, 521, 299, 140,\n",
       "       457,   6, 611, 478,  73, 250, 778, 145, 281, 290, 434, 132, 771,\n",
       "       539, 734, 615,  41, 477, 108, 628,  56, 292, 704, 394, 227, 212,\n",
       "       583, 319,  24, 467, 733, 336, 365, 544, 110,  82,  51, 465, 731,\n",
       "       718, 632, 198, 549, 687, 499, 482, 479, 139, 444, 420,  18, 649,\n",
       "       328,  83,  61, 572, 431, 182, 481, 223, 433, 451, 381, 453, 721,\n",
       "       746, 176, 536, 626, 163, 248, 507, 696,  74, 616, 713, 104, 114,\n",
       "       424,  92, 395,  89, 751, 495, 728, 609, 594,  11, 338,  43,  42,\n",
       "       167, 689, 603, 396, 178, 688, 529, 177, 543, 726, 257, 344, 456,\n",
       "        15, 606, 256, 355, 517, 324, 462, 708, 356, 329, 605,   9, 249,\n",
       "        22, 221, 537, 676, 768, 439, 657, 203, 237,  93, 680, 346, 490,\n",
       "       284, 184, 636, 380, 153,  75, 512, 277,  68, 494, 188, 271, 236,\n",
       "        88, 667, 117, 125, 736, 289, 238,   0, 775, 368, 743, 450, 278,\n",
       "       776, 116, 228, 634, 404, 677, 274, 318, 541, 144, 497, 678, 711,\n",
       "       575, 369, 268, 557, 307, 310, 782,  46, 349, 371, 513, 261, 195,\n",
       "       783, 658, 107,  59, 589, 423, 100, 660, 703, 633, 586, 179, 304,\n",
       "       761, 650, 755, 149, 124, 623, 683, 185, 531,  50, 500, 773, 722,\n",
       "       321, 353, 724, 142, 370, 141, 399, 511, 320,  19, 172, 640, 312,\n",
       "       390, 730,  12, 407, 408, 305, 354,  25, 587, 169,  38, 175, 245,\n",
       "       298, 654, 416, 538, 272, 601, 154, 126, 449, 716, 341, 430, 287,\n",
       "       113, 501, 173, 359, 774,  57, 542, 222, 280,  17, 127, 322, 255,\n",
       "       528, 588, 468, 753, 190, 115, 695, 645,  94, 180, 301, 571, 580,\n",
       "       551, 548, 694, 532,   5, 769,  45, 710, 157, 595, 171,  16,  48,\n",
       "       759, 719,   3, 567, 554, 316, 552, 480, 447, 723, 283,  96, 285,\n",
       "       526, 225,  26, 631, 263, 437, 364, 229,  37, 754, 374, 469, 756,\n",
       "       668, 582, 194, 670, 679, 503, 758, 655, 757, 162, 604, 152, 547,\n",
       "       742, 602, 111, 226, 651, 103, 421, 419, 119,  53, 151, 403, 738,\n",
       "       207, 767, 608,   8, 638,  36, 452, 253, 303, 596, 569, 635, 262,\n",
       "       297, 414, 150, 625, 698, 550, 488, 147, 146, 578, 727, 591, 348,\n",
       "       463, 325, 186, 123, 669, 143, 748, 197, 279, 293, 400, 122, 183,\n",
       "       202, 438, 246, 415, 697, 129, 402, 621, 613, 712, 219, 714, 599,\n",
       "       717, 610, 386, 760, 509, 267, 685, 441, 496, 112, 232, 684, 607,\n",
       "       373, 233, 622, 317, 410, 709, 358, 258, 282, 376, 384, 224, 744,\n",
       "       643, 472, 347, 505, 772, 725, 707, 619, 671, 664, 556, 577,  85,\n",
       "       242, 159, 524,  35, 540, 170, 673, 665, 737,  95, 563, 240, 574,\n",
       "       460, 553, 690, 206, 392, 397, 666, 217,   4, 642, 701, 612, 546,\n",
       "        98, 573, 406, 502,  47,  32, 200, 134,  27, 692, 230, 489, 378,\n",
       "       288, 418, 674, 391, 592, 498, 138,  62, 471, 647, 128, 763, 520,\n",
       "        64,  14, 156,  40, 492, 379, 187, 216,  52, 337, 295])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "590c94da-d051-4cdb-9bb5-5a59b553b27f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 21.5, loss: 2.194\n",
      "Test acc: 29.99, loss: 2.066\n",
      "Test acc: 38.18, loss: 1.938\n",
      "Test acc: 46.339999999999996, loss: 1.822\n",
      "Test acc: 52.339999999999996, loss: 1.717\n",
      "Test acc: 55.300000000000004, loss: 1.621\n",
      "Test acc: 57.54, loss: 1.538\n",
      "Test acc: 58.68, loss: 1.461\n",
      "Test acc: 60.25, loss: 1.387\n",
      "Test acc: 61.339999999999996, loss: 1.321\n",
      "Test acc: 63.38, loss: 1.254\n",
      "Test acc: 64.63, loss: 1.188\n",
      "Test acc: 66.3, loss: 1.126\n",
      "Test acc: 67.91, loss: 1.066\n",
      "Test acc: 69.87, loss: 1.009\n",
      "Test acc: 73.08, loss: 0.953\n",
      "Test acc: 75.44999999999999, loss: 0.901\n",
      "Test acc: 77.56, loss: 0.853\n",
      "Test acc: 78.66, loss: 0.812\n",
      "Test acc: 79.41, loss: 0.781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(79.41, 0.7807565442262552)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MaskedNetwork(SimpleNetwork):\n",
    "    def __init__(self, input_size, mask_size, layers=[10]):\n",
    "        super().__init__(mask_size, layers=layers)\n",
    "        template = np.zeros(input_size)\n",
    "        mask = np.random.choice(len(template), mask_size, False)\n",
    "        template[mask] = 1\n",
    "        self.mask = torch.from_numpy(template).to(torch.bool)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        data = x[:, self.mask]\n",
    "        return super().forward(data)\n",
    "\n",
    "masked_net = MaskedNetwork(784, 700)\n",
    "masked_net.mask = mask\n",
    "optimizer = torch.optim.Adam(masked_net.parameters(), lr=3e-4)\n",
    "train_net(masked_net, optimizer, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41bc784-1d6c-48d7-b017-54ca8356e9a1",
   "metadata": {},
   "source": [
    "## Create simple network with insertable weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b19746d7-e05e-422c-a1a6-677d2d8a152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_parameters = []\n",
    "for layer in net.parameters():\n",
    "    flat_parameters.extend(torch.flatten(layer).detach().numpy())\n",
    "    \n",
    "flat_parameters = torch.from_numpy(np.array(flat_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ae174f8f-e5e2-4756-be75-50fa2e0dc2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class InsertableNet(SimpleNetwork):\n",
    "    def __init__(self, weights, inp_size, out_size, layers=[10]):\n",
    "        super().__init__(inp_size, layers)\n",
    "        input_w_size = inp_size*layers[0]\n",
    "        input_b_size = layers[0]\n",
    "\n",
    "        hidden_w_size = layers[0]*out_size\n",
    "        hidden_b_size = out_size\n",
    "\n",
    "        self.inp_weights = weights[:input_w_size].reshape((layers[0], inp_size))\n",
    "        self.inp_bias = weights[input_w_size:input_w_size+input_b_size]\n",
    "\n",
    "        self.output_weights = weights[input_w_size+input_b_size:input_w_size+input_b_size+hidden_w_size].reshape((out_size, layers[0]))\n",
    "        self.output_bias = weights[input_w_size+input_b_size+hidden_w_size:input_w_size+input_b_size+hidden_w_size+hidden_b_size]\n",
    "        self.out_act = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, data):\n",
    "        out = F.linear(data, self.inp_weights, self.inp_bias)\n",
    "        out = self.relu(out)\n",
    "        out = F.linear(out, self.output_weights, self.output_bias)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ed18b7d6-f71f-4542-b244-f985aa030ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_net = InsertableNet(flat_parameters, 784, 10, [100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "82225727-12c7-4da9-86b8-5d208f4f993b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 97.97\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = insert_net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "print(f\"Test acc: {correct/len(testset)*100}\")\n",
    "assert correct/len(testset)*100 == final_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee06654-710e-4c65-8bf3-9910061f9707",
   "metadata": {},
   "source": [
    "## Create hypernet structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6eb71ab6-e54b-42ad-a4aa-814e9e8a9854",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hypernetwork(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inp_size=784,\n",
    "        out_size=10,\n",
    "        mask_size=20,\n",
    "        node_hidden_size=20,\n",
    "        layers=[64, 256, 128],\n",
    "        test_nodes=100,\n",
    "        mode=\"slow_step\",\n",
    "        device=\"cuda:0\",\n",
    "    ):\n",
    "        \"\"\" Initialize a hypernetwork.\n",
    "        Args:\n",
    "            inp_size - size of input\n",
    "            out_size - size of output\n",
    "            mask_size - size of mask\n",
    "            node_hidden_size - size of hidden layer in target network\n",
    "            layers - list of hidden layer sizes\n",
    "            test_nodes - number of test nodes\n",
    "            device - device to use\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.target_outsize = out_size\n",
    "        self.device = device\n",
    "        self.mode = mode\n",
    "\n",
    "        self.mask_size = mask_size\n",
    "        self.input_size = inp_size\n",
    "        self.node_hidden_size = node_hidden_size\n",
    "\n",
    "        input_w_size = mask_size * node_hidden_size\n",
    "        input_b_size = node_hidden_size\n",
    "\n",
    "        hidden_w_size = node_hidden_size * out_size\n",
    "        hidden_b_size = out_size\n",
    "\n",
    "        self.out_size = input_w_size + input_b_size + hidden_w_size + hidden_b_size\n",
    "\n",
    "        self.input = torch.nn.Linear(inp_size, layers[0])\n",
    "        self.hidden1 = torch.nn.Linear(layers[0], layers[1])\n",
    "        self.hidden2 = torch.nn.Linear(layers[1], layers[2])\n",
    "        self.out = torch.nn.Linear(layers[2], self.out_size)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout()\n",
    "\n",
    "        self.relu = torch.relu\n",
    "        self.template = np.zeros(inp_size)\n",
    "        self.test_nodes = test_nodes\n",
    "        self.test_mask = self._create_mask(test_nodes)\n",
    "\n",
    "        self._retrained = True\n",
    "        self._test_nets = None\n",
    "\n",
    "    def to(self, device):\n",
    "        super().to(device)\n",
    "        self.device = device\n",
    "        self.test_mask = self._create_mask(self.test_nodes)\n",
    "        return self\n",
    "\n",
    "    def _slow_step_training(self, data, mask):\n",
    "        weights = self.craft_network(mask[:1])\n",
    "        mask = mask.to(torch.bool)\n",
    "        nn = InsertableNet(\n",
    "            weights[0],\n",
    "            self.mask_size,\n",
    "            self.target_outsize,\n",
    "            layers=[self.node_hidden_size],\n",
    "        )\n",
    "\n",
    "        res = torch.zeros((len(data), self.target_outsize)).to(self.device)\n",
    "        for i in range(len(data)):\n",
    "            masked_data = data[i, mask[i]]\n",
    "            res[i] = nn(masked_data)\n",
    "        return res\n",
    "\n",
    "    def _external_mask_training(self, data, mask):\n",
    "        recalculate = [True] * len(mask)\n",
    "        for i in range(1, len(mask)):\n",
    "            if torch.equal(mask[i - 1], mask[i]):\n",
    "                recalculate[i] = False\n",
    "\n",
    "        weights = self.craft_network(mask)\n",
    "        mask = mask.to(torch.bool)\n",
    "\n",
    "        res = torch.zeros((len(data), self.target_outsize)).to(self.device)\n",
    "        for i in range(len(data)):\n",
    "            if recalculate[i]:\n",
    "                nn = InsertableNet(\n",
    "                    weights[i],\n",
    "                    self.mask_size,\n",
    "                    self.target_outsize,\n",
    "                    layers=[self.node_hidden_size],\n",
    "                )\n",
    "            masked_data = data[i, mask[i]]\n",
    "            res[i] = nn(masked_data)\n",
    "        return res\n",
    "\n",
    "    def forward(self, data, mask=None):\n",
    "        \"\"\"Get a hypernet prediction.\n",
    "        During training we use a single target network per sample.\n",
    "        During eval, we create a network for each test mask and average their results\n",
    "\n",
    "        Args:\n",
    "            data - prediction input\n",
    "            mask - either None or a torch.tensor((data.shape[0], data.shape[1])).\n",
    "        \"\"\"\n",
    "        if self.training:\n",
    "            self._retrained = True\n",
    "            if self.mode == \"slow_step\":\n",
    "                assert mask is not None, \"Specify mask or choose another training regime\"\n",
    "                return self._slow_step_training(data, mask)\n",
    "\n",
    "            if mask is None:\n",
    "                mask = self._create_mask(len(data))\n",
    "\n",
    "            return self._external_mask_training(data, mask)\n",
    "        else:\n",
    "            if mask is None:\n",
    "                mask = self.test_mask\n",
    "                nets = self._get_test_nets()\n",
    "            else:\n",
    "                nets = self.__craft_nets(mask)\n",
    "            mask = mask.to(torch.bool)\n",
    "\n",
    "            res = torch.zeros((len(data), self.target_outsize)).to(self.device)\n",
    "            for i in range(len(mask)):\n",
    "                nn = nets[i]\n",
    "                masked_data = data[:, mask[i]]\n",
    "                res += nn(masked_data)\n",
    "            res /= self.test_nodes\n",
    "            return res\n",
    "\n",
    "    def _get_test_nets(self):\n",
    "        if self._retrained:\n",
    "            nets = self.__craft_nets(self.test_mask)\n",
    "            self._test_nets = nets\n",
    "            self._retrained = False\n",
    "        return self._test_nets\n",
    "\n",
    "    def __craft_nets(self, mask):\n",
    "        nets = []\n",
    "        weights = self.craft_network(mask.to(torch.float32))\n",
    "        for i in range(len(mask)):\n",
    "            nn = InsertableNet(\n",
    "                weights[i],\n",
    "                self.mask_size,\n",
    "                self.target_outsize,\n",
    "                layers=[self.node_hidden_size],\n",
    "            )\n",
    "            nets.append(nn)\n",
    "        return nets\n",
    "\n",
    "    def _create_mask(self, count):\n",
    "        masks = np.array(\n",
    "            [\n",
    "                np.random.choice((len(self.template)), self.mask_size, False)\n",
    "                for _ in range(count)\n",
    "            ]\n",
    "        )\n",
    "        tmp = np.array([self.template.copy() for _ in range(count)])\n",
    "        for i, mask in enumerate(masks):\n",
    "            tmp[i, mask] = 1\n",
    "        mask = torch.from_numpy(tmp).to(torch.float32).to(self.device)\n",
    "        return mask\n",
    "\n",
    "    def craft_network(self, mask):\n",
    "        out = self.input(mask)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.hidden1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.hidden2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e1487ddb-feda-4af3-8e49-b748268a127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b4121bc1-b65c-4929-8df8-373bb87f2593",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypernet = Hypernetwork(mask_size=700, mode=\"regular\").to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dc294ff4-8e93-4fc1-9b5b-28b4c9e1bf51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0206,  0.0136,  0.0316,  ..., -0.0006,  0.0196,  0.0090],\n",
       "        [-0.0309,  0.0056,  0.0143,  ...,  0.0302,  0.0126, -0.0179],\n",
       "        [-0.0010,  0.0224,  0.0143,  ..., -0.0239,  0.0095,  0.0318],\n",
       "        ...,\n",
       "        [-0.0079, -0.0193,  0.0076,  ...,  0.0181, -0.0325, -0.0233],\n",
       "        [ 0.0272, -0.0285,  0.0215,  ..., -0.0104, -0.0054,  0.0244],\n",
       "        [ 0.0118, -0.0017,  0.0134,  ...,  0.0141, -0.0251,  0.0298]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(hypernet.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0c09bb25-6567-4c46-aa83-06b8fae32dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 64]          50,240\n",
      "            Linear-2                  [-1, 256]          16,640\n",
      "           Dropout-3                  [-1, 256]               0\n",
      "            Linear-4                  [-1, 128]          32,896\n",
      "            Linear-5                [-1, 14230]       1,835,670\n",
      "================================================================\n",
      "Total params: 1,935,446\n",
      "Trainable params: 1,935,446\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.11\n",
      "Params size (MB): 7.38\n",
      "Estimated Total Size (MB): 7.50\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(hypernet, (784, ), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cc44c4d2-3878-4407-985b-43b08854dbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     0] loss: 0.024 acc: 7.812%\n",
      "[1,   100] loss: 1.488 acc: 47.750%\n",
      "[1,   200] loss: 1.047 acc: 66.531%\n",
      "[1,   300] loss: 0.901 acc: 70.906%\n",
      "[1,   400] loss: 0.841 acc: 73.281%\n",
      "[1,   500] loss: 0.760 acc: 76.297%\n",
      "[1,   600] loss: 0.753 acc: 76.078%\n",
      "[1,   700] loss: 0.667 acc: 79.141%\n",
      "[1,   800] loss: 0.654 acc: 79.156%\n",
      "[1,   900] loss: 0.665 acc: 79.156%\n",
      "Test acc: 86.19, loss: 0.470\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(hypernet.parameters(), lr=3e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "train_net(hypernet, optimizer, 1, verbose=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bf3bf079-e158-41fc-b66e-246f441d0192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0252,  0.0100,  0.0265,  ..., -0.0006,  0.0143,  0.0046],\n",
       "        [-0.0344,  0.0029,  0.0111,  ...,  0.0267,  0.0091, -0.0214],\n",
       "        [-0.0040,  0.0196,  0.0109,  ..., -0.0265,  0.0072,  0.0269],\n",
       "        ...,\n",
       "        [-0.0079, -0.0193,  0.0076,  ...,  0.0181, -0.0325, -0.0233],\n",
       "        [ 0.0279, -0.0297,  0.0213,  ..., -0.0117, -0.0065,  0.0241],\n",
       "        [ 0.0093, -0.0066,  0.0129,  ...,  0.0106, -0.0264,  0.0265]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(hypernet.parameters())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e53dae-57a5-455d-8645-3119fd4873fd",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The network is able to train, so everything is working as expected. Now, we can focus on the raw score optimization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img_processing",
   "language": "python",
   "name": "img_processing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

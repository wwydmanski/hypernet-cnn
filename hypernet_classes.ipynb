{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92783e7e-6365-4c18-a113-0ab96e908c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093e1cfc-0554-4973-bc83-734bf882b7ea",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84aefe8b-dd1a-48c7-91a4-dc53355c8745",
   "metadata": {},
   "outputs": [],
   "source": [
    "mods = [transforms.ToTensor(), \n",
    "        transforms.Normalize((0.1307,), (0.3081,)),    #mean and std of MNIST\n",
    "        transforms.Lambda(lambda x: torch.flatten(x))]\n",
    "mods = transforms.Compose(mods)\n",
    "\n",
    "trainset = datasets.MNIST(root='./data/train', train=True, download=True, transform=mods)\n",
    "testset = datasets.MNIST(root='./data/test', train=False, download=True, transform=mods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b268577-494d-42e4-9d86-f2bfd280e89a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Subset the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec7af190-a405-4aca-97a0-e5be73be4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = torch.arange(100)\n",
    "# trainset = data_utils.Subset(trainset, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfe29125-e9dd-453f-95c3-c24e7f9d97b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f662bab8-15f8-4ea7-bc93-5ba1708f7ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(trainset[0][0].reshape((28, 28)));\n",
    "plt.title(trainset[0][1]);\n",
    "plt.xticks([])\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67f07f8-aba0-4186-9a10-2c2f78964afd",
   "metadata": {},
   "source": [
    "## Prepare a single network module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3683f15-19a0-4a50-acc5-4defea5000e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNetwork(torch.nn.Module):\n",
    "    def __init__(self, inp_size, layers=[100]):\n",
    "        super().__init__()\n",
    "        self.layers = []\n",
    "        \n",
    "        self.inp = torch.nn.Linear(inp_size, layers[0])\n",
    "        self.output = torch.nn.Linear(layers[0], 10)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.inp(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.output(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1c7a4aa-32eb-49bc-b13d-a54c81390a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net, optimizer, epochs, verbose=False):\n",
    "    for epoch in range(epochs): \n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        net.train()\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            correct += (outputs.argmax(1)==labels).float().sum()\n",
    "            total += outputs.shape[0]\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 0:    # print every 100 mini-batches\n",
    "                if verbose:\n",
    "                    print('[%d, %5d] loss: %.3f acc: %.3f%%' %\n",
    "                          (epoch + 1, i, running_loss / 100, correct/total*100))\n",
    "                running_loss = 0.0\n",
    "                correct = 0\n",
    "                total=0\n",
    "\n",
    "        correct = 0\n",
    "        test_loss = 0\n",
    "        net.eval()\n",
    "        for i, data in enumerate(testloader):\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "        print(f\"Test acc: {correct/len(testset)*100}, loss: {test_loss/i:.3f}\")\n",
    "        \n",
    "    return correct/len(testset)*100, test_loss/i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75022978-980e-4acb-9b40-3963cd0de80b",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c333be1c-e0b4-49ae-9e2c-c203b86f26fe",
   "metadata": {},
   "source": [
    "#### Full network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4f0ef37-5964-405a-ae93-16fe050fca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleNetwork(784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a74c7b50-57bb-4aff-b2b1-9e27081c6518",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31c8b792-931c-4097-870f-ae89bb637a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 96.3, loss: 0.123\n",
      "Test acc: 96.96000000000001, loss: 0.094\n",
      "Test acc: 97.09, loss: 0.106\n",
      "Test acc: 96.56, loss: 0.120\n",
      "Test acc: 96.77, loss: 0.120\n",
      "Test acc: 97.92, loss: 0.083\n",
      "Test acc: 98.03, loss: 0.083\n",
      "Test acc: 97.95, loss: 0.083\n",
      "Test acc: 97.97, loss: 0.082\n",
      "Test acc: 97.92, loss: 0.083\n",
      "CPU times: user 17min 55s, sys: 1min 1s, total: 18min 56s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=3e-3)\n",
    "train_net(net, optimizer, 5)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=3e-4)\n",
    "final_loss = train_net(net, optimizer, 5)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce339da-00ac-4ce3-a36b-7f58e406d0e1",
   "metadata": {},
   "source": [
    "#### Masked input (for further benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8df1d1a-2372-408d-9aaa-dbac84d7d23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "mask_size = 700\n",
    "\n",
    "np.random.seed(42)\n",
    "template = np.zeros(input_size)\n",
    "mask_idx = np.random.choice(len(template), mask_size, False)\n",
    "template[mask_idx] = 1\n",
    "mask = torch.from_numpy(template).to(torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a89d5a3-1c39-4475-ad87-188628964c26",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([598, 590, 209, 637, 174, 213, 429, 259, 593, 204, 576, 244, 235,\n",
       "       218, 770, 155, 516,  67, 579, 109,  66, 522,  78, 473,  23, 211,\n",
       "       706, 445, 644,  39, 332,  86, 137, 653, 656, 442, 525, 515, 334,\n",
       "       630, 342, 780, 118, 652, 260, 779, 352, 432,  77, 691, 483, 682,\n",
       "        49, 518, 168, 326, 377, 375, 568, 309, 629,  30, 361,  33,  31,\n",
       "       627, 558, 405, 254, 412, 739, 486, 266, 331, 422, 231, 333, 357,\n",
       "       620, 265,  54, 735, 514,  97, 506, 294, 234, 749, 311, 351, 120,\n",
       "       436,  84,  10, 624, 464, 192, 530, 199,  29, 470, 323,  65, 350,\n",
       "       659, 239,  81, 485, 291, 487, 264, 715, 535, 519,  76, 388, 523,\n",
       "       570,  72, 693, 409, 208, 585,  63, 314, 672, 302, 750, 363, 393,\n",
       "       752, 367, 705,   7, 533, 101, 428, 765, 745,   2, 398, 527, 764,\n",
       "       196, 641, 729, 493, 448, 215, 425, 581, 417,  79, 148, 335, 247,\n",
       "       559, 762, 133, 648,  55, 411, 597, 675, 545, 617, 720, 296, 362,\n",
       "        60, 741, 360, 440, 662, 426, 383, 327, 584, 286,  90, 382, 181,\n",
       "       443, 618, 158,  69, 446, 131,  44,  70, 210, 340, 300, 275, 135,\n",
       "       740, 165, 164,  28, 639, 193, 220, 534, 306, 136, 521, 299, 140,\n",
       "       457,   6, 611, 478,  73, 250, 778, 145, 281, 290, 434, 132, 771,\n",
       "       539, 734, 615,  41, 477, 108, 628,  56, 292, 704, 394, 227, 212,\n",
       "       583, 319,  24, 467, 733, 336, 365, 544, 110,  82,  51, 465, 731,\n",
       "       718, 632, 198, 549, 687, 499, 482, 479, 139, 444, 420,  18, 649,\n",
       "       328,  83,  61, 572, 431, 182, 481, 223, 433, 451, 381, 453, 721,\n",
       "       746, 176, 536, 626, 163, 248, 507, 696,  74, 616, 713, 104, 114,\n",
       "       424,  92, 395,  89, 751, 495, 728, 609, 594,  11, 338,  43,  42,\n",
       "       167, 689, 603, 396, 178, 688, 529, 177, 543, 726, 257, 344, 456,\n",
       "        15, 606, 256, 355, 517, 324, 462, 708, 356, 329, 605,   9, 249,\n",
       "        22, 221, 537, 676, 768, 439, 657, 203, 237,  93, 680, 346, 490,\n",
       "       284, 184, 636, 380, 153,  75, 512, 277,  68, 494, 188, 271, 236,\n",
       "        88, 667, 117, 125, 736, 289, 238,   0, 775, 368, 743, 450, 278,\n",
       "       776, 116, 228, 634, 404, 677, 274, 318, 541, 144, 497, 678, 711,\n",
       "       575, 369, 268, 557, 307, 310, 782,  46, 349, 371, 513, 261, 195,\n",
       "       783, 658, 107,  59, 589, 423, 100, 660, 703, 633, 586, 179, 304,\n",
       "       761, 650, 755, 149, 124, 623, 683, 185, 531,  50, 500, 773, 722,\n",
       "       321, 353, 724, 142, 370, 141, 399, 511, 320,  19, 172, 640, 312,\n",
       "       390, 730,  12, 407, 408, 305, 354,  25, 587, 169,  38, 175, 245,\n",
       "       298, 654, 416, 538, 272, 601, 154, 126, 449, 716, 341, 430, 287,\n",
       "       113, 501, 173, 359, 774,  57, 542, 222, 280,  17, 127, 322, 255,\n",
       "       528, 588, 468, 753, 190, 115, 695, 645,  94, 180, 301, 571, 580,\n",
       "       551, 548, 694, 532,   5, 769,  45, 710, 157, 595, 171,  16,  48,\n",
       "       759, 719,   3, 567, 554, 316, 552, 480, 447, 723, 283,  96, 285,\n",
       "       526, 225,  26, 631, 263, 437, 364, 229,  37, 754, 374, 469, 756,\n",
       "       668, 582, 194, 670, 679, 503, 758, 655, 757, 162, 604, 152, 547,\n",
       "       742, 602, 111, 226, 651, 103, 421, 419, 119,  53, 151, 403, 738,\n",
       "       207, 767, 608,   8, 638,  36, 452, 253, 303, 596, 569, 635, 262,\n",
       "       297, 414, 150, 625, 698, 550, 488, 147, 146, 578, 727, 591, 348,\n",
       "       463, 325, 186, 123, 669, 143, 748, 197, 279, 293, 400, 122, 183,\n",
       "       202, 438, 246, 415, 697, 129, 402, 621, 613, 712, 219, 714, 599,\n",
       "       717, 610, 386, 760, 509, 267, 685, 441, 496, 112, 232, 684, 607,\n",
       "       373, 233, 622, 317, 410, 709, 358, 258, 282, 376, 384, 224, 744,\n",
       "       643, 472, 347, 505, 772, 725, 707, 619, 671, 664, 556, 577,  85,\n",
       "       242, 159, 524,  35, 540, 170, 673, 665, 737,  95, 563, 240, 574,\n",
       "       460, 553, 690, 206, 392, 397, 666, 217,   4, 642, 701, 612, 546,\n",
       "        98, 573, 406, 502,  47,  32, 200, 134,  27, 692, 230, 489, 378,\n",
       "       288, 418, 674, 391, 592, 498, 138,  62, 471, 647, 128, 763, 520,\n",
       "        64,  14, 156,  40, 492, 379, 187, 216,  52, 337, 295])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "590c94da-d051-4cdb-9bb5-5a59b553b27f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 89.24, loss: 0.401\n",
      "Test acc: 90.67, loss: 0.332\n",
      "Test acc: 91.27, loss: 0.308\n",
      "Test acc: 91.24, loss: 0.299\n",
      "Test acc: 91.46, loss: 0.290\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2812624/1093763290.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmasked_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2812624/774909066.py\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(net, optimizer, epochs, verbose)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/img_processing/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/img_processing/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/img_processing/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/img_processing/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/img_processing/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/img_processing/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/img_processing/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/img_processing/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/img_processing/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class MaskedNetwork(SimpleNetwork):\n",
    "    def __init__(self, input_size, mask_size, layers=[10]):\n",
    "        super().__init__(mask_size, layers=layers)\n",
    "        template = np.zeros(input_size)\n",
    "        mask = np.random.choice(len(template), mask_size, False)\n",
    "        template[mask] = 1\n",
    "        self.mask = torch.from_numpy(template).to(torch.bool)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        data = x[:, self.mask]\n",
    "        return super().forward(data)\n",
    "\n",
    "masked_net = MaskedNetwork(784, 700)\n",
    "masked_net.mask = mask\n",
    "optimizer = torch.optim.Adam(masked_net.parameters(), lr=3e-4)\n",
    "train_net(masked_net, optimizer, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41bc784-1d6c-48d7-b017-54ca8356e9a1",
   "metadata": {},
   "source": [
    "## Create simple network with insertable weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b19746d7-e05e-422c-a1a6-677d2d8a152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_parameters = []\n",
    "for layer in net.parameters():\n",
    "    flat_parameters.extend(torch.flatten(layer).detach().numpy())\n",
    "    \n",
    "flat_parameters = torch.from_numpy(np.array(flat_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ae174f8f-e5e2-4756-be75-50fa2e0dc2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class InsertableNet(torch.nn.Module):\n",
    "    def __init__(self, weights, shape=[(784, 10), (10, 10)]):\n",
    "        super().__init__()\n",
    "        self.layers = []\n",
    "        self._offset = 0\n",
    "        \n",
    "        for layer in shape:\n",
    "            _w_size = layer[0]*layer[1]\n",
    "            _b_size = layer[1]\n",
    "            \n",
    "            _l = (weights[self._offset:self._offset+_w_size].reshape((layer[1], layer[0])),\n",
    "                  weights[self._offset+_w_size:self._offset+_w_size+_b_size])\n",
    "            self._offset += _w_size+_b_size\n",
    "\n",
    "            self.layers.append(_l)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        out = data\n",
    "        for layer in self.layers[:-1]:\n",
    "            out = F.linear(out, layer[0], layer[1])\n",
    "            out = F.relu(out)\n",
    "\n",
    "        return F.linear(out, self.layers[-1][0], self.layers[-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed18b7d6-f71f-4542-b244-f985aa030ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_net = InsertableNet(flat_parameters, shape=[(784, 100), (100, 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82225727-12c7-4da9-86b8-5d208f4f993b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 97.92\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = insert_net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "print(f\"Test acc: {correct/len(testset)*100}\")\n",
    "assert correct/len(testset)*100 == final_loss, correct/len(testset)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee06654-710e-4c65-8bf3-9910061f9707",
   "metadata": {},
   "source": [
    "## Create hypernet structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6eb71ab6-e54b-42ad-a4aa-814e9e8a9854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum \n",
    "\n",
    "class TrainingModes(enum.Enum):\n",
    "    SLOW_STEP = \"slow-step\"\n",
    "    CARTHESIAN = \"carth\"\n",
    "    \n",
    "class Hypernetwork(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        architecture=torch.nn.Sequential(torch.nn.Linear(784, 128), \n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Linear(128, 64),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Linear(64, 64)\n",
    "                       ),\n",
    "        target_architecture=[(20, 10), (10, 10)],\n",
    "        test_nodes=100,\n",
    "        mode=TrainingModes.SLOW_STEP,\n",
    "        device=\"cuda:0\",\n",
    "    ):\n",
    "        \"\"\" Initialize a hypernetwork.\n",
    "        Args:\n",
    "            target_inp_size - size of input\n",
    "            out_size - size of output\n",
    "            layers - list of hidden layer sizes\n",
    "            test_nodes - number of test nodes\n",
    "            device - device to use\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.target_outsize = target_architecture[-1][-1]\n",
    "        self.mask_size = target_architecture[0][0]\n",
    "        self.target_architecture = target_architecture\n",
    "        self.device = device\n",
    "        self.mode = mode\n",
    "\n",
    "        self.out_size = self.calculate_outdim(target_architecture)\n",
    "\n",
    "        self.model = architecture.to('cpu')\n",
    "        gen = self.model.parameters()\n",
    "        self.input_size = next(gen).size()[1]\n",
    "        out_dim = self.model(torch.rand(1, self.input_size)).shape\n",
    "        print(out_dim)\n",
    "        output_layer = torch.nn.Linear(out_dim[1], self.out_size)\n",
    "        self.model.add_module(\"output_layer\", output_layer)\n",
    "        self.model = self.model.to(device)\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout()\n",
    "\n",
    "        self.relu = torch.relu\n",
    "        self.template = np.zeros(self.input_size)\n",
    "        self.test_nodes = test_nodes\n",
    "        self.test_mask = self._create_mask(test_nodes)\n",
    "\n",
    "        self._retrained = True\n",
    "        self._test_nets = None\n",
    "        \n",
    "    def calculate_outdim(self, architecture):\n",
    "        weights = 0\n",
    "        for layer in architecture:\n",
    "            weights += layer[0]*layer[1]+layer[1]\n",
    "        return weights\n",
    "\n",
    "    def to(self, device):\n",
    "        super().to(device)\n",
    "        self.device = device\n",
    "        self.test_mask = self._create_mask(self.test_nodes)\n",
    "        self.model = self.model.to(device)\n",
    "        return self\n",
    "\n",
    "    def _slow_step_training(self, data, mask):\n",
    "        weights = self.craft_network(mask[:1])\n",
    "        mask = mask[0].to(torch.bool)\n",
    "        nn = InsertableNet(\n",
    "            weights[0],\n",
    "            self.target_architecture,\n",
    "        )\n",
    "\n",
    "        masked_data = data[:, mask]\n",
    "        res = nn(masked_data)\n",
    "        return res\n",
    "\n",
    "    def _external_mask_training(self, data, mask):\n",
    "        recalculate = [True] * len(mask)\n",
    "        for i in range(1, len(mask)):\n",
    "            if torch.equal(mask[i - 1], mask[i]):\n",
    "                recalculate[i] = False\n",
    "\n",
    "        weights = self.craft_network(mask)\n",
    "        mask = mask.to(torch.bool)\n",
    "\n",
    "        res = torch.zeros((len(data), self.target_outsize)).to(self.device)\n",
    "        for i in range(len(data)):\n",
    "            if recalculate[i]:\n",
    "                nn = InsertableNet(\n",
    "                    weights[i],\n",
    "                    self.target_architecture,\n",
    "                )\n",
    "            masked_data = data[i, mask[i]]\n",
    "            res[i] = nn(masked_data)\n",
    "        return res\n",
    "\n",
    "    def forward(self, data, mask=None):\n",
    "        \"\"\"Get a hypernet prediction.\n",
    "        During training we use a single target network per sample.\n",
    "        During eval, we create a network for each test mask and average their results\n",
    "\n",
    "        Args:\n",
    "            data - prediction input\n",
    "            mask - either None or a torch.tensor((data.shape[0], data.shape[1])).\n",
    "        \"\"\"\n",
    "        if self.training:\n",
    "            self._retrained = True\n",
    "            if self.mode == TrainingModes.SLOW_STEP or self.mode == TrainingModes.CARTHESIAN:\n",
    "                return self._slow_step_training(data, mask)\n",
    "\n",
    "            if mask is None:\n",
    "                mask = self._create_mask(len(data))\n",
    "\n",
    "            return self._external_mask_training(data, mask)\n",
    "        else:\n",
    "            return self._ensemble_inference(data, mask)\n",
    "\n",
    "    def _ensemble_inference(self, data, mask):\n",
    "        if mask is None:\n",
    "            mask = self.test_mask\n",
    "            nets = self._get_test_nets()\n",
    "        else:\n",
    "            nets = self.__craft_nets(mask)\n",
    "        mask = mask.to(torch.bool)\n",
    "\n",
    "        res = torch.zeros((len(data), self.target_outsize)).to(self.device)\n",
    "        for i in range(len(mask)):\n",
    "            nn = nets[i]\n",
    "            masked_data = data[:, mask[i]]\n",
    "            res += nn(masked_data)\n",
    "        res /= len(mask)\n",
    "        return res\n",
    "\n",
    "    def _get_test_nets(self):\n",
    "        if self._retrained:\n",
    "            nets = self.__craft_nets(self.test_mask)\n",
    "            self._test_nets = nets\n",
    "            self._retrained = False\n",
    "        return self._test_nets\n",
    "\n",
    "    def __craft_nets(self, mask):\n",
    "        nets = []\n",
    "        weights = self.craft_network(mask.to(torch.float32))\n",
    "        for i in range(len(mask)):\n",
    "            nn = InsertableNet(\n",
    "                weights[i],\n",
    "                self.target_architecture,\n",
    "            )\n",
    "            nets.append(nn)\n",
    "        return nets\n",
    "\n",
    "    @staticmethod\n",
    "    def random_choice_noreplace2(l, n_sample, num_draw):\n",
    "        '''\n",
    "        l: 1-D array or list\n",
    "        n_sample: sample size for each draw\n",
    "        num_draw: number of draws\n",
    "\n",
    "        Intuition: Randomly generate numbers, get the index of the smallest n_sample number for each row.\n",
    "        '''\n",
    "        l = np.array(l)\n",
    "        return l[np.argpartition(np.random.rand(num_draw,len(l)), n_sample-1,axis=-1)[:,:n_sample]]\n",
    "    \n",
    "    def _create_mask(self, count):\n",
    "        # masks = np.random.choice((len(self.template)), (count, self.mask_size), False)\n",
    "        masks = Hypernetwork.random_choice_noreplace2(np.arange(len(self.template)), self.mask_size, count)\n",
    "        tmp = np.array([self.template.copy() for _ in range(count)])\n",
    "        for i, mask in enumerate(masks):\n",
    "            tmp[i, mask] = 1\n",
    "        mask = torch.from_numpy(tmp).to(torch.float32).to(self.device)\n",
    "        return mask\n",
    "\n",
    "    def craft_network(self, mask):\n",
    "        out = self.model(mask)\n",
    "        # out = self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e1487ddb-feda-4af3-8e49-b748268a127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "998d8895-a202-4a46-a7d0-025f46a0942d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "# hypernet = Hypernetwork(mask_size=700, mode=\"regular\").to(\"cpu\")\n",
    "hypernet = Hypernetwork(\n",
    "    architecture=torch.nn.Sequential(torch.nn.Linear(784, 64), \n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Linear(64, 256),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout(),\n",
    "                        torch.nn.Linear(256, 128),\n",
    "                        torch.nn.ReLU()\n",
    "                       ),\n",
    "    mode=None,\n",
    "    target_architecture=[(700, 20), (20, 10)]).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dc294ff4-8e93-4fc1-9b5b-28b4c9e1bf51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0348,  0.0273, -0.0174,  ..., -0.0061, -0.0090,  0.0333],\n",
       "        [ 0.0127,  0.0013, -0.0099,  ...,  0.0034,  0.0033,  0.0103],\n",
       "        [ 0.0200, -0.0278, -0.0335,  ...,  0.0289,  0.0135, -0.0139],\n",
       "        ...,\n",
       "        [-0.0307,  0.0118, -0.0067,  ...,  0.0090, -0.0196,  0.0262],\n",
       "        [-0.0019, -0.0049,  0.0300,  ..., -0.0036,  0.0045, -0.0027],\n",
       "        [ 0.0255, -0.0085,  0.0192,  ..., -0.0207,  0.0264, -0.0246]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(hypernet.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0c09bb25-6567-4c46-aa83-06b8fae32dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 64]          50,240\n",
      "              ReLU-2                   [-1, 64]               0\n",
      "            Linear-3                  [-1, 256]          16,640\n",
      "              ReLU-4                  [-1, 256]               0\n",
      "           Dropout-5                  [-1, 256]               0\n",
      "            Linear-6                  [-1, 128]          32,896\n",
      "              ReLU-7                  [-1, 128]               0\n",
      "            Linear-8                [-1, 14230]       1,835,670\n",
      "================================================================\n",
      "Total params: 1,935,446\n",
      "Trainable params: 1,935,446\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.12\n",
      "Params size (MB): 7.38\n",
      "Estimated Total Size (MB): 7.50\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(hypernet, (784, ), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cc44c4d2-3878-4407-985b-43b08854dbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     0] loss: 0.023 acc: 10.938%\n",
      "[1,   100] loss: 1.559 acc: 45.766%\n",
      "[1,   200] loss: 1.026 acc: 67.203%\n",
      "[1,   300] loss: 0.883 acc: 71.266%\n",
      "[1,   400] loss: 0.816 acc: 74.031%\n",
      "[1,   500] loss: 0.769 acc: 76.094%\n",
      "[1,   600] loss: 0.710 acc: 77.562%\n",
      "[1,   700] loss: 0.695 acc: 78.172%\n",
      "[1,   800] loss: 0.664 acc: 79.672%\n",
      "[1,   900] loss: 0.652 acc: 78.859%\n",
      "Test acc: 85.95, loss: 0.474\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(hypernet.parameters(), lr=3e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "train_net(hypernet, optimizer, 1, verbose=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bf3bf079-e158-41fc-b66e-246f441d0192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0252,  0.0100,  0.0265,  ..., -0.0006,  0.0143,  0.0046],\n",
       "        [-0.0344,  0.0029,  0.0111,  ...,  0.0267,  0.0091, -0.0214],\n",
       "        [-0.0040,  0.0196,  0.0109,  ..., -0.0265,  0.0072,  0.0269],\n",
       "        ...,\n",
       "        [-0.0079, -0.0193,  0.0076,  ...,  0.0181, -0.0325, -0.0233],\n",
       "        [ 0.0279, -0.0297,  0.0213,  ..., -0.0117, -0.0065,  0.0241],\n",
       "        [ 0.0093, -0.0066,  0.0129,  ...,  0.0106, -0.0264,  0.0265]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(hypernet.parameters())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e53dae-57a5-455d-8645-3119fd4873fd",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The network is able to train, so everything is working as expected. Now, we can focus on the raw score optimization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img_processing",
   "language": "python",
   "name": "img_processing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edfde2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rpy2.rinterface_lib.sexp.NULLType object at 0x7f3c9c327c40> [RTYPES.NILSXP]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rpy2.robjects.packages as rpackages\n",
    "\n",
    "# import R's utility package\n",
    "utils = rpackages.importr('utils')\n",
    "\n",
    "# select a mirror for R packages\n",
    "utils.chooseCRANmirror(ind=1) # select the first mirror in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b1005bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.install_packages('logisticPCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db453527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/hypernet\n"
     ]
    }
   ],
   "source": [
    "%cd hypernet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ef57058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3439415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment, Optimizer\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f81b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "411db77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabular_hypernet as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fed976bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp.lpca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfbc97da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp.training_utils.get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35fd81c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UXrV5UxyhTK3cyQNG6BDuc4bE'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['COMET_KEY'] = 'UXrV5UxyhTK3cyQNG6BDuc4bE'\n",
    "os.environ.get(\"COMET_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884b2bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc4dc449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add shuffle for supervised\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb6c13ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tabular_hypernet.modules import InsertableNet\n",
    "import enum\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "class TrainingModes(enum.Enum):\n",
    "    SLOW_STEP = \"slow-step\"\n",
    "    CARTHESIAN = \"carth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20ffa011",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hypernetwork(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        architecture=torch.nn.Sequential(torch.nn.Linear(784, 128), \n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Linear(128, 64),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Linear(64, 64)\n",
    "                       ),\n",
    "        target_architecture=[(20, 10), (10, 10)],\n",
    "        test_nodes=100,\n",
    "        mode=TrainingModes.SLOW_STEP,\n",
    "        device=\"cuda:0\",\n",
    "        mask_len=None,\n",
    "    ):\n",
    "        \"\"\" Initialize a hypernetwork.\n",
    "        Args:\n",
    "            target_inp_size - size of input\n",
    "            out_size - size of output\n",
    "            layers - list of hidden layer sizes\n",
    "            test_nodes - number of test nodes\n",
    "            device - device to use\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.target_outsize = target_architecture[-1][-1]\n",
    "        self.mask_size = target_architecture[0][0]\n",
    "        self.target_architecture = target_architecture\n",
    "        self.device = device\n",
    "        self.mode = mode\n",
    "\n",
    "        self.out_size = self.calculate_outdim(target_architecture)\n",
    "\n",
    "        self.model = architecture.to('cpu')\n",
    "        gen = self.model.parameters()\n",
    "        self.input_size = next(gen).size()[1]\n",
    "        out_dim = self.model(torch.rand(1, self.input_size)).shape\n",
    "        print(out_dim)\n",
    "        output_layer = torch.nn.Linear(out_dim[1], self.out_size)\n",
    "        self.model.add_module(\"output_layer\", output_layer)\n",
    "        self.model = self.model.to(device)\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout()\n",
    "\n",
    "        self.relu = torch.relu\n",
    "        self.template = np.zeros(mask_len if mask_len else self.input_size)\n",
    "        self.test_nodes = test_nodes\n",
    "        self.test_mask = self._create_mask(test_nodes)\n",
    "\n",
    "        self._retrained = True\n",
    "        self._test_nets = None\n",
    "        \n",
    "    def calculate_outdim(self, architecture):\n",
    "        weights = 0\n",
    "        for layer in architecture:\n",
    "            weights += layer[0]*layer[1]+layer[1]\n",
    "        return weights\n",
    "\n",
    "    def to(self, device):\n",
    "        super().to(device)\n",
    "        self.device = device\n",
    "        self.test_mask = self._create_mask(self.test_nodes)\n",
    "        self.model = self.model.to(device)\n",
    "        return self\n",
    "\n",
    "    def _slow_step_training(self, data, mask, pc_mask=None):\n",
    "        weights = self.craft_network(pc_mask[:1] if pc_mask != None else mask[:1])\n",
    "        mask = mask[0].to(torch.bool)\n",
    "        nn = InsertableNet(\n",
    "            weights[0],\n",
    "            self.target_architecture,\n",
    "        )\n",
    "\n",
    "        masked_data = data[:, mask]\n",
    "        res = nn(masked_data)\n",
    "        return res\n",
    "\n",
    "    def _external_mask_training(self, data, mask):\n",
    "        recalculate = [True] * len(mask)\n",
    "        for i in range(1, len(mask)):\n",
    "            if torch.equal(mask[i - 1], mask[i]):\n",
    "                recalculate[i] = False\n",
    "\n",
    "        weights = self.craft_network(mask)\n",
    "        mask = mask.to(torch.bool)\n",
    "\n",
    "        res = torch.zeros((len(data), self.target_outsize)).to(self.device)\n",
    "        for i in range(len(data)):\n",
    "            if recalculate[i]:\n",
    "                nn = InsertableNet(\n",
    "                    weights[i],\n",
    "                    self.target_architecture,\n",
    "                )\n",
    "            masked_data = data[i, mask[i]]\n",
    "            res[i] = nn(masked_data)\n",
    "        return res\n",
    "\n",
    "    def forward(self, data, mask=None, pc_mask=None):\n",
    "        \"\"\"Get a hypernet prediction.\n",
    "        During training we use a single target network per sample.\n",
    "        During eval, we create a network for each test mask and average their results\n",
    "\n",
    "        Args:\n",
    "            data - prediction input\n",
    "            mask - either None or a torch.tensor((data.shape[0], data.shape[1])).\n",
    "        \"\"\"\n",
    "        if self.training:\n",
    "            self._retrained = True\n",
    "            if self.mode == TrainingModes.SLOW_STEP or self.mode == TrainingModes.CARTHESIAN:\n",
    "                return self._slow_step_training(data, mask, pc_mask)\n",
    "\n",
    "            if mask is None:\n",
    "                mask = self._create_mask(len(data))\n",
    "\n",
    "            return self._external_mask_training(data, mask)\n",
    "        else:\n",
    "            return self._ensemble_inference(data, mask)\n",
    "\n",
    "    def _ensemble_inference(self, data, mask):\n",
    "        if mask is None:\n",
    "            mask = self.test_mask\n",
    "            nets = self._get_test_nets()\n",
    "        else:\n",
    "            nets = self.__craft_nets(mask)\n",
    "        mask = mask.to(torch.bool)\n",
    "\n",
    "        res = torch.zeros((len(data), self.target_outsize)).to(self.device)\n",
    "        for i in range(len(mask)):\n",
    "            nn = nets[i]\n",
    "            masked_data = data[:, mask[i]]\n",
    "            res += nn(masked_data)\n",
    "        res /= len(mask)\n",
    "        if res.shape[1] > 1:\n",
    "            res = F.softmax(res, 1)\n",
    "        return res\n",
    "\n",
    "    def _get_test_nets(self):\n",
    "        if self._retrained:\n",
    "            nets = self.__craft_nets(self.pcs if hasattr(self, 'pcs') else self.test_mask)\n",
    "            self._test_nets = nets\n",
    "            self._retrained = False\n",
    "        return self._test_nets\n",
    "\n",
    "    def __craft_nets(self, mask):\n",
    "        nets = []\n",
    "        weights = self.craft_network(mask.to(torch.float32))\n",
    "        for i in range(len(mask)):\n",
    "            nn = InsertableNet(\n",
    "                weights[i],\n",
    "                self.target_architecture,\n",
    "            )\n",
    "            nets.append(nn)\n",
    "        return nets\n",
    "\n",
    "    @staticmethod\n",
    "    def random_choice_noreplace2(l, n_sample, num_draw):\n",
    "        '''\n",
    "        l: 1-D array or list\n",
    "        n_sample: sample size for each draw\n",
    "        num_draw: number of draws\n",
    "\n",
    "        Intuition: Randomly generate numbers, get the index of the smallest n_sample number for each row.\n",
    "        '''\n",
    "        l = np.array(l)\n",
    "        return l[np.argpartition(np.random.rand(num_draw,len(l)), n_sample-1,axis=-1)[:,:n_sample]]\n",
    "    \n",
    "    def _create_mask(self, count):\n",
    "        # masks = np.random.choice((len(self.template)), (count, self.mask_size), False)\n",
    "        masks = Hypernetwork.random_choice_noreplace2(np.arange(len(self.template)), self.mask_size, count)\n",
    "        tmp = np.array([self.template.copy() for _ in range(count)])\n",
    "        for i, mask in enumerate(masks):\n",
    "            tmp[i, mask] = 1\n",
    "        mask = torch.from_numpy(tmp).to(torch.float32).to(self.device)\n",
    "        return mask\n",
    "\n",
    "    def craft_network(self, mask):\n",
    "        out = self.model(mask)\n",
    "        # out = self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7070b634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688384bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "982c0ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_pcs(hypernet, optimizer, criterion, loaders, data_size, epochs, masks_no, \n",
    "                    experiment=None,\n",
    "                    tag=\"lpca\", \n",
    "                    device='cuda:0', \n",
    "                    project_name=\"hypernetwork\",\n",
    "                    test_every=5,\n",
    "                    log_params={},\n",
    "                  ):\n",
    "    \"\"\" Train hypernetwork using slow step method - use the same mask for a whole batch, change it once per iteration.\"\"\"\n",
    "    if experiment is None:\n",
    "        experiment = Experiment(api_key=os.environ.get(\"COMET_KEY\"), project_name=project_name, display_summary_level=0)\n",
    "        experiment.add_tag(tag)\n",
    "    experiment.log_parameter(\"test_nodes\", hypernet.test_nodes)\n",
    "    experiment.log_parameter(\"mask_size\", hypernet.mask_size)\n",
    "    experiment.log_parameter(\"lr\", optimizer.defaults['lr'])\n",
    "    experiment.log_parameter(\"training_size\", data_size)\n",
    "    experiment.log_parameter(\"masks_no\", masks_no)\n",
    "    experiment.log_parameter(\"max_epochs\", epochs)\n",
    "    experiment.log_parameter(\"check_val_every_n_epoch\", test_every)\n",
    "    \n",
    "    for k, v in log_params.items():\n",
    "        experiment.log_parameter(k, v)\n",
    "\n",
    "    trainloader, testloader = loaders\n",
    "    test_loss = []\n",
    "    test_accs = []\n",
    "    mask_idx = 0\n",
    "    with trange(epochs) as t:\n",
    "        for epoch in t:\n",
    "            hypernet.train()\n",
    "            for i, data in enumerate(trainloader):\n",
    "                try:\n",
    "                    inputs, labels, _ = data\n",
    "                except ValueError:\n",
    "                    inputs, labels = data\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                #Masks\n",
    "                masks = hypernet.test_mask[mask_idx].repeat(len(inputs), 1)\n",
    "                \n",
    "                #Principal components \n",
    "                pcs = hypernet.pcs[mask_idx].repeat(len(inputs), 1) if hasattr(hypernet, 'pcs') else None\n",
    "                \n",
    "                \n",
    "                mask_idx = (mask_idx+1) % len(hypernet.test_mask)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = hypernet(inputs, masks, pcs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            total_loss = 0\n",
    "            correct = 0\n",
    "            denom = 0\n",
    "\n",
    "            hypernet.eval()\n",
    "            if epoch%test_every==0:\n",
    "                for i, data in enumerate(testloader):\n",
    "                    try:\n",
    "                        images, labels, _ = data\n",
    "                    except ValueError:\n",
    "                        images, labels = data\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    denom += len(labels)\n",
    "\n",
    "                    outputs = hypernet(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "                    total_loss += criterion(outputs, labels).item()\n",
    "\n",
    "                test_loss.append(total_loss/denom)\n",
    "                test_accs.append(correct/denom*100)\n",
    "\n",
    "                t.set_postfix(test_acc=correct/denom*100, loss=total_loss/i)\n",
    "                experiment.log_metric(\"test_accuracy\", correct/len(testloader.dataset)*100, step=epoch)\n",
    "                experiment.log_metric(\"test_loss\", test_loss[-1], step=epoch)\n",
    "\n",
    "    experiment.end()    \n",
    "    return max(test_accs), test_loss[np.argmax(test_accs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823cc754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec000d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8c2df55",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd37710",
   "metadata": {},
   "source": [
    "### Setup for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afbc4d3",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59940b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fa50ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77a2b909",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5162270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = hp.semisl.get_train_test_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ce322f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3000\n",
    "\n",
    "masks_no = 100\n",
    "\n",
    "results = defaultdict(list)\n",
    "size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68697821",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k = 100 # has to be less or equal than masks_no\n",
    "\n",
    "lr = 3e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465b132b",
   "metadata": {},
   "source": [
    "### Test several components quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e6a4131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n",
      "hypernet.test_mask.shape torch.Size([100, 784])\n",
      "generated_masks.shape (100, 784)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.com/abulenok/hypernetwork/d096ff2f725740df8ec988ce57b360e5\n",
      "\n",
      " 90%|███████████████████████████████████████████████████████▋      | 2695/3000 [1:10:34<03:31,  1.44it/s, loss=1.77, test_acc=71]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████| 3000/3000 [1:10:54<00:00,  1.42s/it, loss=1.78, test_acc=70.5]\n",
      "COMET ERROR: Error sending a notification, make sure you have opted-in for notifications\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n"
     ]
    }
   ],
   "source": [
    "for k in [100, 50, 20, 10]:\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # seeds\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "    hypernet = Hypernetwork(\n",
    "        architecture=torch.nn.Sequential(\n",
    "            torch.nn.Linear(k, 64), \n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 128),\n",
    "        ),\n",
    "        target_architecture=[(mask_size, 100), (100, 10)],\n",
    "        test_nodes=masks_no,\n",
    "        mask_len=784\n",
    "    ).cuda()\n",
    "\n",
    "    hypernet._create_mask = None\n",
    "    generated_masks = np.array(hypernet.test_mask.cpu())\n",
    "\n",
    "    print('hypernet.test_mask.shape', hypernet.test_mask.shape)\n",
    "    print('generated_masks.shape', generated_masks.shape)\n",
    "\n",
    "    m = 2\n",
    "\n",
    "    # m = hp.lpca.select_m(generated_masks, ks=50)\n",
    "\n",
    "    pcs = hp.lpca.get_LPCs(generated_masks, k, m)\n",
    "\n",
    "    hypernet.pcs = torch.tensor(pcs).to(hypernet.device).float()\n",
    "\n",
    "\n",
    "    hypernet = hypernet.train()\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam(hypernet.parameters(), lr=lr)\n",
    "\n",
    "    # loaders\n",
    "    trainloader, testloader = hp.training_utils.get_dataset(size, test_batch_size=32)\n",
    "\n",
    "    res = train_with_pcs(\n",
    "        hypernet,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        (trainloader, testloader),\n",
    "        size,\n",
    "        epochs,\n",
    "        masks_no,\n",
    "        tag='lpca-init-grid-search',\n",
    "        test_every=5,\n",
    "        log_params={\n",
    "            'k':k,\n",
    "            'seed': seed,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c97954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2880c4af",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "644c2989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n",
      "hypernet.test_mask.shape torch.Size([100, 784])\n",
      "generated_masks.shape (100, 784)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.com/abulenok/hypernetwork/1b8720ee74bc41b9b0a0ca17ca66d8c7\n",
      "\n",
      " 83%|███████████████████████████████████████████████████▌          | 2496/3000 [59:05<21:45,  2.59s/it, loss=1.78, test_acc=71.2]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# seeds\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "\n",
    "hypernet = Hypernetwork(\n",
    "    architecture=torch.nn.Sequential(\n",
    "        torch.nn.Linear(784, 64), \n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(64, 256),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(256, 128),\n",
    "    ),\n",
    "    target_architecture=[(mask_size, 100), (100, 10)],\n",
    "    test_nodes=masks_no,\n",
    ").cuda()\n",
    "\n",
    "hypernet._create_mask = None\n",
    "generated_masks = np.array(hypernet.test_mask.cpu())\n",
    "\n",
    "print('hypernet.test_mask.shape', hypernet.test_mask.shape)\n",
    "print('generated_masks.shape', generated_masks.shape)\n",
    "\n",
    "hypernet = hypernet.train()\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(hypernet.parameters(), lr=lr)\n",
    "\n",
    "# loaders\n",
    "trainloader, testloader = hp.training_utils.get_dataset(size, test_batch_size=32)\n",
    "\n",
    "res = train_with_pcs(\n",
    "    hypernet,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    (trainloader, testloader),\n",
    "    size,\n",
    "    epochs,\n",
    "    masks_no,\n",
    "    tag='lpca-init-grid-search',\n",
    "    test_every=5,\n",
    "    log_params={\n",
    "        'k': 'none',\n",
    "        'seed': seed,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bd335d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fcb953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149b40e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

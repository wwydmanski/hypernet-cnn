{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01de83ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc12a648-b80a-4eca-afc3-79331e4db7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fdadf44-450a-4006-ac5a-bed9840409f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from tqdm import trange\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import sklearn\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "plt.style.use(\"seaborn\")\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbdec3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7585d3a-dff3-43e2-bc0f-f024306021a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a37b70c-292b-4c14-85ed-3c93020dc182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3085114d-cf61-4625-97c5-10f34c00d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabular_hypernet import HypernetworkPCA, TrainingModes, Hypernetwork\n",
    "from tabular_hypernet.modules import SimpleNetwork\n",
    "from tabular_hypernet.training_utils import train_slow_step, train_model, train_carthesian\n",
    "from tabular_hypernet.interfaces import HypernetworkSklearnInterface, SimpleSklearnInterface\n",
    "# from ipynb.fs.defs.MNIST_benchmark import test_model\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d62c6026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c014884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f84a62eb-e16d-4519-ad76-2237037833c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d12953cc-1ec5-46a9-933a-714e5ceafd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from loguru import logger\n",
    "\n",
    "logger.add(\"log_Lymf.txt\", format='{time:YYYY-MM-DD HH:mm:ss.SSS} | {message}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa3c18d1-1d56-4393-9441-245420fb3c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04d1ae25-987c-4043-9771-829c928723de",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE=\"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a1a1e98-a8b4-4df2-aae6-b593fe61667a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from loguru import logger\n",
    "\n",
    "logger.add(\"log.txt\", format='{time:YYYY-MM-DD HH:mm:ss.SSS} | {message}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81b884da",
   "metadata": {},
   "outputs": [],
   "source": [
    "GS_METRIC = \"balanced_accuracy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82db70f7",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7add86f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = \"cnae\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba2d025f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 855) 9\n"
     ]
    }
   ],
   "source": [
    "if DATA == \"cnae\":\n",
    "    cnae = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00233/CNAE-9.data', header=None)\n",
    "    cnae = cnae.drop(1, axis=1)\n",
    "    X = cnae.values[:, 1:].astype(float)\n",
    "    y = cnae.values[:, 0]\n",
    "    y = LabelEncoder().fit_transform(y).astype(int)\n",
    "    #(1080, 855) 2\n",
    "\n",
    "print(X.shape, len(np.unique(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c587b420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e85869a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = len(np.unique(y if not isinstance(y, tuple) else y_train))\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6305ff4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 120, 1: 120, 2: 120, 3: 120, 4: 120, 5: 120, 6: 120, 7: 120, 8: 120}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y if not isinstance(y, tuple) else y_train, return_counts=True)\n",
    "\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe2c8e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "855"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = X.shape[1] if not isinstance(X, tuple) else X_train.shape[1]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4777a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = int(len(X)*0.7) if not isinstance(X, tuple) else len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e7a0ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "756"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38876ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('dataset size:', len(X), '|', 'max training size:', max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30a5727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RUN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507c32bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa56e0fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b77cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c287f46",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bdc5ffdd-e04d-425f-8d6c-bd8456644faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "def prepare_data(X, y, size=None):\n",
    "    if isinstance(X, tuple) and isinstance(y, tuple):\n",
    "        X_train, X_test = X\n",
    "        y_train, y_test = y\n",
    "    else:    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=size, stratify=y)\n",
    "    # X_train, y_train = imblearn.over_sampling.RandomOverSampler(random_state=42).fit_resample(X_train, y_train)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = [torch.from_numpy(x) for x in [X_train, X_test, y_train, y_test]]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca0a827a-0e1f-4f5c-b15d-3354f075021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data(X, y, size=max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281d7f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d223075b-b7d8-414e-97c9-ade8bda5f0fd",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9f92f86-4c40-492c-8d48-f23efa85eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5aa90ca0-8a00-4491-b111-ce7eee0e9c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _summarize_results(y_pred, y_score, y_test, labels):\n",
    "    results = []\n",
    "    for idx, label in enumerate(labels):\n",
    "        y_pred_filt = y_pred[y_test==idx]\n",
    "        y_test_filt = y_test[y_test==idx]\n",
    "        acc = (y_pred_filt==y_test_filt.numpy()).sum()/len(y_test_filt)*100\n",
    "        results.append({\n",
    "            \"Class\": label,\n",
    "            \"Metric\": acc\n",
    "        })\n",
    "        \n",
    "    acc = (y_pred==y_test.numpy()).sum()/len(y_test)*100    \n",
    "    results.append({\n",
    "        \"Class\": \"Total\",\n",
    "        \"Metric\": acc\n",
    "    })\n",
    "    \n",
    "    \n",
    "    results.append({\n",
    "        \"Class\": \"balanced_accuracy\",\n",
    "        \"Metric\": balanced_accuracy_score(y_test, torch.from_numpy(y_pred)).item()*100\n",
    "    })\n",
    "    \n",
    "    try:\n",
    "        results.append({\n",
    "            \"Class\": \"F1 score\",\n",
    "            \"Metric\": f1_score(y_test, torch.from_numpy(y_pred)).item()*100\n",
    "        })\n",
    "        results.append({\n",
    "            \"Class\": \"roc_auc\",\n",
    "            \"Metric\": roc_auc_score(y_test, torch.from_numpy(y_score[:, 1])).item()*100\n",
    "        })\n",
    "        results.append({\n",
    "            \"Class\": \"Precision\",\n",
    "            \"Metric\": precision_score(y_test, torch.from_numpy(y_pred)).item()*100\n",
    "        })\n",
    "        results.append({\n",
    "            \"Class\": \"Recall\",\n",
    "            \"Metric\": recall_score(y_test, torch.from_numpy(y_pred)).item()*100\n",
    "        })\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return results\n",
    "\n",
    "def test_model(model_fn, data, train_size, label_encoder=None, iters=10, as_numpy=False):\n",
    "    if TEST_RUN:\n",
    "        iters = 1\n",
    "        \n",
    "    if label_encoder is not None:\n",
    "        labels = label_encoder.classes_\n",
    "    else:\n",
    "        labels = sorted(pd.unique(data[1][0] if isinstance(data[1], tuple) else data[1]))\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for i in range(iters):\n",
    "        print('iter', i+1, 'of', iters)\n",
    "        X_train, X_test, y_train, y_test = prepare_data(*data, train_size)\n",
    "        \n",
    "        model = model_fn()\n",
    "\n",
    "        if as_numpy:\n",
    "            model.fit(X_train.numpy(), y_train.numpy());\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        y_score = model.predict_proba(X_test)\n",
    "        results.extend(_summarize_results(y_pred, y_score, y_test, labels))\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    dframe = pd.DataFrame.from_dict(results)\n",
    "#     sns.violinplot(data=dframe[dframe[\"Class\"]!=\"Loss\"], y=\"Class\", x=\"Metric\", orient='h')\n",
    "    return dframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f351cf",
   "metadata": {},
   "source": [
    "### Param search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a95790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ecee618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyhopper_best_params(model_fn, param_grid, data_size=max_size, metric=GS_METRIC, time=\"30m\", default_params={}, n_jobs=1):\n",
    "    if TEST_RUN:\n",
    "        time = 30\n",
    "        if 'epochs' in param_grid:\n",
    "            param_grid[\"epochs\"] = pyhopper.choice([10])\n",
    "        \n",
    "    logger.info(f\"pyhopper_best_params {model_fn.__name__}\")\n",
    "    \n",
    "    def objective(params):\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        model_results = test_model(\n",
    "                        model_fn(\n",
    "                            **default_params,\n",
    "                            **params\n",
    "                        ),\n",
    "                        (X, y),\n",
    "                        data_size,\n",
    "                        None, 5)\n",
    "        with open(f\"{DATA}_{model_fn.__name__}_params.txt\", \"a\") as f:\n",
    "            f.write(str(datetime.datetime.now()) + \", \" + str(params) + \", \" + str(model_results[model_results[\"Class\"]==metric][\"Metric\"].mean()) + \"\\n\")\n",
    "        return model_results[model_results[\"Class\"]==metric][\"Metric\"].mean()\n",
    "\n",
    "    from pyhopper.callbacks import History\n",
    "    search = pyhopper.Search(param_grid)\n",
    "\n",
    "    best_params = search.run(objective, \"maximize\", time, n_jobs=n_jobs, seeding_ratio=0.5)\n",
    "    \n",
    "    with open(f\"{DATA}_{model_fn.__name__}_best_params.txt\", \"a\") as f:\n",
    "            f.write(str(best_params))\n",
    "    \n",
    "    print(f\"{DATA}_{model_fn.__name__}_{best_params}\")\n",
    "    return best_params, search.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f3796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228c7d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9cebfb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_best = {'n_estimators': 2650, 'max_depth': 15, 'learning_rate': 0.0034326936147232585, \n",
    "                'min_child_weight': 1, 'gamma': 0.1, \n",
    "                'subsample': 0.7, 'reg_lambda': 1.4511825415327815, 'reg_alpha': 0.019404822808488445}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1145d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_best = {'layer_dim': 256, 'num_layers': 4, 'depth': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f4386a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_fn1_best_params = {'epochs': 100, 'drop1': 0.5, 'drop2': 0.7, 'lr': 0.0003, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "177de588",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_fn2_best_params = {'epochs': 100, 'drop1': 0.5, 'drop2': 0.1, 'drop3': 0.7, 'lr': 0.0003, 'batch_size': 64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09ca526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_fn3_best_params = {'epochs': 150, 'drop1': 0.3, 'drop2': 0.5, 'drop3': 0.7, \n",
    "                      'drop4': 0.7, 'lr': 0.0003, 'batch_size': 32}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e271cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_pca_best_params = {'epochs': 100, 'masks_no': 50, 'mask_size': 400, \n",
    "                      'target_size': 50, 'n_comp': 3, 'lr': 3e-05, 'batch_size': 32}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dade8b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_best_params = {'epochs': 100, 'masks_no': 50, 'mask_size': 400, 'target_size': 50, 'lr': 3e-05, 'batch_size': 32}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c24d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = {'n_estimators': 1700, 'max_features': 'sqrt', 'criterion': 'gini', 'max_depth': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db460f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20f51db3",
   "metadata": {},
   "source": [
    "# TRAIN MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf59445b-c0f0-4ee7-bfe9-5c8a57c22b86",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aacc321b-420a-47f3-88af-6bb02aa0ddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50c27ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "xgboost.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "63e24c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xgboost(**params):\n",
    "    random_seed = np.random.randint(1024)\n",
    "    def _inner(**args):\n",
    "        return XGBClassifier(\n",
    "            verbosity=0,\n",
    "            random_state=random_seed,\n",
    "            use_label_encoder=False,\n",
    "            **params,\n",
    "            **args\n",
    "        )\n",
    "    return _inner    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8213082c",
   "metadata": {},
   "source": [
    "#### Hyperparam tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da7af406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 17:47:31.044 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params get_xgboost\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a44b1eaa2549019a80572d3d507707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 01:30:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 85.93  : 1     : 01:30 (m:s)     \n",
      "Random seeding    : 90.31  : 16    : 47:23 (m:s)     \n",
      "Local sampling    : 91.48  : 7     : 40:23 (m:s)     \n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 91.48  : 24    : 01:29:16 (h:m:s)\n",
      "=====================================================\n",
      "cnae_get_xgboost_{'n_estimators': 2650, 'max_depth': 15, 'learning_rate': 0.0034326936147232585, 'min_child_weight': 1, 'gamma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "                'n_estimators': pyhopper.int(50, 3000, multiple_of=50),\n",
    "                'max_depth': pyhopper.choice([2, 3, 5, 10, 15]),\n",
    "                'learning_rate': pyhopper.float(1e-5,1e-1, log=True),\n",
    "                'min_child_weight': pyhopper.choice([1, 2, 4, 8, 16, 32]),\n",
    "                'gamma': pyhopper.choice([0, 0.001, 0.1, 1]),\n",
    "             }\n",
    "\n",
    "xgbt_best1, xgbt_history1 = pyhopper_best_params(get_xgboost, param_grid, time=\"90m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d8fb3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "858bc970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 19:16:47.275 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params get_xgboost\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1691d73336a645daa8e6e23462946e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 01:30:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 91.11  : 1     : 08:42 (m:s)     \n",
      "Random seeding    : 91.42  : 5     : 42:15 (m:s)     \n",
      "Local sampling    : 91.85  : 4     : 32:42 (m:s)     \n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 91.85  : 10    : 01:23:39 (h:m:s)\n",
      "=====================================================\n",
      "cnae_get_xgboost_{'subsample': 0.7, 'reg_lambda': 1.4511825415327815, 'reg_alpha': 0.019404822808488445}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "                'subsample': pyhopper.choice([0.5, 0.6, 0.7, 0.8, 0.9, 1]),\n",
    "                'reg_lambda': pyhopper.float(1e-5, 10, init=0, log=True),\n",
    "                'reg_alpha': pyhopper.float(1e-5, 10, init=0, log=True),\n",
    "             }\n",
    "\n",
    "\n",
    "xgbt_best2, xgbt_history2 = pyhopper_best_params(get_xgboost, param_grid, time=\"90m\", default_params=xgbt_best1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fb0f7b",
   "metadata": {},
   "source": [
    "#### Best Params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2aa500",
   "metadata": {},
   "source": [
    "'Ionosphere' {'gamma': 0, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 1500}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "511d7466",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_best = {**xgbt_best1, **xgbt_best2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5cedd88-43b4-465c-b1e1-6a0b620ae73a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 10\n",
      "iter 2 of 10\n",
      "iter 3 of 10\n",
      "iter 4 of 10\n",
      "iter 5 of 10\n",
      "iter 6 of 10\n",
      "iter 7 of 10\n",
      "iter 8 of 10\n",
      "iter 9 of 10\n",
      "iter 10 of 10\n"
     ]
    }
   ],
   "source": [
    "data_size = max_size\n",
    "\n",
    "xgb_dframe = test_model(get_xgboost(**xgboost_best),\n",
    "                        (X, y),\n",
    "                        data_size,\n",
    "                        label_encoder=None, iters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f530a0df-271a-495f-b49d-2cffe523c328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756: 90.49 ~ 2.05 (max: 94.44)\n"
     ]
    }
   ],
   "source": [
    "res = xgb_dframe[xgb_dframe[\"Class\"]==\"Total\"].reset_index(drop=True)[\"Metric\"]\n",
    "print(f\"{data_size}: {res.mean():.2f} ~ {res.std():.2f} (max: {res.max():.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e53148cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>87.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>91.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>96.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>82.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>91.311728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>91.311728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Metric\n",
       "Class                       \n",
       "0                  94.305556\n",
       "1                  92.777778\n",
       "2                  93.055556\n",
       "3                  85.972222\n",
       "4                  97.500000\n",
       "5                  87.500000\n",
       "6                  91.527778\n",
       "7                  96.527778\n",
       "8                  82.638889\n",
       "Total              91.311728\n",
       "balanced_accuracy  91.311728"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_dframe.groupby(['Class']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08dcdab-2c4b-4a05-822b-912037488763",
   "metadata": {},
   "source": [
    "### NODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "64d10cad-57b5-488c-9a94-63259bd0c13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qhoptim.pyt import QHAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "806be7a7-e4c8-4525-a38f-9ae16a3bd229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_fn(layer_dim=128, num_layers=1, depth=3):\n",
    "    def _inner():\n",
    "        network = torch.nn.Sequential(\n",
    "            node.DenseBlock(X_train.shape[1], \n",
    "                            layer_dim=layer_dim,\n",
    "                            num_layers=num_layers, \n",
    "                            tree_dim=n_classes+1, \n",
    "                            depth=depth, \n",
    "                            flatten_output=False,\n",
    "                            choice_function=node.entmax15, \n",
    "                            bin_function=node.entmoid15\n",
    "                           ),\n",
    "            node.Lambda(lambda x: x.mean(dim=1))\n",
    "        )\n",
    "        \n",
    "        \n",
    "        network = network.to(DEVICE)\n",
    "        network.device=DEVICE\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            res = network(torch.as_tensor(X_train, device=DEVICE).to(torch.float32))\n",
    "        \n",
    "            \n",
    "        optimizer_params = { 'nus':(0.7, 1.0), 'betas':(0.95, 0.998) }\n",
    "        optim = QHAdam(network.parameters(), **optimizer_params)\n",
    "            \n",
    "        network = SimpleSklearnInterface(network, device=DEVICE, epochs=150, batch_size=32)\n",
    "        network.optimizer = optim\n",
    "        return network\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d404841f",
   "metadata": {},
   "source": [
    "#### Tune hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "816a242b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 12:22:53.004 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params node_fn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8044b7246b9d416b8189e5c8159df91f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 03:00:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 95.86  : 1     : 05:46 (m:s)     \n",
      "Random seeding    : 95.99  : 6     : 01:39:10 (h:m:s)\n",
      "Local sampling    : 95.99  : 5     : 01:02:51 (h:m:s)\n",
      "Duplicates        : -      : 4     : -               \n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 95.99  : 16    : 02:47:46 (h:m:s)\n",
      "=====================================================\n",
      "cnae_node_fn_{'layer_dim': 256, 'num_layers': 4, 'depth': 5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'layer_dim': 256, 'num_layers': 4, 'depth': 5}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'layer_dim': hp.quniform('layer_dim', 100, 1200, 100),\n",
    "# 'num_layers': hp.quniform('num_layers', 1, 4, 1),\n",
    "# 'depth': hp.quniform('depth', 2, 7, 1)\n",
    "                    \n",
    "param_grid = {\n",
    "    'layer_dim': pyhopper.int(64, 512, power_of=2), #1024\n",
    "    'num_layers': pyhopper.int(1, 5),\n",
    "    'depth': pyhopper.int(2, 7),\n",
    "}\n",
    "\n",
    "node_best, node_history = pyhopper_best_params(node_fn, param_grid, time=\"180m\", n_jobs=1)\n",
    "node_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8e91b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7772daf",
   "metadata": {},
   "source": [
    "#### Use best hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f6e447c1-63a6-4c90-b22e-5e0852817f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 10\n",
      "iter 2 of 10\n",
      "iter 3 of 10\n",
      "iter 4 of 10\n",
      "iter 5 of 10\n",
      "iter 6 of 10\n",
      "iter 7 of 10\n",
      "iter 8 of 10\n",
      "iter 9 of 10\n",
      "iter 10 of 10\n",
      "756: nan ~ nan, (max: nan)\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "size=max_size\n",
    "\n",
    "node_results = test_model(node_fn(**node_best),\n",
    "                    (X, y),\n",
    "                    size,\n",
    "                    label_encoder=None, iters=10)\n",
    "res = node_results[node_results[\"Class\"]==\"roc_auc\"].reset_index(drop=True)[\"Metric\"]\n",
    "print(f\"{size}: {res.mean():.2f} ~ {res.std():.2f}, (max: {res.max():.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8437ea73-72bf-4b18-94d4-eb58a8da9792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d696b0-f5b6-4508-9fff-5166fad29e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "753c2e4d-aca4-4eb1-b3ea-a1926fd44efe",
   "metadata": {},
   "source": [
    "### Dropout Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c97f270-5e57-4cea-b2f1-3204451b0f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_fn1(epochs=100, drop1=0.3, drop2=0.5, batch_size=32, lr=3e-4):\n",
    "    \n",
    "    def _inner():\n",
    "        network = torch.nn.Sequential(\n",
    "                        torch.nn.Dropout(drop1),\n",
    "                        torch.nn.Linear(n_features, 64),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout(drop2),\n",
    "                        torch.nn.Linear(64, n_classes)\n",
    "                    ).to(DEVICE).train()\n",
    "\n",
    "        network = SimpleSklearnInterface(network, epochs=epochs, batch_size=batch_size, lr=lr)\n",
    "        return network\n",
    "    return _inner\n",
    "\n",
    "\n",
    "\n",
    "def network_fn2(epochs=100, drop1=0.3, drop2=0.5, drop3=0.5, batch_size=32, lr=3e-4):\n",
    "    \n",
    "    def _inner():\n",
    "        network = torch.nn.Sequential(\n",
    "                        torch.nn.Dropout(drop1),\n",
    "                        torch.nn.Linear(n_features, 64),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout(drop2),\n",
    "                        torch.nn.Linear(64, 64),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout(drop3),\n",
    "                        torch.nn.Linear(64, n_classes)\n",
    "                    ).to(DEVICE).train()\n",
    "\n",
    "        network = SimpleSklearnInterface(network, epochs=epochs, batch_size=batch_size, lr=lr)\n",
    "        return network\n",
    "    return _inner\n",
    "\n",
    "\n",
    "\n",
    "def network_fn3(epochs=100, drop1=0.3, drop2=0.5, drop3=0.5, drop4=0.5, batch_size=32, lr=3e-4):\n",
    "    \n",
    "    def _inner():\n",
    "        network = torch.nn.Sequential(\n",
    "                        torch.nn.Dropout(drop1),\n",
    "                        torch.nn.Linear(n_features, 64),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout(drop2),\n",
    "                        torch.nn.Linear(64, 128),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout(drop3),\n",
    "                        torch.nn.Linear(128, 64),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout(drop4),\n",
    "                        torch.nn.Linear(64, n_classes)\n",
    "                    ).to(DEVICE).train()\n",
    "\n",
    "        network = SimpleSklearnInterface(network, epochs=epochs, batch_size=batch_size, lr=lr)\n",
    "        return network\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7bb2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64652732",
   "metadata": {},
   "source": [
    "#### Find Hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256e43a3",
   "metadata": {},
   "source": [
    "### Dropout 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41850a57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 16:12:27.803 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params network_fn1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a395f41174d4cc8899dfcf6570e3712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 01:00:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "==================== Summary ===================\n",
      "Mode              : Best f : Steps : Time       \n",
      "----------------  : ----   : ----  : ----       \n",
      "Initial solution  : 92.47  : 1     : 01:44 (m:s)\n",
      "Random seeding    : 95.62  : 14    : 28:26 (m:s)\n",
      "Local sampling    : 95.68  : 15    : 28:42 (m:s)\n",
      "Duplicates        : -      : 10    : -          \n",
      "----------------  : ----   : ----  : ----       \n",
      "Total             : 95.68  : 40    : 58:53 (m:s)\n",
      "================================================\n",
      "cnae_network_fn1_{'epochs': 100, 'drop1': 0.5, 'drop2': 0.7, 'lr': 0.0003, 'batch_size': 32}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs': 100, 'drop1': 0.5, 'drop2': 0.7, 'lr': 0.0003, 'batch_size': 32}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "                \"epochs\": pyhopper.choice([100, 150]),\n",
    "                \"drop1\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"drop2\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"lr\": pyhopper.choice([3e-5, 3e-4, 3e-3, 3e-2, 3e-1]),\n",
    "                \"batch_size\": pyhopper.choice([32, 64]),\n",
    "             }\n",
    "\n",
    "nn_fn1_best_params, nn_fn1_history = pyhopper_best_params(network_fn1, param_grid, time=\"60m\")\n",
    "nn_fn1_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b0143ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 10\n",
      "iter 2 of 10\n",
      "iter 3 of 10\n",
      "iter 4 of 10\n",
      "iter 5 of 10\n",
      "iter 6 of 10\n",
      "iter 7 of 10\n",
      "iter 8 of 10\n",
      "iter 9 of 10\n",
      "iter 10 of 10\n"
     ]
    }
   ],
   "source": [
    "data_size = max_size\n",
    "\n",
    "nn1_results = test_model(network_fn1(**nn_fn1_best_params),\n",
    "                (X, y),\n",
    "                data_size,\n",
    "                None, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb03b139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756: nan ~ nan (max: nan)\n"
     ]
    }
   ],
   "source": [
    "res = nn1_results[nn1_results[\"Class\"]==\"Balanced Acc score\"][\"Metric\"]\n",
    "print(f\"{data_size}: {res.mean():.2f} ~ {res.std():.2f} (max: {res.max():.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc25ca37",
   "metadata": {},
   "source": [
    "### Dropout 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ded59e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 17:17:56.668 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params network_fn2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47bf740c732c42b0a7c6d3559167bf02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 01:10:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 90.68  : 1     : 01:43 (m:s)     \n",
      "Random seeding    : 95.49  : 19    : 35:36 (m:s)     \n",
      "Local sampling    : 95.43  : 16    : 31:25 (m:s)     \n",
      "Duplicates        : -      : 10    : -               \n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 95.49  : 46    : 01:08:44 (h:m:s)\n",
      "=====================================================\n",
      "cnae_network_fn2_{'epochs': 100, 'drop1': 0.5, 'drop2': 0.1, 'drop3': 0.7, 'lr': 0.0003, 'batch_size': 64}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs': 100,\n",
       " 'drop1': 0.5,\n",
       " 'drop2': 0.1,\n",
       " 'drop3': 0.7,\n",
       " 'lr': 0.0003,\n",
       " 'batch_size': 64}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "                \"epochs\": pyhopper.choice([100, 150]),\n",
    "                \"drop1\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"drop2\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"drop3\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"lr\": pyhopper.choice([3e-5, 3e-4, 3e-3, 3e-2, 3e-1]),\n",
    "                \"batch_size\": pyhopper.choice([32, 64]),\n",
    "             }\n",
    "\n",
    "nn_fn2_best_params, nn_fn2_history = pyhopper_best_params(network_fn2, param_grid, time=\"70m\")\n",
    "nn_fn2_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "326bbde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 10\n",
      "iter 2 of 10\n",
      "iter 3 of 10\n",
      "iter 4 of 10\n",
      "iter 5 of 10\n",
      "iter 6 of 10\n",
      "iter 7 of 10\n",
      "iter 8 of 10\n",
      "iter 9 of 10\n",
      "iter 10 of 10\n"
     ]
    }
   ],
   "source": [
    "data_size = max_size\n",
    "\n",
    "nn2_results = test_model(network_fn2(**nn_fn2_best_params),\n",
    "                (X, y),\n",
    "                data_size,\n",
    "                None, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8349efaf",
   "metadata": {},
   "source": [
    "### Dropout 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5321d73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 18:32:42.853 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params network_fn3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b13c0b21fab4255bc1a6190c4189c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 01:15:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 90.74  : 1     : 01:50 (m:s)     \n",
      "Random seeding    : 95.8   : 18    : 36:42 (m:s)     \n",
      "Local sampling    : 95.68  : 15    : 34:43 (m:s)     \n",
      "Duplicates        : -      : 6     : -               \n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 95.8   : 40    : 01:13:14 (h:m:s)\n",
      "=====================================================\n",
      "cnae_network_fn3_{'epochs': 150, 'drop1': 0.3, 'drop2': 0.5, 'drop3': 0.7, 'drop4': 0.7, 'lr': 0.0003, 'batch_size': 32}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs': 150,\n",
       " 'drop1': 0.3,\n",
       " 'drop2': 0.5,\n",
       " 'drop3': 0.7,\n",
       " 'drop4': 0.7,\n",
       " 'lr': 0.0003,\n",
       " 'batch_size': 32}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "                \"epochs\": pyhopper.choice([100, 150]),\n",
    "                \"drop1\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"drop2\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"drop3\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"drop4\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"lr\": pyhopper.choice([3e-5, 3e-4, 3e-3, 3e-2, 3e-1]),\n",
    "                \"batch_size\": pyhopper.choice([32, 64]),\n",
    "             }\n",
    "\n",
    "nn_fn3_best_params, nn_fn3_history = pyhopper_best_params(network_fn3, param_grid, time=\"75m\")\n",
    "nn_fn3_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa8b864e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 10\n",
      "iter 2 of 10\n",
      "iter 3 of 10\n",
      "iter 4 of 10\n",
      "iter 5 of 10\n",
      "iter 6 of 10\n",
      "iter 7 of 10\n",
      "iter 8 of 10\n",
      "iter 9 of 10\n",
      "iter 10 of 10\n"
     ]
    }
   ],
   "source": [
    "data_size = max_size\n",
    "\n",
    "nn3_results = test_model(network_fn3(**nn_fn3_best_params),\n",
    "                (X, y),\n",
    "                data_size,\n",
    "                None, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb86765-3874-4023-8e26-b40ccc6df903",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933db2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d60779d-0042-49af-8a32-e6d0b59e1589",
   "metadata": {
    "tags": []
   },
   "source": [
    "### HypernetworkPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6e5536d6-cf9d-4a2b-9d7b-184c0ac27a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_pca_fn(epochs=100, masks_no=100, mask_size=100, target_size=100, n_comp=5, lr=3e-4, batch_size=64, verbose=False):\n",
    "    def _inner():\n",
    "        hypernet = HypernetworkPCA(\n",
    "                        target_architecture=[(mask_size, target_size), (target_size, n_classes)], \n",
    "                        test_nodes=masks_no,\n",
    "                        architecture=torch.nn.Sequential(torch.nn.Linear(n_comp, 64), \n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(64, 128),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Dropout(),\n",
    "                            torch.nn.Linear(128, 128),\n",
    "                            torch.nn.ReLU(),\n",
    "                        ),\n",
    "                        mode=TrainingModes.CARTHESIAN,\n",
    "                        input_size=n_features\n",
    "                    ).to(DEVICE)    \n",
    "        hypernet = hypernet.train()\n",
    "\n",
    "        network = HypernetworkSklearnInterface(hypernet, device=DEVICE, epochs=epochs, batch_size=batch_size, verbose=verbose, lr=lr)\n",
    "        return network\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1e43b7af-9be5-427a-be2e-4f134ba1e644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_to_html():\n",
    "    tmpfile = BytesIO()\n",
    "    plt.gcf().savefig(tmpfile, format='png')\n",
    "    encoded = base64.b64encode(tmpfile.getvalue()).decode('utf-8')\n",
    "\n",
    "    html = '<img src=\\'data:image/png;base64,{}\\'>'.format(encoded)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a257e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be2e5638-be6d-4a42-8eb4-be84078643bb",
   "metadata": {},
   "source": [
    "#### Find hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "45f2e4fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 19:56:50.812 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params network_pca_fn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c121208dc9344f3ac24b389b59616cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 08:00:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 13.7   : 1     : 42:14 (m:s)     \n",
      "Random seeding    : 86.48  : 4     : 04:55:18 (h:m:s)\n",
      "Local sampling    : 80.68  : 2     : 01:46:22 (h:m:s)\n",
      "Duplicates        : -      : 1     : -               \n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 86.48  : 8     : 07:23:54 (h:m:s)\n",
      "=====================================================\n",
      "cnae_network_pca_fn_{'epochs': 100, 'masks_no': 200, 'mask_size': 200, 'target_size': 50, 'n_comp': 3, 'lr': 3e-05, 'batch_size': 32}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs': 100,\n",
       " 'masks_no': 200,\n",
       " 'mask_size': 200,\n",
       " 'target_size': 50,\n",
       " 'n_comp': 3,\n",
       " 'lr': 3e-05,\n",
       " 'batch_size': 32}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"epochs\": pyhopper.choice([100]),\n",
    "    \"masks_no\": pyhopper.choice([100, 150, 200, 300, 500]),#pyhopper.int(50, 200, multiple_of=10),\n",
    "    \"mask_size\": pyhopper.choice([5, 10, 20, 50, 100, 200, 400]),\n",
    "    \"target_size\": pyhopper.choice([5, 10, 20, 50]),\n",
    "    \"n_comp\": pyhopper.choice([3, 10, 25, 50, 80]),\n",
    "    \"lr\": pyhopper.choice([3e-5, 3e-4, 3e-3, 3e-2, 3e-1]),\n",
    "    \"batch_size\": pyhopper.choice([32, 64]),\n",
    "\n",
    "}\n",
    "\n",
    "hp_pca_best_params, hp_pca_history = pyhopper_best_params(network_pca_fn, param_grid, time=\"480m\")\n",
    "hp_pca_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9569bae-98d8-4d2b-9643-3e57fe6bdcbf",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "df7c4b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 100,\n",
       " 'masks_no': 50,\n",
       " 'mask_size': 400,\n",
       " 'target_size': 50,\n",
       " 'n_comp': 3,\n",
       " 'lr': 3e-05,\n",
       " 'batch_size': 32}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_pca_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa4f868",
   "metadata": {},
   "source": [
    "'Libras'\n",
    "{'epochs': 150,\n",
    " 'masks_no': 70,\n",
    " 'mask_size': 20,\n",
    " 'target_size': 10,\n",
    " 'n_comp': 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8454fdc",
   "metadata": {},
   "source": [
    "'Lymphography' {'epochs': 120, 'masks_no': 50, 'mask_size': 4, 'target_size': 20, 'n_comp': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81b7e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803eafa7",
   "metadata": {},
   "source": [
    "Ionosphere\n",
    "{'epochs': 100, 'masks_no': 60, 'mask_size': 5, 'target_size': 10}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f5b3a72c-14cf-4d70-bb83-1f0a8aad5144",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 10\n",
      "torch.Size([1, 128])\n",
      "855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:50<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 10\n",
      "torch.Size([1, 128])\n",
      "855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:49<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 10\n",
      "torch.Size([1, 128])\n",
      "855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:49<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 10\n",
      "torch.Size([1, 128])\n",
      "855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:49<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 10\n",
      "torch.Size([1, 128])\n",
      "855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:50<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 6 of 10\n",
      "torch.Size([1, 128])\n",
      "855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:50<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 7 of 10\n",
      "torch.Size([1, 128])\n",
      "855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:49<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 8 of 10\n",
      "torch.Size([1, 128])\n",
      "855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:49<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 9 of 10\n",
      "torch.Size([1, 128])\n",
      "855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:50<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 10 of 10\n",
      "torch.Size([1, 128])\n",
      "855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:50<00:00,  1.70s/it]\n"
     ]
    }
   ],
   "source": [
    "epochs = 100#hp_pca_best_params['epochs']\n",
    "masks_no = hp_pca_best_params['masks_no']\n",
    "mask_size = hp_pca_best_params['mask_size']\n",
    "target_size = hp_pca_best_params['target_size']\n",
    "n_comp = hp_pca_best_params['n_comp']\n",
    "lr = hp_pca_best_params['lr']\n",
    "batch_size = hp_pca_best_params['batch_size']\n",
    "data_size = max_size\n",
    "\n",
    "nn_pca_results = test_model(network_pca_fn(target_size=target_size, mask_size=mask_size, masks_no=masks_no, n_comp=n_comp, epochs=epochs, verbose=True),\n",
    "                (X, y),\n",
    "                data_size,\n",
    "                None, 10)\n",
    "\n",
    "# exp.log_table(\"metrics.csv\", nn_pca_results.groupby(\"Class\").mean())\n",
    "# exp.log_metric(\"f1_score\", nn_pca_results.groupby(\"Class\").mean().loc[\"F1 score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b950280b-188d-4321-8db6-9cb69912a242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756: 94.97 ~ 0.97 (max: 96.60)\n"
     ]
    }
   ],
   "source": [
    "res = nn_pca_results[nn_pca_results[\"Class\"]==\"Total\"].reset_index(drop=True)[\"Metric\"]\n",
    "print(f\"{data_size}: {res.mean():.2f} ~ {res.std():.2f} (max: {res.max():.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6e0de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d82e3c9a-94c1-4984-a311-e0091c453333",
   "metadata": {},
   "source": [
    "### Hypernetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f81bdd75-482c-47ee-a9b3-4c2348f3b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_hp_fn(epochs=150, masks_no=100, mask_size=100, target_size=100, lr=3e-4, batch_size=64, verbose=False):\n",
    "    def _inner():\n",
    "        hypernet = Hypernetwork(\n",
    "                        target_architecture=[(mask_size, target_size), (target_size, n_classes)],\n",
    "                        test_nodes=masks_no,\n",
    "                        architecture=torch.nn.Sequential(torch.nn.Linear(n_features, 64), \n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(64, 128),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Dropout(),\n",
    "                            torch.nn.Linear(128, 128),\n",
    "                            torch.nn.ReLU(),\n",
    "                        ),\n",
    "                        mode=TrainingModes.CARTHESIAN,\n",
    "                    ).to(DEVICE)    \n",
    "        hypernet = hypernet.train()\n",
    "\n",
    "        network = HypernetworkSklearnInterface(hypernet, device=DEVICE, epochs=epochs, batch_size=batch_size, verbose=verbose, lr=lr)\n",
    "        return network\n",
    "    return _inner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76e319a",
   "metadata": {},
   "source": [
    "#### Find hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5235e59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 04:45:22.501 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params network_hp_fn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd44c88596794ecf91a7dcb0a5115131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 08:00:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 23.64  : 1     : 06:16 (m:s)     \n",
      "Random seeding    : 91.98  : 5     : 04:47:19 (h:m:s)\n",
      "Local sampling    : 21.85  : 2     : 03:05:39 (h:m:s)\n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 91.98  : 8     : 07:59:14 (h:m:s)\n",
      "=====================================================\n",
      "cnae_network_hp_fn_{'epochs': 100, 'masks_no': 200, 'mask_size': 200, 'target_size': 20, 'lr': 0.0003, 'batch_size': 32}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs': 100,\n",
       " 'masks_no': 200,\n",
       " 'mask_size': 200,\n",
       " 'target_size': 20,\n",
       " 'lr': 0.0003,\n",
       " 'batch_size': 32}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"epochs\": pyhopper.choice([100]),\n",
    "    \"masks_no\": pyhopper.choice([10, 50, 75, 100, 150, 200, 300, 500]), #pyhopper.int(10, 400, multiple_of=10),\n",
    "    \"mask_size\": pyhopper.choice([5, 10, 20, 50, 100, 200, 400]),\n",
    "    \"target_size\": pyhopper.choice([5, 10, 20, 50]),\n",
    "    \"lr\": pyhopper.choice([3e-5, 3e-4, 3e-3, 3e-2, 3e-1]),\n",
    "    \"batch_size\": pyhopper.choice([32, 64]),\n",
    "}\n",
    "\n",
    "hp_best_params, hp_history = pyhopper_best_params(network_hp_fn, param_grid, time=\"480m\")\n",
    "hp_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b4b9203a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 100,\n",
       " 'masks_no': 50,\n",
       " 'mask_size': 400,\n",
       " 'target_size': 50,\n",
       " 'lr': 0.0003,\n",
       " 'batch_size': 32}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe02f07-52f6-4735-93f5-8e14bd22803f",
   "metadata": {},
   "source": [
    "#### Train using the best hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "283d9aca-1f98-42e6-b229-e14e937cb431",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 10\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:03<00:00,  3.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 10\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:58<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 10\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:59<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 10\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:03<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 10\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:58<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 6 of 10\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:58<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 7 of 10\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:58<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 8 of 10\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:58<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 9 of 10\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:57<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 10 of 10\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:59<00:00,  2.99s/it]\n"
     ]
    }
   ],
   "source": [
    "epochs = 100#hp_best_params['epochs']\n",
    "masks_no = hp_best_params['masks_no']\n",
    "mask_size = hp_best_params['mask_size']\n",
    "target_size = hp_best_params['target_size']\n",
    "data_size = max_size\n",
    "batch_size = hp_best_params['batch_size']\n",
    "lr = hp_best_params['lr']\n",
    "\n",
    "\n",
    "hyper_results = test_model(network_hp_fn(epochs, masks_no, mask_size, target_size, batch_size=batch_size,verbose=True),\n",
    "                    (X, y),\n",
    "                    data_size,\n",
    "                    None, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b2129c6b-2c65-458e-b175-51aaf313fa42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756: 92.25 ~ 2.55, (max: 95.37)\n"
     ]
    }
   ],
   "source": [
    "res = hyper_results[hyper_results[\"Class\"]==\"balanced_accuracy\"].reset_index(drop=True)[\"Metric\"]\n",
    "print(f\"{data_size}: {res.mean():.2f} ~ {res.std():.2f}, (max: {res.max():.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdb5810-96c6-4010-af1e-a59b0b9f6b65",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6758728e-d6c8-4d23-9aa7-ba7998704411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6da01b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rf(**params):\n",
    "    random_seed = np.random.randint(1024)\n",
    "    def _inner():\n",
    "        return RandomForestClassifier(\n",
    "            random_state=random_seed,\n",
    "            **params\n",
    "        )\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73ccafa",
   "metadata": {},
   "source": [
    "#### Find hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc080fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "                'n_estimators': pyhopper.int(50, 3000, multiple_of=50),\n",
    "                'max_features': pyhopper.choice([None, 'sqrt', 0.2, 0.3, 0.5, 0.7]),\n",
    "                'criterion' : pyhopper.choice(['gini', 'entropy']),\n",
    "                'max_depth': pyhopper.choice([None, 2, 4, 8, 16]),\n",
    "             }\n",
    "\n",
    "rf_best, rf_history = pyhopper_best_params(get_rf, param_grid, time=\"90m\")\n",
    "rf_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf8eaa2",
   "metadata": {},
   "source": [
    "#### Use best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3325fd3b-8a85-46eb-896c-46bf8d768a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 10\n",
      "iter 2 of 10\n",
      "iter 3 of 10\n",
      "iter 4 of 10\n",
      "iter 5 of 10\n",
      "iter 6 of 10\n",
      "iter 7 of 10\n",
      "iter 8 of 10\n",
      "iter 9 of 10\n",
      "iter 10 of 10\n"
     ]
    }
   ],
   "source": [
    "size = max_size\n",
    "\n",
    "rf_dframe = test_model(get_rf(**rf_best), \n",
    "                        (X, y),\n",
    "                        size,\n",
    "                        None, iters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a543f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa987cfe",
   "metadata": {},
   "source": [
    "# Collect analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6ffd69a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6c53193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['Random forest'] = rf_dframe.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['Hypernet'] = hyper_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['HypernetPCA'] = nn_pca_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['Dropout_1'] = nn1_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['Dropout_2'] = nn2_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['Dropout_3'] = nn3_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['Node'] = node_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['XGBoost'] = xgb_dframe.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7f523ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Random forest</th>\n",
       "      <th>0</th>\n",
       "      <td>97.777778</td>\n",
       "      <td>2.868877</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93.055556</td>\n",
       "      <td>3.982558</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>3.657114</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.722222</td>\n",
       "      <td>4.192308</td>\n",
       "      <td>88.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">XGBoost</th>\n",
       "      <th>6</th>\n",
       "      <td>91.388889</td>\n",
       "      <td>4.233011</td>\n",
       "      <td>97.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>96.666667</td>\n",
       "      <td>3.414646</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>77.777778</td>\n",
       "      <td>7.407407</td>\n",
       "      <td>91.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>90.493827</td>\n",
       "      <td>2.051431</td>\n",
       "      <td>94.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>90.493827</td>\n",
       "      <td>2.051431</td>\n",
       "      <td>94.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       mean       std         max\n",
       "              Class                                              \n",
       "Random forest 0                   97.777778  2.868877  100.000000\n",
       "              1                   93.055556  3.982558  100.000000\n",
       "              2                   95.000000  3.657114  100.000000\n",
       "              3                   84.722222  4.192308   88.888889\n",
       "              4                  100.000000  0.000000  100.000000\n",
       "...                                     ...       ...         ...\n",
       "XGBoost       6                   91.388889  4.233011   97.222222\n",
       "              7                   96.666667  3.414646  100.000000\n",
       "              8                   77.777778  7.407407   91.666667\n",
       "              Total               90.493827  2.051431   94.444444\n",
       "              balanced_accuracy   90.493827  2.051431   94.444444\n",
       "\n",
       "[88 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models_df=pd.concat(d, axis=0)\n",
    "all_models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aac13dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f8b898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "60823a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UXrV5UxyhTK3cyQNG6BDuc4bE'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['COMET_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1f9da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "80d25d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_df.to_csv(f\"{DATA}_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0654fd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/abulenok/hypernet-uci-tune/cd3d48b8f7b048d1934b06562ea42da7\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     copy                       : True\n",
      "COMET INFO:     iterated_power             : auto\n",
      "COMET INFO:     n_components               : 3\n",
      "COMET INFO:     n_oversamples              : 10\n",
      "COMET INFO:     power_iteration_normalizer : auto\n",
      "COMET INFO:     random_state               : 1\n",
      "COMET INFO:     svd_solver                 : auto\n",
      "COMET INFO:     tol                        : 0.0\n",
      "COMET INFO:     whiten                     : False\n",
      "COMET INFO:     with_mean                  : True\n",
      "COMET INFO:     with_std                   : True\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     asset                    : 1 (5.09 KB)\n",
      "COMET INFO:     conda-info               : 1\n",
      "COMET INFO:     conda-specification      : 1\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (5.21 MB)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO:     source_code              : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.com/abulenok/hypernet-uci-tune/4de718e831d54a9a9d63fd69a09f30c0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'web': 'https://www.comet.com/api/asset/download?assetId=96b7c9337313423fafa70e413639f6d6&experimentKey=4de718e831d54a9a9d63fd69a09f30c0',\n",
       " 'api': 'https://www.comet.com/api/rest/v2/experiment/asset/get-asset?assetId=96b7c9337313423fafa70e413639f6d6&experimentKey=4de718e831d54a9a9d63fd69a09f30c0',\n",
       " 'assetId': '96b7c9337313423fafa70e413639f6d6'}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = Experiment(os.environ.get(\"COMET_KEY\"), 'hypernet-uci-tune')\n",
    "# exp.log_parameters({\"epochs\": epochs, \"mask_size\": mask_size, \"masks_no\": masks_no, \"data_size\": data_size})\n",
    "exp.add_tag(f\"hypernet-tune2{DATA}\")\n",
    "exp.log_table(f\"{DATA}_metrics.csv\", all_models_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce733782",
   "metadata": {},
   "source": [
    "### Replace some data in existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a0a197e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_df = pd.concat(d, axis=0)\n",
    "# tmp_df = tmp_df.reset_index()\n",
    "# tmp_df = tmp_df.rename(columns={tmp_df.columns[0]: DATA})\n",
    "\n",
    "# tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8fdbf166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_models_df = pd.read_csv(f\"{DATA}_metrics.csv\")\n",
    "# all_models_df = all_models_df.rename(columns={all_models_df.columns[0]: DATA})\n",
    "# all_models_df = all_models_df.drop(all_models_df[all_models_df.iloc[:, 0] == 'Hypernet'].index)\n",
    "# all_models_df = all_models_df.drop(all_models_df[all_models_df.iloc[:, 0] == 'HypernetPCA'].index)\n",
    "\n",
    "# all_models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d2cc3246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_models_df = pd.concat([all_models_df, tmp_df])\n",
    "# all_models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff93119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5ebc5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e6b6d6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cnae_metrics.csv'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{DATA}_metrics.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9a061329",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_df = pd.read_csv(f\"{DATA}_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e2fb29bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Class</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Random forest</td>\n",
       "      <td>0</td>\n",
       "      <td>97.777778</td>\n",
       "      <td>2.868877</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Random forest</td>\n",
       "      <td>1</td>\n",
       "      <td>93.055556</td>\n",
       "      <td>3.982558</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Random forest</td>\n",
       "      <td>2</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>3.657114</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Random forest</td>\n",
       "      <td>3</td>\n",
       "      <td>84.722222</td>\n",
       "      <td>4.192308</td>\n",
       "      <td>88.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Random forest</td>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>6</td>\n",
       "      <td>91.388889</td>\n",
       "      <td>4.233011</td>\n",
       "      <td>97.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>7</td>\n",
       "      <td>96.666667</td>\n",
       "      <td>3.414646</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>8</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>7.407407</td>\n",
       "      <td>91.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Total</td>\n",
       "      <td>90.493827</td>\n",
       "      <td>2.051431</td>\n",
       "      <td>94.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>87</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>90.493827</td>\n",
       "      <td>2.051431</td>\n",
       "      <td>94.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index     Unnamed: 0              Class        mean       std         max\n",
       "0       0  Random forest                  0   97.777778  2.868877  100.000000\n",
       "1       1  Random forest                  1   93.055556  3.982558  100.000000\n",
       "2       2  Random forest                  2   95.000000  3.657114  100.000000\n",
       "3       3  Random forest                  3   84.722222  4.192308   88.888889\n",
       "4       4  Random forest                  4  100.000000  0.000000  100.000000\n",
       "..    ...            ...                ...         ...       ...         ...\n",
       "83     83        XGBoost                  6   91.388889  4.233011   97.222222\n",
       "84     84        XGBoost                  7   96.666667  3.414646  100.000000\n",
       "85     85        XGBoost                  8   77.777778  7.407407   91.666667\n",
       "86     86        XGBoost              Total   90.493827  2.051431   94.444444\n",
       "87     87        XGBoost  balanced_accuracy   90.493827  2.051431   94.444444\n",
       "\n",
       "[88 rows x 6 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63595ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcccc753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1bf024fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_models_df = all_models_df.drop(all_models_df.columns[0], axis=1)\n",
    "# all_models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca3f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398b55e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c69f547c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Class</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>91.851852</td>\n",
       "      <td>1.358648</td>\n",
       "      <td>94.135802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Hypernet</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>92.253086</td>\n",
       "      <td>2.551150</td>\n",
       "      <td>95.370370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>HypernetPCA</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>94.969136</td>\n",
       "      <td>0.965654</td>\n",
       "      <td>96.604938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Dropout_1</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>94.537037</td>\n",
       "      <td>1.029321</td>\n",
       "      <td>95.987654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Dropout_2</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>94.012346</td>\n",
       "      <td>0.685528</td>\n",
       "      <td>95.370370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Dropout_3</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>94.969136</td>\n",
       "      <td>0.770575</td>\n",
       "      <td>96.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Node</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>94.722222</td>\n",
       "      <td>1.168047</td>\n",
       "      <td>97.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>90.493827</td>\n",
       "      <td>2.051431</td>\n",
       "      <td>94.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0              Class       mean       std        max\n",
       "10  Random forest  balanced_accuracy  91.851852  1.358648  94.135802\n",
       "21       Hypernet  balanced_accuracy  92.253086  2.551150  95.370370\n",
       "32    HypernetPCA  balanced_accuracy  94.969136  0.965654  96.604938\n",
       "43      Dropout_1  balanced_accuracy  94.537037  1.029321  95.987654\n",
       "54      Dropout_2  balanced_accuracy  94.012346  0.685528  95.370370\n",
       "65      Dropout_3  balanced_accuracy  94.969136  0.770575  96.296296\n",
       "76           Node  balanced_accuracy  94.722222  1.168047  97.222222\n",
       "87        XGBoost  balanced_accuracy  90.493827  2.051431  94.444444"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models_df[all_models_df['Class'] == 'balanced_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7beddf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = all_models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1996040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp.rename(columns={tmp.columns[0]: DATA})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "36d69505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnae</th>\n",
       "      <th>Class</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>0</td>\n",
       "      <td>97.777778</td>\n",
       "      <td>2.868877</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>1</td>\n",
       "      <td>93.055556</td>\n",
       "      <td>3.982558</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>2</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>3.657114</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>3</td>\n",
       "      <td>84.722222</td>\n",
       "      <td>4.192308</td>\n",
       "      <td>88.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>6</td>\n",
       "      <td>91.388889</td>\n",
       "      <td>4.233011</td>\n",
       "      <td>97.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>7</td>\n",
       "      <td>96.666667</td>\n",
       "      <td>3.414646</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>8</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>7.407407</td>\n",
       "      <td>91.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Total</td>\n",
       "      <td>90.493827</td>\n",
       "      <td>2.051431</td>\n",
       "      <td>94.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>90.493827</td>\n",
       "      <td>2.051431</td>\n",
       "      <td>94.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             cnae              Class        mean       std         max\n",
       "0   Random forest                  0   97.777778  2.868877  100.000000\n",
       "1   Random forest                  1   93.055556  3.982558  100.000000\n",
       "2   Random forest                  2   95.000000  3.657114  100.000000\n",
       "3   Random forest                  3   84.722222  4.192308   88.888889\n",
       "4   Random forest                  4  100.000000  0.000000  100.000000\n",
       "..            ...                ...         ...       ...         ...\n",
       "83        XGBoost                  6   91.388889  4.233011   97.222222\n",
       "84        XGBoost                  7   96.666667  3.414646  100.000000\n",
       "85        XGBoost                  8   77.777778  7.407407   91.666667\n",
       "86        XGBoost              Total   90.493827  2.051431   94.444444\n",
       "87        XGBoost  balanced_accuracy   90.493827  2.051431   94.444444\n",
       "\n",
       "[88 rows x 5 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b9ee21a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnae</th>\n",
       "      <th>Class</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>91.851852</td>\n",
       "      <td>1.358648</td>\n",
       "      <td>94.135802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Hypernet</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>92.253086</td>\n",
       "      <td>2.551150</td>\n",
       "      <td>95.370370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>HypernetPCA</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>94.969136</td>\n",
       "      <td>0.965654</td>\n",
       "      <td>96.604938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Dropout_1</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>94.537037</td>\n",
       "      <td>1.029321</td>\n",
       "      <td>95.987654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Dropout_2</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>94.012346</td>\n",
       "      <td>0.685528</td>\n",
       "      <td>95.370370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Dropout_3</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>94.969136</td>\n",
       "      <td>0.770575</td>\n",
       "      <td>96.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Node</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>94.722222</td>\n",
       "      <td>1.168047</td>\n",
       "      <td>97.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>90.493827</td>\n",
       "      <td>2.051431</td>\n",
       "      <td>94.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cnae              Class       mean       std        max\n",
       "10  Random forest  balanced_accuracy  91.851852  1.358648  94.135802\n",
       "21       Hypernet  balanced_accuracy  92.253086  2.551150  95.370370\n",
       "32    HypernetPCA  balanced_accuracy  94.969136  0.965654  96.604938\n",
       "43      Dropout_1  balanced_accuracy  94.537037  1.029321  95.987654\n",
       "54      Dropout_2  balanced_accuracy  94.012346  0.685528  95.370370\n",
       "65      Dropout_3  balanced_accuracy  94.969136  0.770575  96.296296\n",
       "76           Node  balanced_accuracy  94.722222  1.168047  97.222222\n",
       "87        XGBoost  balanced_accuracy  90.493827  2.051431  94.444444"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[tmp['Class'] == \"balanced_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49403f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

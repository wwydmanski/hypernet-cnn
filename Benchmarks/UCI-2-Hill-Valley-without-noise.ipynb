{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01de83ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc12a648-b80a-4eca-afc3-79331e4db7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fdadf44-450a-4006-ac5a-bed9840409f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from tqdm import trange\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import sklearn\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "plt.style.use(\"seaborn\")\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbdec3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7585d3a-dff3-43e2-bc0f-f024306021a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a37b70c-292b-4c14-85ed-3c93020dc182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3085114d-cf61-4625-97c5-10f34c00d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabular_hypernet import HypernetworkPCA, TrainingModes, Hypernetwork\n",
    "from tabular_hypernet.modules import SimpleNetwork\n",
    "from tabular_hypernet.training_utils import train_slow_step, train_model, train_carthesian\n",
    "from tabular_hypernet.interfaces import HypernetworkSklearnInterface, SimpleSklearnInterface\n",
    "# from ipynb.fs.defs.MNIST_benchmark import test_model\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d62c6026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c014884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f84a62eb-e16d-4519-ad76-2237037833c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d12953cc-1ec5-46a9-933a-714e5ceafd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from loguru import logger\n",
    "\n",
    "logger.add(\"log_Lymf.txt\", format='{time:YYYY-MM-DD HH:mm:ss.SSS} | {message}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa3c18d1-1d56-4393-9441-245420fb3c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04d1ae25-987c-4043-9771-829c928723de",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE=\"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a1a1e98-a8b4-4df2-aae6-b593fe61667a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from loguru import logger\n",
    "\n",
    "logger.add(\"log.txt\", format='{time:YYYY-MM-DD HH:mm:ss.SSS} | {message}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81b884da",
   "metadata": {},
   "outputs": [],
   "source": [
    "GS_METRIC = \"balanced_accuracy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82db70f7",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7add86f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = \"Hill-Valley-without-noise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba2d025f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (606, 100) 2\n",
      "test (606, 100) 2\n"
     ]
    }
   ],
   "source": [
    "if DATA == \"Hill-Valley-without-noise\":\n",
    "    hill_valley_train = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/hill-valley/Hill_Valley_without_noise_Training.data')\n",
    "    hill_valley_test = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/hill-valley/Hill_Valley_without_noise_Testing.data')\n",
    "    \n",
    "    X_train = hill_valley_train.values[:, :-1].astype(float)\n",
    "    y_train = hill_valley_train.values[:, -1]\n",
    "    y_train = LabelEncoder().fit_transform(y_train).astype(int)\n",
    "    \n",
    "    X_test = hill_valley_test.values[:, :-1].astype(float)\n",
    "    y_test = hill_valley_test.values[:, -1]\n",
    "    y_test = LabelEncoder().fit_transform(y_test).astype(int)\n",
    "    \n",
    "    print('train', X_train.shape, len(np.unique(y_train)))\n",
    "    print('test', X_test.shape, len(np.unique(y_test)))\n",
    "    \n",
    "    X = (X_train, X_test)\n",
    "    y = (y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c587b420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e85869a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = len(np.unique(y if not isinstance(y, tuple) else y_train))\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6305ff4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 305, 1: 301}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y if not isinstance(y, tuple) else y_train, return_counts=True)\n",
    "\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe2c8e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = X.shape[1] if not isinstance(X, tuple) else X_train.shape[1]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4777a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = int(len(X)*0.7) if not isinstance(X, tuple) else len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e7a0ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "606"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38876ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('dataset size:', len(X), '|', 'max training size:', max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30a5727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RUN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507c32bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c287f46",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bdc5ffdd-e04d-425f-8d6c-bd8456644faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "def prepare_data(X, y, size=None):\n",
    "    if isinstance(X, tuple) and isinstance(y, tuple):\n",
    "        X_train, X_test = X\n",
    "        y_train, y_test = y\n",
    "    else:    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=size, stratify=y)\n",
    "    # X_train, y_train = imblearn.over_sampling.RandomOverSampler(random_state=42).fit_resample(X_train, y_train)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = [torch.from_numpy(x) for x in [X_train, X_test, y_train, y_test]]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca0a827a-0e1f-4f5c-b15d-3354f075021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data(X, y, size=max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281d7f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d223075b-b7d8-414e-97c9-ade8bda5f0fd",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9f92f86-4c40-492c-8d48-f23efa85eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5aa90ca0-8a00-4491-b111-ce7eee0e9c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _summarize_results(y_pred, y_score, y_test, labels):\n",
    "    results = []\n",
    "    for idx, label in enumerate(labels):\n",
    "        y_pred_filt = y_pred[y_test==idx]\n",
    "        y_test_filt = y_test[y_test==idx]\n",
    "        acc = (y_pred_filt==y_test_filt.numpy()).sum()/len(y_test_filt)*100\n",
    "        results.append({\n",
    "            \"Class\": label,\n",
    "            \"Metric\": acc\n",
    "        })\n",
    "        \n",
    "    acc = (y_pred==y_test.numpy()).sum()/len(y_test)*100    \n",
    "    results.append({\n",
    "        \"Class\": \"Total\",\n",
    "        \"Metric\": acc\n",
    "    })\n",
    "    \n",
    "    \n",
    "    results.append({\n",
    "        \"Class\": \"balanced_accuracy\",\n",
    "        \"Metric\": balanced_accuracy_score(y_test, torch.from_numpy(y_pred)).item()*100\n",
    "    })\n",
    "    \n",
    "    try:\n",
    "        results.append({\n",
    "            \"Class\": \"F1 score\",\n",
    "            \"Metric\": f1_score(y_test, torch.from_numpy(y_pred)).item()*100\n",
    "        })\n",
    "        results.append({\n",
    "            \"Class\": \"roc_auc\",\n",
    "            \"Metric\": roc_auc_score(y_test, torch.from_numpy(y_score[:, 1])).item()*100\n",
    "        })\n",
    "        results.append({\n",
    "            \"Class\": \"Precision\",\n",
    "            \"Metric\": precision_score(y_test, torch.from_numpy(y_pred)).item()*100\n",
    "        })\n",
    "        results.append({\n",
    "            \"Class\": \"Recall\",\n",
    "            \"Metric\": recall_score(y_test, torch.from_numpy(y_pred)).item()*100\n",
    "        })\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return results\n",
    "\n",
    "def test_model(model_fn, data, train_size, label_encoder=None, iters=10, as_numpy=False):\n",
    "    if TEST_RUN:\n",
    "        iters = 1\n",
    "        \n",
    "    if label_encoder is not None:\n",
    "        labels = label_encoder.classes_\n",
    "    else:\n",
    "        labels = sorted(pd.unique(data[1][0] if isinstance(data[1], tuple) else data[1]))\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for i in range(iters):\n",
    "        print('iter', i+1, 'of', iters)\n",
    "        X_train, X_test, y_train, y_test = prepare_data(*data, train_size)\n",
    "        \n",
    "        model = model_fn()\n",
    "\n",
    "        if as_numpy:\n",
    "            model.fit(X_train.numpy(), y_train.numpy());\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        y_score = model.predict_proba(X_test)\n",
    "        results.extend(_summarize_results(y_pred, y_score, y_test, labels))\n",
    "        \n",
    "#         del model\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "    dframe = pd.DataFrame.from_dict(results)\n",
    "#     sns.violinplot(data=dframe[dframe[\"Class\"]!=\"Loss\"], y=\"Class\", x=\"Metric\", orient='h')\n",
    "    return dframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f351cf",
   "metadata": {},
   "source": [
    "### Param search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1a95790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def grid_search_best_params(model_fn, param_grid, data_size=max_size, scoring=GS_METRIC):\n",
    "#     if TEST_RUN:\n",
    "#         tmp = {k: [v[0]] for k, v in param_grid.items()}\n",
    "#         param_grid = tmp\n",
    "        \n",
    "#     X_train, X_test, y_train, y_test = prepare_data(X, y, data_size)\n",
    "\n",
    "#     cv_clf = GridSearchCV(\n",
    "#         estimator=model_fn(), \n",
    "#         param_grid=param_grid,\n",
    "#         scoring=scoring, \n",
    "#         return_train_score=True,\n",
    "#         verbose=1, \n",
    "#         cv=5,\n",
    "#     )\n",
    "\n",
    "#     res = cv_clf.fit(X_train, y_train)\n",
    "\n",
    "#     print(f'best params for {DATA}', res.best_params_)\n",
    "#     print('mean_train_score', cv_clf.cv_results_['mean_train_score'].mean())\n",
    "#     print('std_train_score', cv_clf.cv_results_['std_train_score'].mean())\n",
    "\n",
    "#     predictions = cv_clf.predict(X_test) \n",
    "#     print(classification_report(y_test, predictions))\n",
    "    \n",
    "#     with open(f\"{DATA}_{model_fn.__name__}_best_params.txt\", \"a\") as f:\n",
    "#             f.write(str(res.best_params_) + \", \" + str(balanced_accuracy_score(y_test, predictions)) + \"\\n\")\n",
    "    \n",
    "#     print(f\"{DATA}_{model_fn.__name__}_{res.best_params_}\")\n",
    "    \n",
    "#     return res.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecee618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyhopper_best_params(model_fn, param_grid, data_size=max_size, metric=GS_METRIC, time=\"30m\", default_params={}):\n",
    "    if TEST_RUN:\n",
    "        time = 30\n",
    "        if 'epochs' in param_grid:\n",
    "            param_grid[\"epochs\"] = pyhopper.choice([10])\n",
    "        \n",
    "    logger.info(f\"pyhopper_best_params {model_fn.__name__}\")\n",
    "    \n",
    "    def objective(params):\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "        model_results = test_model(\n",
    "                        model_fn(\n",
    "                            **default_params,\n",
    "                            **params\n",
    "                        ),\n",
    "                        (X, y),\n",
    "                        data_size,\n",
    "                        None, 5)\n",
    "        with open(f\"{DATA}_{model_fn.__name__}_params.txt\", \"a\") as f:\n",
    "            f.write(str(datetime.datetime.now()) + \", \" + str(params) + \", \" + str(model_results[model_results[\"Class\"]==metric][\"Metric\"].mean()) + \"\\n\")\n",
    "        return model_results[model_results[\"Class\"]==metric][\"Metric\"].mean()\n",
    "\n",
    "    from pyhopper.callbacks import History\n",
    "    search = pyhopper.Search(param_grid)\n",
    "\n",
    "    best_params = search.run(objective, \"maximize\", time, n_jobs=\"1x per-gpu\", seeding_ratio=0.5)\n",
    "    \n",
    "    with open(f\"{DATA}_{model_fn.__name__}_best_params.txt\", \"a\") as f:\n",
    "            f.write(str(best_params))\n",
    "    \n",
    "    print(f\"{DATA}_{model_fn.__name__}_{best_params}\")\n",
    "    return best_params, search.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57f3796d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 12, 5, 14, 11, 54, 232100)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "datetime.datetime.now()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f51db3",
   "metadata": {},
   "source": [
    "# TRAIN MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf59445b-c0f0-4ee7-bfe9-5c8a57c22b86",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aacc321b-420a-47f3-88af-6bb02aa0ddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50c27ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "xgboost.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63e24c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xgboost(**params):\n",
    "    random_seed = np.random.randint(1024)\n",
    "    def _inner(**args):\n",
    "        return XGBClassifier(\n",
    "            verbosity=0,\n",
    "            random_state=random_seed,\n",
    "            use_label_encoder=False,\n",
    "            **params,\n",
    "            **args\n",
    "        )\n",
    "    return _inner    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8213082c",
   "metadata": {},
   "source": [
    "#### Hyperparam tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da7af406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 00:31:52.626 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params get_xgboost\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fddc8861d8b54469b120f24f9c604838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 01:30:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 53.27  : 1     : 9.77 s          \n",
      "Random seeding    : 59.94  : 105   : 45:06 (m:s)     \n",
      "Local sampling    : 60.36  : 136   : 44:34 (m:s)     \n",
      "Duplicates        : -      : 14    : -               \n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 60.36  : 256   : 01:29:51 (h:m:s)\n",
      "=====================================================\n",
      "Hill-Valley-without-noise_get_xgboost_{'n_estimators': 1800, 'max_depth': 5, 'learning_rate': 0.06182609930343652, 'min_child_weight': 2, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "                'n_estimators': pyhopper.int(50, 3000, multiple_of=50),\n",
    "                'max_depth': pyhopper.choice([2, 3, 5, 10, 15]),\n",
    "                'learning_rate': pyhopper.float(1e-5,1e-1, log=True),\n",
    "                'min_child_weight': pyhopper.choice([1, 2, 4, 8, 16, 32]),\n",
    "                'gamma': pyhopper.choice([0, 0.001, 0.1, 1]),\n",
    "             }\n",
    "\n",
    "xgbt_best1, xgbt_history1 = pyhopper_best_params(get_xgboost, param_grid, time=\"90m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d8fb3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "858bc970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 02:01:43.870 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params get_xgboost\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97abd0e38ed148bcb0cbe18e335c610c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 01:30:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 64.07  : 1     : 23 s            \n",
      "Random seeding    : 66.2   : 114   : 44:40 (m:s)     \n",
      "Local sampling    : 66.72  : 110   : 44:54 (m:s)     \n",
      "Duplicates        : -      : 23    : -               \n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 66.72  : 248   : 01:29:57 (h:m:s)\n",
      "=====================================================\n",
      "Hill-Valley-without-noise_get_xgboost_{'subsample': 0.5, 'reg_lambda': 0.0027221559995285268, 'reg_alpha': 0.0059937063392050795}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "                'subsample': pyhopper.choice([0.5, 0.6, 0.7, 0.8, 0.9, 1]),\n",
    "                'reg_lambda': pyhopper.float(1e-5, 10, init=0, log=True),\n",
    "                'reg_alpha': pyhopper.float(1e-5, 10, init=0, log=True),\n",
    "             }\n",
    "\n",
    "\n",
    "xgbt_best2, xgbt_history2 = pyhopper_best_params(get_xgboost, param_grid, time=\"90m\", default_params=xgbt_best1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fb0f7b",
   "metadata": {},
   "source": [
    "#### Best Params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2aa500",
   "metadata": {},
   "source": [
    "'Ionosphere' {'gamma': 0, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 1500}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "511d7466",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_best = {**xgbt_best1, **xgbt_best2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5cedd88-43b4-465c-b1e1-6a0b620ae73a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 20\n",
      "iter 2 of 20\n",
      "iter 3 of 20\n",
      "iter 4 of 20\n",
      "iter 5 of 20\n",
      "iter 6 of 20\n",
      "iter 7 of 20\n",
      "iter 8 of 20\n",
      "iter 9 of 20\n",
      "iter 10 of 20\n",
      "iter 11 of 20\n",
      "iter 12 of 20\n",
      "iter 13 of 20\n",
      "iter 14 of 20\n",
      "iter 15 of 20\n",
      "iter 16 of 20\n",
      "iter 17 of 20\n",
      "iter 18 of 20\n",
      "iter 19 of 20\n",
      "iter 20 of 20\n"
     ]
    }
   ],
   "source": [
    "data_size = max_size\n",
    "\n",
    "xgb_dframe = test_model(get_xgboost(**xgboost_best),\n",
    "                        (X, y),\n",
    "                        data_size,\n",
    "                        label_encoder=None, iters=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f530a0df-271a-495f-b49d-2cffe523c328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606: 65.68 ~ 0.00 (max: 65.68)\n"
     ]
    }
   ],
   "source": [
    "res = xgb_dframe[xgb_dframe[\"Class\"]==\"Total\"].reset_index(drop=True)[\"Metric\"]\n",
    "print(f\"{data_size}: {res.mean():.2f} ~ {res.std():.2f} (max: {res.max():.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e53148cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.061093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 score</th>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>65.191740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>71.061093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>65.676568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>65.530547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>71.282359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Metric\n",
       "Class                       \n",
       "0                  60.000000\n",
       "1                  71.061093\n",
       "F1 score           68.000000\n",
       "Precision          65.191740\n",
       "Recall             71.061093\n",
       "Total              65.676568\n",
       "balanced_accuracy  65.530547\n",
       "roc_auc            71.282359"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_dframe.groupby(['Class']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08dcdab-2c4b-4a05-822b-912037488763",
   "metadata": {},
   "source": [
    "### NODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64d10cad-57b5-488c-9a94-63259bd0c13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qhoptim.pyt import QHAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "806be7a7-e4c8-4525-a38f-9ae16a3bd229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_fn(layer_dim=128, num_layers=1, depth=3):\n",
    "    def _inner():\n",
    "        network = torch.nn.Sequential(\n",
    "            node.DenseBlock(X_train.shape[1], \n",
    "                            layer_dim=layer_dim,\n",
    "                            num_layers=num_layers, \n",
    "                            tree_dim=n_classes+1, \n",
    "                            depth=depth, \n",
    "                            flatten_output=False,\n",
    "                            choice_function=node.entmax15, \n",
    "                            bin_function=node.entmoid15\n",
    "                           ),\n",
    "            node.Lambda(lambda x: x.mean(dim=1))\n",
    "        )\n",
    "        \n",
    "        \n",
    "        network = network.to(DEVICE)\n",
    "        network.device=DEVICE\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            res = network(torch.as_tensor(X_train, device=DEVICE).to(torch.float32))\n",
    "        \n",
    "            \n",
    "        optimizer_params = { 'nus':(0.7, 1.0), 'betas':(0.95, 0.998) }\n",
    "        optim = QHAdam(network.parameters(), **optimizer_params)\n",
    "            \n",
    "        network = SimpleSklearnInterface(network, device=DEVICE, epochs=150, batch_size=32)\n",
    "        network.optimizer = optim\n",
    "        return network\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d404841f",
   "metadata": {},
   "source": [
    "#### Tune hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "816a242b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 03:33:18.003 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params node_fn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "825d47617d0e4ca4b121d38e814948b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 01:30:00 (h:m:s)\n",
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n",
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/qhoptim/pyt/qhadam.py:133: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1055.)\n",
      "  exp_avg.mul_(beta1_adj).add_(1.0 - beta1_adj, d_p)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 52.02  : 1     : 04:17 (m:s)     \n",
      "Random seeding    : 52.73  : 7     : 42:41 (m:s)     \n",
      "Local sampling    : 52.88  : 8     : 38:33 (m:s)     \n",
      "Duplicates        : -      : 6     : -               \n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 52.88  : 22    : 01:25:32 (h:m:s)\n",
      "=====================================================\n",
      "Hill-Valley-without-noise_node_fn_{'layer_dim': 512, 'num_layers': 2, 'depth': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'layer_dim': 512, 'num_layers': 2, 'depth': 3}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'layer_dim': hp.quniform('layer_dim', 100, 1200, 100),\n",
    "# 'num_layers': hp.quniform('num_layers', 1, 4, 1),\n",
    "# 'depth': hp.quniform('depth', 2, 7, 1)\n",
    "                    \n",
    "param_grid = {\n",
    "    'layer_dim': pyhopper.int(64, 1024, power_of=2),\n",
    "    'num_layers': pyhopper.int(1, 5),\n",
    "    'depth': pyhopper.int(2, 7),\n",
    "}\n",
    "\n",
    "node_best, node_history = pyhopper_best_params(node_fn, param_grid, time=\"90m\")\n",
    "node_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8e91b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7772daf",
   "metadata": {},
   "source": [
    "#### Use best hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6e447c1-63a6-4c90-b22e-5e0852817f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 20\n",
      "iter 2 of 20\n",
      "iter 3 of 20\n",
      "iter 4 of 20\n",
      "iter 5 of 20\n",
      "iter 6 of 20\n",
      "iter 7 of 20\n",
      "iter 8 of 20\n",
      "iter 9 of 20\n",
      "iter 10 of 20\n",
      "iter 11 of 20\n",
      "iter 12 of 20\n",
      "iter 13 of 20\n",
      "iter 14 of 20\n",
      "iter 15 of 20\n",
      "iter 16 of 20\n",
      "iter 17 of 20\n",
      "iter 18 of 20\n",
      "iter 19 of 20\n",
      "iter 20 of 20\n",
      "606: 51.42 ~ 0.17, (max: 51.91)\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "size=max_size\n",
    "\n",
    "node_results = test_model(node_fn(**node_best),\n",
    "                    (X, y),\n",
    "                    size,\n",
    "                    label_encoder=None, iters=20)\n",
    "res = node_results[node_results[\"Class\"]==\"roc_auc\"].reset_index(drop=True)[\"Metric\"]\n",
    "print(f\"{size}: {res.mean():.2f} ~ {res.std():.2f}, (max: {res.max():.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8437ea73-72bf-4b18-94d4-eb58a8da9792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d696b0-f5b6-4508-9fff-5166fad29e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "753c2e4d-aca4-4eb1-b3ea-a1926fd44efe",
   "metadata": {},
   "source": [
    "### Dropout Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9c97f270-5e57-4cea-b2f1-3204451b0f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_fn1(epochs=100, drop1=0.3, drop2=0.5, batch_size=32, lr=3e-4):\n",
    "    \n",
    "    def _inner():\n",
    "        network = torch.nn.Sequential(\n",
    "                        torch.nn.Dropout(drop1),\n",
    "                        torch.nn.Linear(n_features, 64),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout(drop2),\n",
    "                        torch.nn.Linear(64, n_classes)\n",
    "                    ).to(DEVICE).train()\n",
    "\n",
    "        network = SimpleSklearnInterface(network, epochs=epochs, batch_size=batch_size, lr=lr)\n",
    "        return network\n",
    "    return _inner\n",
    "\n",
    "\n",
    "\n",
    "def network_fn2(epochs=100, drop1=0.3, drop2=0.5, drop3=0.5, batch_size=32, lr=3e-4):\n",
    "    \n",
    "    def _inner():\n",
    "        network = torch.nn.Sequential(\n",
    "                        torch.nn.Dropout(drop1),\n",
    "                        torch.nn.Linear(n_features, 64),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout(drop2),\n",
    "                        torch.nn.Linear(64, 64),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout(drop3),\n",
    "                        torch.nn.Linear(64, n_classes)\n",
    "                    ).to(DEVICE).train()\n",
    "\n",
    "        network = SimpleSklearnInterface(network, epochs=epochs, batch_size=batch_size, lr=lr)\n",
    "        return network\n",
    "    return _inner\n",
    "\n",
    "\n",
    "\n",
    "def network_fn3(epochs=100, drop1=0.3, drop2=0.5, drop3=0.5, drop4=0.5, batch_size=32, lr=3e-4):\n",
    "    \n",
    "    def _inner():\n",
    "        network = torch.nn.Sequential(\n",
    "                        torch.nn.Dropout(drop1),\n",
    "                        torch.nn.Linear(n_features, 64),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout(drop2),\n",
    "                        torch.nn.Linear(64, 128),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout(drop3),\n",
    "                        torch.nn.Linear(128, 64),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout(drop4),\n",
    "                        torch.nn.Linear(64, n_classes)\n",
    "                    ).to(DEVICE).train()\n",
    "\n",
    "        network = SimpleSklearnInterface(network, epochs=epochs, batch_size=batch_size, lr=lr)\n",
    "        return network\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7bb2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64652732",
   "metadata": {},
   "source": [
    "#### Find Hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256e43a3",
   "metadata": {},
   "source": [
    "### Dropout 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41850a57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 05:13:10.271 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params network_fn1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cbe06c6447a403bafb5256058fc5242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 01:00:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "==================== Summary ===================\n",
      "Mode              : Best f : Steps : Time       \n",
      "----------------  : ----   : ----  : ----       \n",
      "Initial solution  : 52.5   : 1     : 01:17 (m:s)\n",
      "Random seeding    : 54     : 18    : 29:37 (m:s)\n",
      "Local sampling    : 55.24  : 19    : 28:24 (m:s)\n",
      "Duplicates        : -      : 18    : -          \n",
      "----------------  : ----   : ----  : ----       \n",
      "Total             : 55.24  : 56    : 59:18 (m:s)\n",
      "================================================\n",
      "Hill-Valley-without-noise_network_fn1_{'epochs': 150, 'drop1': 0.1, 'drop2': 0.5, 'lr': 0.03, 'batch_size': 32}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs': 150, 'drop1': 0.1, 'drop2': 0.5, 'lr': 0.03, 'batch_size': 32}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "                \"epochs\": pyhopper.choice([100, 150]),\n",
    "                \"drop1\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"drop2\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"lr\": pyhopper.choice([3e-5, 3e-4, 3e-3, 3e-2, 3e-1]),\n",
    "                \"batch_size\": pyhopper.choice([32, 64]),\n",
    "             }\n",
    "\n",
    "nn_fn1_best_params, nn_fn1_history = pyhopper_best_params(network_fn1, param_grid, time=\"60m\")\n",
    "nn_fn1_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b0143ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 20\n",
      "iter 2 of 20\n",
      "iter 3 of 20\n",
      "iter 4 of 20\n",
      "iter 5 of 20\n",
      "iter 6 of 20\n",
      "iter 7 of 20\n",
      "iter 8 of 20\n",
      "iter 9 of 20\n",
      "iter 10 of 20\n",
      "iter 11 of 20\n",
      "iter 12 of 20\n",
      "iter 13 of 20\n",
      "iter 14 of 20\n",
      "iter 15 of 20\n",
      "iter 16 of 20\n",
      "iter 17 of 20\n",
      "iter 18 of 20\n",
      "iter 19 of 20\n",
      "iter 20 of 20\n"
     ]
    }
   ],
   "source": [
    "data_size = max_size\n",
    "\n",
    "nn1_results = test_model(network_fn1(**nn_fn1_best_params),\n",
    "                (X, y),\n",
    "                data_size,\n",
    "                None, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb03b139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606: nan ~ nan (max: nan)\n"
     ]
    }
   ],
   "source": [
    "res = nn1_results[nn1_results[\"Class\"]==\"Balanced Acc score\"][\"Metric\"]\n",
    "print(f\"{data_size}: {res.mean():.2f} ~ {res.std():.2f} (max: {res.max():.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc25ca37",
   "metadata": {},
   "source": [
    "### Dropout 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ded59e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 06:19:53.783 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params network_fn2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a4a999b4444e10aa47ab56aabc7b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 01:10:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 51.55  : 1     : 01:20 (m:s)     \n",
      "Random seeding    : 54.85  : 22    : 34:01 (m:s)     \n",
      "Local sampling    : 55.24  : 21    : 34:05 (m:s)     \n",
      "Duplicates        : -      : 19    : -               \n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 55.24  : 63    : 01:09:26 (h:m:s)\n",
      "=====================================================\n",
      "Hill-Valley-without-noise_network_fn2_{'epochs': 150, 'drop1': 0.1, 'drop2': 0.3, 'drop3': 0.1, 'lr': 3e-05, 'batch_size': 32}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs': 150,\n",
       " 'drop1': 0.1,\n",
       " 'drop2': 0.3,\n",
       " 'drop3': 0.1,\n",
       " 'lr': 3e-05,\n",
       " 'batch_size': 32}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "                \"epochs\": pyhopper.choice([100, 150]),\n",
    "                \"drop1\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"drop2\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"drop3\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"lr\": pyhopper.choice([3e-5, 3e-4, 3e-3, 3e-2, 3e-1]),\n",
    "                \"batch_size\": pyhopper.choice([32, 64]),\n",
    "             }\n",
    "\n",
    "nn_fn2_best_params, nn_fn2_history = pyhopper_best_params(network_fn2, param_grid, time=\"70m\")\n",
    "nn_fn2_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "326bbde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 20\n",
      "iter 2 of 20\n",
      "iter 3 of 20\n",
      "iter 4 of 20\n",
      "iter 5 of 20\n",
      "iter 6 of 20\n",
      "iter 7 of 20\n",
      "iter 8 of 20\n",
      "iter 9 of 20\n",
      "iter 10 of 20\n",
      "iter 11 of 20\n",
      "iter 12 of 20\n",
      "iter 13 of 20\n",
      "iter 14 of 20\n",
      "iter 15 of 20\n",
      "iter 16 of 20\n",
      "iter 17 of 20\n",
      "iter 18 of 20\n",
      "iter 19 of 20\n",
      "iter 20 of 20\n"
     ]
    }
   ],
   "source": [
    "data_size = max_size\n",
    "\n",
    "nn2_results = test_model(network_fn2(**nn_fn2_best_params),\n",
    "                (X, y),\n",
    "                data_size,\n",
    "                None, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8349efaf",
   "metadata": {},
   "source": [
    "### Dropout 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5321d73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 07:37:08.248 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params network_fn3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d546ca81e01b400f865edf7a8fca83c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 01:15:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n",
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 50.47  : 1     : 01:21 (m:s)     \n",
      "Random seeding    : 59.1   : 21    : 37:41 (m:s)     \n",
      "Local sampling    : 58.63  : 20    : 34:40 (m:s)     \n",
      "Duplicates        : -      : 15    : -               \n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 59.1   : 57    : 01:13:42 (h:m:s)\n",
      "=====================================================\n",
      "Hill-Valley-without-noise_network_fn3_{'epochs': 150, 'drop1': 0.1, 'drop2': 0.1, 'drop3': 0.1, 'drop4': 0.3, 'lr': 3e-05, 'batch_size': 32}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs': 150,\n",
       " 'drop1': 0.1,\n",
       " 'drop2': 0.1,\n",
       " 'drop3': 0.1,\n",
       " 'drop4': 0.3,\n",
       " 'lr': 3e-05,\n",
       " 'batch_size': 32}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "                \"epochs\": pyhopper.choice([100, 150]),\n",
    "                \"drop1\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"drop2\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"drop3\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"drop4\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"lr\": pyhopper.choice([3e-5, 3e-4, 3e-3, 3e-2, 3e-1]),\n",
    "                \"batch_size\": pyhopper.choice([32, 64]),\n",
    "             }\n",
    "\n",
    "nn_fn3_best_params, nn_fn3_history = pyhopper_best_params(network_fn3, param_grid, time=\"75m\")\n",
    "nn_fn3_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aa8b864e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 20\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'verbose'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m data_size \u001b[38;5;241m=\u001b[39m max_size\n\u001b[0;32m----> 3\u001b[0m nn3_results \u001b[38;5;241m=\u001b[39m \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork_fn3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdata_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36mtest_model\u001b[0;34m(model_fn, data, train_size, label_encoder, iters, as_numpy)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miter\u001b[39m\u001b[38;5;124m'\u001b[39m, i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mof\u001b[39m\u001b[38;5;124m'\u001b[39m, iters)\n\u001b[1;32m     58\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m prepare_data(\u001b[38;5;241m*\u001b[39mdata, train_size)\n\u001b[0;32m---> 60\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m as_numpy:\n\u001b[1;32m     63\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train\u001b[38;5;241m.\u001b[39mnumpy(), y_train\u001b[38;5;241m.\u001b[39mnumpy());\n",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36mnetwork_fn3.<locals>._inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_inner\u001b[39m():\n\u001b[1;32m     41\u001b[0m     network \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m     42\u001b[0m                     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mDropout(drop1),\n\u001b[1;32m     43\u001b[0m                     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(n_features, \u001b[38;5;241m64\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m                     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m64\u001b[39m, n_classes)\n\u001b[1;32m     53\u001b[0m                 )\u001b[38;5;241m.\u001b[39mto(DEVICE)\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 55\u001b[0m     network \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleSklearnInterface\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m network\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'verbose'"
     ]
    }
   ],
   "source": [
    "data_size = max_size\n",
    "\n",
    "nn3_results = test_model(network_fn3(**nn_fn3_best_params),\n",
    "                (X, y),\n",
    "                data_size,\n",
    "                None, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb86765-3874-4023-8e26-b40ccc6df903",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933db2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d60779d-0042-49af-8a32-e6d0b59e1589",
   "metadata": {
    "tags": []
   },
   "source": [
    "### HypernetworkPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e5536d6-cf9d-4a2b-9d7b-184c0ac27a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_pca_fn(epochs=100, masks_no=100, mask_size=100, target_size=100, n_comp=5, lr=3e-4, batch_size=64, verbose=False):\n",
    "    def _inner():\n",
    "        hypernet = HypernetworkPCA(\n",
    "                        target_architecture=[(mask_size, target_size), (target_size, n_classes)], \n",
    "                        test_nodes=masks_no,\n",
    "                        architecture=torch.nn.Sequential(torch.nn.Linear(n_comp, 64), \n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(64, 128),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Dropout(),\n",
    "                            torch.nn.Linear(128, 128),\n",
    "                            torch.nn.ReLU(),\n",
    "                        ),\n",
    "                        mode=TrainingModes.CARTHESIAN,\n",
    "                        input_size=n_features\n",
    "                    ).to(DEVICE)    \n",
    "        hypernet = hypernet.train()\n",
    "\n",
    "        network = HypernetworkSklearnInterface(hypernet, device=DEVICE, epochs=epochs, batch_size=batch_size, verbose=verbose, lr=lr)\n",
    "        return network\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e43b7af-9be5-427a-be2e-4f134ba1e644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_to_html():\n",
    "    tmpfile = BytesIO()\n",
    "    plt.gcf().savefig(tmpfile, format='png')\n",
    "    encoded = base64.b64encode(tmpfile.getvalue()).decode('utf-8')\n",
    "\n",
    "    html = '<img src=\\'data:image/png;base64,{}\\'>'.format(encoded)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a257e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be2e5638-be6d-4a42-8eb4-be84078643bb",
   "metadata": {},
   "source": [
    "#### Find hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45f2e4fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 18:12:05.626 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params network_pca_fn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6ce118b928403ebc161260fb8f2ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 06:00:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 72.83  : 1     : 01:00:37 (h:m:s)\n",
      "Random seeding    : 71.51  : 4     : 02:12:24 (h:m:s)\n",
      "Local sampling    : 72.91  : 3     : 02:45:01 (h:m:s)\n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 72.91  : 8     : 05:58:03 (h:m:s)\n",
      "=====================================================\n",
      "Hill-Valley-without-noise_network_pca_fn_{'epochs': 100, 'masks_no': 130, 'mask_size': 41, 'target_size': 10, 'n_comp': 26, 'lr': 3e-05, 'batch_size': 32}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs': 100,\n",
       " 'masks_no': 130,\n",
       " 'mask_size': 41,\n",
       " 'target_size': 10,\n",
       " 'n_comp': 26,\n",
       " 'lr': 3e-05,\n",
       " 'batch_size': 32}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"epochs\": pyhopper.choice([100]),\n",
    "    \"masks_no\": pyhopper.int(50, 200, multiple_of=10),\n",
    "    \"mask_size\": pyhopper.int(3, 90),\n",
    "    \"target_size\": pyhopper.choice([5, 10, 20, 50]),\n",
    "    \"n_comp\": pyhopper.int(3, 50),\n",
    "    \"lr\": pyhopper.choice([3e-5, 3e-4, 3e-3, 3e-2, 3e-1]),\n",
    "    \"batch_size\": pyhopper.choice([32, 64]),\n",
    "\n",
    "}\n",
    "\n",
    "hp_pca_best_params, hp_pca_history = pyhopper_best_params(network_pca_fn, param_grid, time=\"360m\")\n",
    "hp_pca_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9569bae-98d8-4d2b-9643-3e57fe6bdcbf",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df7c4b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 100,\n",
       " 'masks_no': 130,\n",
       " 'mask_size': 41,\n",
       " 'target_size': 10,\n",
       " 'n_comp': 26,\n",
       " 'lr': 3e-05,\n",
       " 'batch_size': 32}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_pca_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa4f868",
   "metadata": {},
   "source": [
    "'Libras'\n",
    "{'epochs': 150,\n",
    " 'masks_no': 70,\n",
    " 'mask_size': 20,\n",
    " 'target_size': 10,\n",
    " 'n_comp': 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8454fdc",
   "metadata": {},
   "source": [
    "'Lymphography' {'epochs': 120, 'masks_no': 50, 'mask_size': 4, 'target_size': 20, 'n_comp': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e81b7e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hill-Valley-without-noise'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803eafa7",
   "metadata": {},
   "source": [
    "Ionosphere\n",
    "{'epochs': 100, 'masks_no': 60, 'mask_size': 5, 'target_size': 10}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f5b3a72c-14cf-4d70-bb83-1f0a8aad5144",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 10\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 2 of 10\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 3 of 10\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 4 of 10\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 5 of 10\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 6 of 10\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 7 of 10\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 8 of 10\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 9 of 10\n",
      "torch.Size([1, 128])\n",
      "100\n",
      "iter 10 of 10\n",
      "torch.Size([1, 128])\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "epochs = 100#hp_pca_best_params['epochs']\n",
    "masks_no = hp_pca_best_params['masks_no']\n",
    "mask_size = hp_pca_best_params['mask_size']\n",
    "target_size = hp_pca_best_params['target_size']\n",
    "n_comp = hp_pca_best_params['n_comp']\n",
    "lr = hp_pca_best_params['lr']\n",
    "batch_size = hp_pca_best_params['batch_size']\n",
    "data_size = max_size\n",
    "\n",
    "nn_pca_results = test_model(network_pca_fn(target_size=target_size, mask_size=mask_size, masks_no=masks_no, n_comp=n_comp, epochs=epochs),\n",
    "                (X, y),\n",
    "                data_size,\n",
    "                None, 10)\n",
    "\n",
    "# exp.log_table(\"metrics.csv\", nn_pca_results.groupby(\"Class\").mean())\n",
    "# exp.log_metric(\"f1_score\", nn_pca_results.groupby(\"Class\").mean().loc[\"F1 score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b950280b-188d-4321-8db6-9cb69912a242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606: 67.89 ~ 2.46 (max: 72.11)\n"
     ]
    }
   ],
   "source": [
    "res = nn_pca_results[nn_pca_results[\"Class\"]==\"Total\"].reset_index(drop=True)[\"Metric\"]\n",
    "print(f\"{data_size}: {res.mean():.2f} ~ {res.std():.2f} (max: {res.max():.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6e0de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d82e3c9a-94c1-4984-a311-e0091c453333",
   "metadata": {},
   "source": [
    "### Hypernetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f81bdd75-482c-47ee-a9b3-4c2348f3b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_hp_fn(epochs=150, masks_no=100, mask_size=100, target_size=100, lr=3e-4, batch_size=64, verbose=False):\n",
    "    def _inner():\n",
    "        hypernet = Hypernetwork(\n",
    "                        target_architecture=[(mask_size, target_size), (target_size, n_classes)],\n",
    "                        test_nodes=masks_no,\n",
    "                        architecture=torch.nn.Sequential(torch.nn.Linear(n_features, 64), \n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(64, 128),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Dropout(),\n",
    "                            torch.nn.Linear(128, 128),\n",
    "                            torch.nn.ReLU(),\n",
    "                        ),\n",
    "                        mode=TrainingModes.CARTHESIAN,\n",
    "                    ).to(DEVICE)    \n",
    "        hypernet = hypernet.train()\n",
    "\n",
    "        network = HypernetworkSklearnInterface(hypernet, device=DEVICE, epochs=epochs, batch_size=batch_size, verbose=verbose, lr=lr)\n",
    "        return network\n",
    "    return _inner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76e319a",
   "metadata": {},
   "source": [
    "#### Find hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5235e59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 01:17:38.398 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params network_hp_fn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e89654782ba4127b94fa65a9bf96b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 06:00:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 70.67  : 1     : 01:31:55 (h:m:s)\n",
      "Random seeding    : 70.38  : 3     : 03:19:50 (h:m:s)\n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 70.67  : 4     : 04:51:45 (h:m:s)\n",
      "=====================================================\n",
      "Hill-Valley-without-noise_network_hp_fn_{'epochs': 100, 'masks_no': 210, 'mask_size': 46, 'target_size': 5, 'lr': 3e-05, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs': 100,\n",
       " 'masks_no': 210,\n",
       " 'mask_size': 46,\n",
       " 'target_size': 5,\n",
       " 'lr': 3e-05,\n",
       " 'batch_size': 32}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"epochs\": pyhopper.choice([100]),\n",
    "    \"masks_no\": pyhopper.choice([50, 70, 100, 150, 200, 300]),\n",
    "    \"mask_size\": pyhopper.choice([2, 5, 10, 20, 50, 90]),\n",
    "    \"target_size\": pyhopper.choice([5, 10, 20, 50]),\n",
    "    \"lr\": pyhopper.choice([3e-5, 3e-4, 3e-3, 3e-2, 3e-1]),\n",
    "    \"batch_size\": pyhopper.choice([32, 64]),\n",
    "}\n",
    "\n",
    "hp_best_params, hp_history = pyhopper_best_params(network_hp_fn, param_grid, time=\"360m\")\n",
    "hp_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b4b9203a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 100,\n",
       " 'masks_no': 210,\n",
       " 'mask_size': 46,\n",
       " 'target_size': 5,\n",
       " 'lr': 3e-05,\n",
       " 'batch_size': 32}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe02f07-52f6-4735-93f5-8e14bd22803f",
   "metadata": {},
   "source": [
    "#### Train using the best hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283d9aca-1f98-42e6-b229-e14e937cb431",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 10\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [18:32<00:00, 11.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 10\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 75/100 [13:46<04:39, 11.19s/it]"
     ]
    }
   ],
   "source": [
    "epochs = 100#hp_best_params['epochs']\n",
    "masks_no = 210#hp_best_params['masks_no']\n",
    "mask_size = 46#hp_best_params['mask_size']\n",
    "target_size = 5#hp_best_params['target_size']\n",
    "data_size = max_size\n",
    "batch_size = 32#hp_best_params['batch_size']\n",
    "lr = 1e-4#hp_best_params['lr']\n",
    "\n",
    "\n",
    "hyper_results = test_model(network_hp_fn(epochs, masks_no, mask_size, target_size, batch_size=batch_size,verbose=True),\n",
    "                    (X, y),\n",
    "                    data_size,\n",
    "                    None, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2129c6b-2c65-458e-b175-51aaf313fa42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606: 70.42 ~ 4.64, (max: 80.00)\n"
     ]
    }
   ],
   "source": [
    "res = hyper_results[hyper_results[\"Class\"]==\"balanced_accuracy\"].reset_index(drop=True)[\"Metric\"]\n",
    "print(f\"{data_size}: {res.mean():.2f} ~ {res.std():.2f}, (max: {res.max():.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdb5810-96c6-4010-af1e-a59b0b9f6b65",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6758728e-d6c8-4d23-9aa7-ba7998704411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6da01b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rf(**params):\n",
    "    random_seed = np.random.randint(1024)\n",
    "    def _inner():\n",
    "        return RandomForestClassifier(\n",
    "            random_state=random_seed,\n",
    "            **params\n",
    "        )\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73ccafa",
   "metadata": {},
   "source": [
    "#### Find hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8dc080fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 02:21:11.907 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params get_rf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c18e8ca02e3b4ae888c699f2e1279a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 01:30:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 57.34  : 1     : 04:14 (m:s)     \n",
      "Random seeding    : 57.51  : 22    : 42:01 (m:s)     \n",
      "Local sampling    : 58.3   : 6     : 40:45 (m:s)     \n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 58.3   : 29    : 01:27:00 (h:m:s)\n",
      "=====================================================\n",
      "Hill-Valley-without-noise_get_rf_{'n_estimators': 1800, 'max_features': None, 'criterion': 'entropy', 'max_depth': 16}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1800,\n",
       " 'max_features': None,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': 16}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "                'n_estimators': pyhopper.int(50, 3000, multiple_of=50),\n",
    "                'max_features': pyhopper.choice([None, 'sqrt', 0.2, 0.3, 0.5, 0.7]),\n",
    "                'criterion' : pyhopper.choice(['gini', 'entropy']),\n",
    "                'max_depth': pyhopper.choice([None, 2, 4, 8, 16]),\n",
    "             }\n",
    "\n",
    "rf_best, rf_history = pyhopper_best_params(get_rf, param_grid, time=\"90m\")\n",
    "rf_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf8eaa2",
   "metadata": {},
   "source": [
    "#### Use best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3325fd3b-8a85-46eb-896c-46bf8d768a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 20\n",
      "iter 2 of 20\n",
      "iter 3 of 20\n",
      "iter 4 of 20\n",
      "iter 5 of 20\n",
      "iter 6 of 20\n",
      "iter 7 of 20\n",
      "iter 8 of 20\n",
      "iter 9 of 20\n",
      "iter 10 of 20\n",
      "iter 11 of 20\n",
      "iter 12 of 20\n",
      "iter 13 of 20\n",
      "iter 14 of 20\n",
      "iter 15 of 20\n",
      "iter 16 of 20\n",
      "iter 17 of 20\n",
      "iter 18 of 20\n",
      "iter 19 of 20\n",
      "iter 20 of 20\n"
     ]
    }
   ],
   "source": [
    "size = max_size\n",
    "\n",
    "rf_dframe = test_model(get_rf(**rf_best), \n",
    "                        (X, y),\n",
    "                        size,\n",
    "                        None, iters=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a543f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa987cfe",
   "metadata": {},
   "source": [
    "# Collect analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ffd69a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6c53193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['Random forest'] = rf_dframe.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['Hypernet'] = hyper_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['HypernetPCA'] = nn_pca_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['Dropout_1'] = nn1_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['Dropout_2'] = nn2_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['Dropout_3'] = nn3_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['Node'] = node_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['XGBoost'] = xgb_dframe.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "be6d4b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['Hypernet'] = hyper_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['HypernetPCA'] = nn_pca_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f523ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">Hypernet</th>\n",
       "      <th>0</th>\n",
       "      <td>68.237288</td>\n",
       "      <td>32.215896</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.790997</td>\n",
       "      <td>36.633142</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 score</th>\n",
       "      <td>60.624845</td>\n",
       "      <td>23.615921</td>\n",
       "      <td>78.934010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>69.614103</td>\n",
       "      <td>29.732611</td>\n",
       "      <td>97.321429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>64.790997</td>\n",
       "      <td>36.633142</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>66.468647</td>\n",
       "      <td>6.723643</td>\n",
       "      <td>72.607261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>66.514142</td>\n",
       "      <td>6.355408</td>\n",
       "      <td>72.777263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>78.859393</td>\n",
       "      <td>14.991318</td>\n",
       "      <td>99.017930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">HypernetPCA</th>\n",
       "      <th>0</th>\n",
       "      <td>83.762712</td>\n",
       "      <td>25.112445</td>\n",
       "      <td>98.983051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52.829582</td>\n",
       "      <td>25.353289</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 score</th>\n",
       "      <td>60.412931</td>\n",
       "      <td>9.730186</td>\n",
       "      <td>78.580482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>85.499881</td>\n",
       "      <td>12.913877</td>\n",
       "      <td>97.637795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>52.829582</td>\n",
       "      <td>25.353289</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>67.887789</td>\n",
       "      <td>2.455242</td>\n",
       "      <td>72.112211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>68.296147</td>\n",
       "      <td>2.329741</td>\n",
       "      <td>71.746689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>88.759605</td>\n",
       "      <td>7.702046</td>\n",
       "      <td>97.510491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    mean        std         max\n",
       "            Class                                              \n",
       "Hypernet    0                  68.237288  32.215896  100.000000\n",
       "            1                  64.790997  36.633142  100.000000\n",
       "            F1 score           60.624845  23.615921   78.934010\n",
       "            Precision          69.614103  29.732611   97.321429\n",
       "            Recall             64.790997  36.633142  100.000000\n",
       "            Total              66.468647   6.723643   72.607261\n",
       "            balanced_accuracy  66.514142   6.355408   72.777263\n",
       "            roc_auc            78.859393  14.991318   99.017930\n",
       "HypernetPCA 0                  83.762712  25.112445   98.983051\n",
       "            1                  52.829582  25.353289  100.000000\n",
       "            F1 score           60.412931   9.730186   78.580482\n",
       "            Precision          85.499881  12.913877   97.637795\n",
       "            Recall             52.829582  25.353289  100.000000\n",
       "            Total              67.887789   2.455242   72.112211\n",
       "            balanced_accuracy  68.296147   2.329741   71.746689\n",
       "            roc_auc            88.759605   7.702046   97.510491"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models_df=pd.concat(d, axis=0)\n",
    "all_models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f076f2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.237288</td>\n",
       "      <td>32.215896</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.790997</td>\n",
       "      <td>36.633142</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 score</th>\n",
       "      <td>60.624845</td>\n",
       "      <td>23.615921</td>\n",
       "      <td>78.934010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>69.614103</td>\n",
       "      <td>29.732611</td>\n",
       "      <td>97.321429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>64.790997</td>\n",
       "      <td>36.633142</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>66.468647</td>\n",
       "      <td>6.723643</td>\n",
       "      <td>72.607261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>66.514142</td>\n",
       "      <td>6.355408</td>\n",
       "      <td>72.777263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>78.859393</td>\n",
       "      <td>14.991318</td>\n",
       "      <td>99.017930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mean        std         max\n",
       "Class                                              \n",
       "0                  68.237288  32.215896  100.000000\n",
       "1                  64.790997  36.633142  100.000000\n",
       "F1 score           60.624845  23.615921   78.934010\n",
       "Precision          69.614103  29.732611   97.321429\n",
       "Recall             64.790997  36.633142  100.000000\n",
       "Total              66.468647   6.723643   72.607261\n",
       "balanced_accuracy  66.514142   6.355408   72.777263\n",
       "roc_auc            78.859393  14.991318   99.017930"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['Hypernet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d466404a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aac13dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f8b898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "60823a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UXrV5UxyhTK3cyQNG6BDuc4bE'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['COMET_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1f9da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "80d25d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_df.to_csv(f\"{DATA}_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0654fd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.com/abulenok/hypernet-uci-tune/0a5a20a890a54e5fa65426abdd408482\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'web': 'https://www.comet.com/api/asset/download?assetId=ddc76235360a4b8cb5b7ed81796c7f0f&experimentKey=0a5a20a890a54e5fa65426abdd408482',\n",
       " 'api': 'https://www.comet.com/api/rest/v2/experiment/asset/get-asset?assetId=ddc76235360a4b8cb5b7ed81796c7f0f&experimentKey=0a5a20a890a54e5fa65426abdd408482',\n",
       " 'assetId': 'ddc76235360a4b8cb5b7ed81796c7f0f'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = Experiment(os.environ.get(\"COMET_KEY\"), 'hypernet-uci-tune')\n",
    "# exp.log_parameters({\"epochs\": epochs, \"mask_size\": mask_size, \"masks_no\": masks_no, \"data_size\": data_size})\n",
    "exp.add_tag(f\"hypernet-tune2{DATA}\")\n",
    "exp.log_table(f\"{DATA}_metrics.csv\", all_models_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdbf166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cc3246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e6b6d6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hill-Valley-without-noise_metrics.csv'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{DATA}_metrics.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9a061329",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_df_tmp = pd.read_csv(f\"{DATA}_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eba9685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e39d56bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Class</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>0</td>\n",
       "      <td>53.559322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.559322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>1</td>\n",
       "      <td>61.093248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.093248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>59.561129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.561129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>Precision</td>\n",
       "      <td>58.103976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.103976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>Recall</td>\n",
       "      <td>61.093248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.093248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Precision</td>\n",
       "      <td>65.191740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.191740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Recall</td>\n",
       "      <td>71.061093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.061093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Total</td>\n",
       "      <td>65.676568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.676568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>65.530547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.530547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>71.282359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.282359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0              Class       mean  std        max\n",
       "0   Random forest                  0  53.559322  0.0  53.559322\n",
       "1   Random forest                  1  61.093248  0.0  61.093248\n",
       "2   Random forest           F1 score  59.561129  0.0  59.561129\n",
       "3   Random forest          Precision  58.103976  0.0  58.103976\n",
       "4   Random forest             Recall  61.093248  0.0  61.093248\n",
       "..            ...                ...        ...  ...        ...\n",
       "59        XGBoost          Precision  65.191740  0.0  65.191740\n",
       "60        XGBoost             Recall  71.061093  0.0  71.061093\n",
       "61        XGBoost              Total  65.676568  0.0  65.676568\n",
       "62        XGBoost  balanced_accuracy  65.530547  0.0  65.530547\n",
       "63        XGBoost            roc_auc  71.282359  0.0  71.282359\n",
       "\n",
       "[64 rows x 5 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models_df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7beddf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = all_models_df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c404f129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Class</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>0</td>\n",
       "      <td>53.559322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.559322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>1</td>\n",
       "      <td>61.093248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.093248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>59.561129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.561129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>Precision</td>\n",
       "      <td>58.103976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.103976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>Recall</td>\n",
       "      <td>61.093248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.093248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Precision</td>\n",
       "      <td>65.191740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.191740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Recall</td>\n",
       "      <td>71.061093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.061093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Total</td>\n",
       "      <td>65.676568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.676568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>65.530547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.530547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>71.282359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.282359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0              Class       mean  std        max\n",
       "0   Random forest                  0  53.559322  0.0  53.559322\n",
       "1   Random forest                  1  61.093248  0.0  61.093248\n",
       "2   Random forest           F1 score  59.561129  0.0  59.561129\n",
       "3   Random forest          Precision  58.103976  0.0  58.103976\n",
       "4   Random forest             Recall  61.093248  0.0  61.093248\n",
       "..            ...                ...        ...  ...        ...\n",
       "59        XGBoost          Precision  65.191740  0.0  65.191740\n",
       "60        XGBoost             Recall  71.061093  0.0  71.061093\n",
       "61        XGBoost              Total  65.676568  0.0  65.676568\n",
       "62        XGBoost  balanced_accuracy  65.530547  0.0  65.530547\n",
       "63        XGBoost            roc_auc  71.282359  0.0  71.282359\n",
       "\n",
       "[64 rows x 5 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1996040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp.rename(columns={tmp.columns[0]: DATA})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b9ee21a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hill-Valley-without-noise</th>\n",
       "      <th>Class</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>57.326285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.326285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hypernet</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>70.593656</td>\n",
       "      <td>4.897924</td>\n",
       "      <td>79.669737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>HypernetPCA</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>67.491471</td>\n",
       "      <td>4.121086</td>\n",
       "      <td>77.378604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Dropout_1</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>54.059295</td>\n",
       "      <td>1.901047</td>\n",
       "      <td>58.720366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Dropout_2</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>54.796474</td>\n",
       "      <td>2.549261</td>\n",
       "      <td>59.113848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Dropout_3</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>56.386424</td>\n",
       "      <td>2.888482</td>\n",
       "      <td>61.583193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Node</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>52.710311</td>\n",
       "      <td>0.335881</td>\n",
       "      <td>53.109161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>65.530547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.530547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hill-Valley-without-noise              Class       mean       std  \\\n",
       "6              Random forest  balanced_accuracy  57.326285  0.000000   \n",
       "14                  Hypernet  balanced_accuracy  70.593656  4.897924   \n",
       "22               HypernetPCA  balanced_accuracy  67.491471  4.121086   \n",
       "30                 Dropout_1  balanced_accuracy  54.059295  1.901047   \n",
       "38                 Dropout_2  balanced_accuracy  54.796474  2.549261   \n",
       "46                 Dropout_3  balanced_accuracy  56.386424  2.888482   \n",
       "54                      Node  balanced_accuracy  52.710311  0.335881   \n",
       "62                   XGBoost  balanced_accuracy  65.530547  0.000000   \n",
       "\n",
       "          max  \n",
       "6   57.326285  \n",
       "14  79.669737  \n",
       "22  77.378604  \n",
       "30  58.720366  \n",
       "38  59.113848  \n",
       "46  61.583193  \n",
       "54  53.109161  \n",
       "62  65.530547  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[tmp['Class'] == \"balanced_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b0f287e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49403f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

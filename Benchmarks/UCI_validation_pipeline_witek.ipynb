{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01de83ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc12a648-b80a-4eca-afc3-79331e4db7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fdadf44-450a-4006-ac5a-bed9840409f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/MCB/wwydmanski/miniconda3/envs/torch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_4189342/2881205326.py:17: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use(\"seaborn\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from tqdm import trange\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import sklearn\n",
    "import time\n",
    "import datetime\n",
    "from hypertab_benchmark_utils import *\n",
    "\n",
    "plt.style.use(\"seaborn\")\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a37b70c-292b-4c14-85ed-3c93020dc182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3085114d-cf61-4625-97c5-10f34c00d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypertab import HypernetworkPCA, TrainingModes, Hypernetwork\n",
    "from hypertab.interfaces import HypernetworkSklearnInterface\n",
    "# from ipynb.fs.defs.MNIST_benchmark import test_model\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d62c6026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, balanced_accuracy_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f84a62eb-e16d-4519-ad76-2237037833c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhopper\n",
    "import sklearn.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d12953cc-1ec5-46a9-933a-714e5ceafd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from loguru import logger\n",
    "\n",
    "logger.add(\"log.txt\", format='{time:YYYY-MM-DD HH:mm:ss.SSS} | {message}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04d1ae25-987c-4043-9771-829c928723de",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE=\"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72ab68a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "GS_METRIC = 'balanced_accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82db70f7",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30a5727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RUN = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c287f46",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8e64dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_tuple(X, y, train_size=None):\n",
    "    if isinstance(X, tuple) and isinstance(y, tuple):\n",
    "        X_train, X_test = X\n",
    "        y_train, y_test = y\n",
    "    else:    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size, stratify=y)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdc5ffdd-e04d-425f-8d6c-bd8456644faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "def prepare_data(X, y, size=None):\n",
    "    if isinstance(X, tuple) and isinstance(y, tuple):\n",
    "        X_train, X_test = X\n",
    "        y_train, y_test = y\n",
    "    else:    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=size, stratify=y)\n",
    "    # X_train, y_train = imblearn.over_sampling.RandomOverSampler(random_state=42).fit_resample(X_train, y_train)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = [torch.from_numpy(x) for x in [X_train, X_test, y_train, y_test]]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d223075b-b7d8-414e-97c9-ade8bda5f0fd",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9f92f86-4c40-492c-8d48-f23efa85eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5aa90ca0-8a00-4491-b111-ce7eee0e9c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _summarize_results(y_pred, y_score, y_test, labels):\n",
    "    results = []\n",
    "    for idx, label in enumerate(labels):\n",
    "        y_pred_filt = y_pred[y_test==idx]\n",
    "        y_test_filt = y_test[y_test==idx]\n",
    "#         acc = (y_pred_filt==y_test_filt.numpy()).sum()/len(y_test_filt)*100\n",
    "        acc = accuracy_score(y_test_filt, y_pred_filt)\n",
    "        results.append({\n",
    "            \"Class\": label,\n",
    "            \"Metric\": acc\n",
    "        })\n",
    "        \n",
    "#     acc = (y_pred==y_test.numpy()).sum()/len(y_test)*100 \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    results.append({\n",
    "        \"Class\": \"Total\",\n",
    "        \"Metric\": acc\n",
    "    })\n",
    "    \n",
    "    results.append({\n",
    "        \"Class\": \"balanced_accuracy\",\n",
    "        \"Metric\": balanced_accuracy_score(y_test, torch.from_numpy(y_pred)).item()*100\n",
    "    })\n",
    "    \n",
    "    try:\n",
    "        results.append({\n",
    "            \"Class\": \"F1 score\",\n",
    "            \"Metric\": f1_score(y_test, torch.from_numpy(y_pred)).item()*100\n",
    "        })\n",
    "        results.append({\n",
    "            \"Class\": \"roc_auc\",\n",
    "            \"Metric\": roc_auc_score(y_test, torch.from_numpy(y_score[:, 1])).item()*100\n",
    "        })\n",
    "        results.append({\n",
    "            \"Class\": \"Precision\",\n",
    "            \"Metric\": precision_score(y_test, torch.from_numpy(y_pred)).item()*100\n",
    "        })\n",
    "        results.append({\n",
    "            \"Class\": \"Recall\",\n",
    "            \"Metric\": recall_score(y_test, torch.from_numpy(y_pred)).item()*100\n",
    "        })\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return results\n",
    "\n",
    "def test_model(model_fn, data, train_size, label_encoder=None, iters=10, as_numpy=False):\n",
    "    if TEST_RUN:\n",
    "        iters = 1\n",
    "        \n",
    "    if label_encoder is not None:\n",
    "        labels = label_encoder.classes_\n",
    "    else:\n",
    "        labels = sorted(pd.unique(data[1][0] if isinstance(data[1], tuple) else data[1]))\n",
    "\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    X, y = data\n",
    "\n",
    "    for i in range(iters):\n",
    "        X_train, X_test, y_train, y_test = prepare_data(*data, train_size)\n",
    "        print('iter', i+1, 'of', iters, 'X_train shape', X_train.shape)\n",
    "\n",
    "        model = model_fn()\n",
    "\n",
    "        if as_numpy:\n",
    "            model.fit(X_train.numpy(), y_train.numpy());\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        y_score = model.predict_proba(X_test)\n",
    "        results.extend(_summarize_results(y_pred, y_score, y_test, labels))\n",
    "\n",
    "    dframe = pd.DataFrame.from_dict(results)\n",
    "    # sns.violinplot(data=dframe[dframe[\"Class\"]!=\"Loss\"], y=\"Class\", x=\"Metric\", orient='h')\n",
    "    return dframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f351cf",
   "metadata": {},
   "source": [
    "### Param search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecee618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyhopper_best_params(model_fn, param_grid, data, train_size, metric=GS_METRIC, time=\"30m\", default_params={}):\n",
    "    if TEST_RUN:\n",
    "        time = 60\n",
    "        if 'epochs' in param_grid:\n",
    "            param_grid[\"epochs\"] = pyhopper.choice([10])\n",
    "    \n",
    "    X, y = data\n",
    "    print('pyhopper', X.shape, y.shape, train_size)\n",
    "        \n",
    "    def objective(params):\n",
    "    #     print(\"Training...\")\n",
    "        print('params',params)\n",
    "        model_results = test_model(\n",
    "                        model_fn(\n",
    "                            **default_params,\n",
    "                            **params\n",
    "                        ),\n",
    "                        (X, y),\n",
    "                        train_size,\n",
    "                        None, 5)\n",
    "        with open(f\"params/{DATA}_{model_fn.__name__}_params.txt\", \"a\") as f:\n",
    "            f.write(str(params) + \", \" + str(model_results[model_results[\"Class\"]==metric][\"Metric\"].mean()) + \"\\n\")\n",
    "        return model_results[model_results[\"Class\"]==metric][\"Metric\"].mean()\n",
    "\n",
    "    from pyhopper.callbacks import History\n",
    "    search = pyhopper.Search(param_grid)\n",
    "\n",
    "    best_params = search.run(objective, \"maximize\", time, n_jobs=1, seeding_ratio=0.5)\n",
    "    \n",
    "    with open(f\"{DATA}_{model_fn.__name__}_best_params.txt\", \"a\") as f:\n",
    "            f.write(str(best_params))\n",
    "    \n",
    "    print(f\"{DATA}_{model_fn.__name__}_{best_params}\")\n",
    "    return best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "026edf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b789cbd2",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "DATA = \"Glass\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2d4d55",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d47877e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214, 10) 6 149\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import sklearn.datasets\n",
    "\n",
    "if DATA == \"BreastCancer\":\n",
    "    dataset = sklearn.datasets.load_breast_cancer()\n",
    "    X = dataset['data']\n",
    "    y = dataset['target']\n",
    "elif DATA == \"Connectionist\":\n",
    "    dataset = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\", header=None)\n",
    "    X = dataset.values[:, :-1].astype(float)\n",
    "    y = dataset.values[:, -1]\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "elif DATA == \"Dermatology\":\n",
    "    dataset = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/dermatology/dermatology.data\", header=None, na_values=\"?\").dropna()\n",
    "    X = dataset.values[:, :-1].astype(float)\n",
    "    y = dataset.values[:, -1].astype(int) - 1\n",
    "elif DATA == \"Glass\":\n",
    "    dataset = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data\", header=None, na_values=\"?\").dropna()\n",
    "    X = dataset.values[:, :-1].astype(float)\n",
    "    y = dataset.values[:, -1].astype(int)\n",
    "    y = LabelEncoder().fit_transform(y).astype(int)\n",
    "    \n",
    "elif DATA == \"Cleveland\":\n",
    "    dataset = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\", header=None, na_values=\"?\").dropna()\n",
    "    X = dataset.values[:, :-1].astype(float)\n",
    "    y = dataset.values[:, -1].astype(int)\n",
    "    y = LabelEncoder().fit_transform(y).astype(int)\n",
    "\n",
    "elif DATA == \"CNAE9\":\n",
    "    dataset = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00233/CNAE-9.data\", header=None, na_values=\"?\").dropna()\n",
    "    X = dataset.values[:, 1:].astype(float)\n",
    "    y = dataset.values[:, 0].astype(int)\n",
    "    y = LabelEncoder().fit_transform(y).astype(int)\n",
    "\n",
    "max_size = int(len(X)*0.7)\n",
    "print(X.shape, len(np.unique(y)), max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85f1625b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 70, 1: 76, 2: 17, 3: 13, 4: 9, 5: 29}\n",
      "n_classes 6\n",
      "n_features 10\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(np.unique(y))\n",
    "n_features = X.shape[1]\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "print('n_classes', n_classes)\n",
    "print('n_features', n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "649b158c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_max_size 128\n",
      "eval_max_size 171\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, stratify=y, random_state=42)\n",
    "\n",
    "eval_max_size = int(len(X_train))\n",
    "train_max_size = int(len(X_train) * 0.75)\n",
    "print('train_max_size', train_max_size)\n",
    "print('eval_max_size', eval_max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2de7b1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484716b4",
   "metadata": {},
   "source": [
    "## HyperTab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e25919f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypertab_fn(epochs=150, masks_no=100, mask_size=100, target_size=100, lr=3e-4, batch_size=64, verbose=False):\n",
    "    def _inner():\n",
    "        hypernet = Hypernetwork(\n",
    "                        target_architecture=[(mask_size, target_size), (target_size, n_classes)],\n",
    "                        test_nodes=masks_no,\n",
    "                        architecture=torch.nn.Sequential(torch.nn.Linear(n_features, 32), \n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 128),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Dropout(),\n",
    "                            torch.nn.Linear(128, 128),\n",
    "                            torch.nn.ReLU(),\n",
    "                        ),\n",
    "                        mode=TrainingModes.CARTHESIAN,\n",
    "                    ).to(DEVICE)    \n",
    "        hypernet = hypernet.train()\n",
    "\n",
    "        network = HypernetworkSklearnInterface(hypernet, device=DEVICE, epochs=epochs, batch_size=batch_size, verbose=verbose, lr=3e-4)\n",
    "        return network\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8c9e3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyhopper (171, 10) (171,) 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | [00:00<?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 10:00 (m:s)\n",
      "params {'epochs': 100, 'masks_no': 10, 'mask_size': 2, 'target_size': 5, 'batch_size': 32}\n",
      "iter 1 of 5 X_train shape torch.Size([128, 10])\n",
      "Remote process caught exception in objective function: \n",
      "======================================================\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/MCB/wwydmanski/miniconda3/envs/torch/lib/python3.9/site-packages/pyhopper/parallel.py\", line 227, in execute\n",
      "    iter_or_result = objective_function(candidate, **kwargs)\n",
      "  File \"/tmp/ipykernel_4189342/436130538.py\", line 13, in objective\n",
      "    model_results = test_model(\n",
      "  File \"/tmp/ipykernel_4189342/3179501506.py\", line 73, in test_model\n",
      "    results.extend(_summarize_results(y_pred, y_score, y_test, labels))\n",
      "  File \"/tmp/ipykernel_4189342/3179501506.py\", line 28, in _summarize_results\n",
      "    \"Metric\": f1_score(y_test, torch.from_numpy(y_pred)).item()*100\n",
      "NameError: name 'f1_score' is not defined\n",
      "\n",
      "======================================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Pyhopper - Remote process caught exception",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m param_grid \u001b[39m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m: pyhopper\u001b[39m.\u001b[39mchoice([\u001b[39m100\u001b[39m, \u001b[39m150\u001b[39m, \u001b[39m200\u001b[39m, \u001b[39m300\u001b[39m, \u001b[39m400\u001b[39m, \u001b[39m500\u001b[39m]),\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmasks_no\u001b[39m\u001b[39m\"\u001b[39m: pyhopper\u001b[39m.\u001b[39mchoice([\u001b[39m10\u001b[39m, \u001b[39m20\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m80\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39m150\u001b[39m, \u001b[39m200\u001b[39m]),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m\"\u001b[39m: pyhopper\u001b[39m.\u001b[39mchoice([\u001b[39m32\u001b[39m, \u001b[39m64\u001b[39m]),\n\u001b[1;32m      7\u001b[0m }\n\u001b[1;32m      8\u001b[0m \u001b[39m#{'epochs': 100, 'masks_no': 10, 'mask_size': 2, 'target_size': 5, 'lr': 3e-05, 'batch_size': 32}\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m hp_best_params \u001b[39m=\u001b[39m pyhopper_best_params(\n\u001b[1;32m     10\u001b[0m     get_parametrized_hypertab_fn(DEVICE\u001b[39m=\u001b[39;49mDEVICE, n_classes\u001b[39m=\u001b[39;49mn_classes, n_features\u001b[39m=\u001b[39;49mn_features), param_grid, data\u001b[39m=\u001b[39;49m(X_train, y_train), train_size\u001b[39m=\u001b[39;49mtrain_max_size, time\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m10m\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m hp_best_params\n",
      "Cell \u001b[0;32mIn[21], line 28\u001b[0m, in \u001b[0;36mpyhopper_best_params\u001b[0;34m(model_fn, param_grid, data, train_size, metric, time, default_params)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyhopper\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m History\n\u001b[1;32m     26\u001b[0m search \u001b[39m=\u001b[39m pyhopper\u001b[39m.\u001b[39mSearch(param_grid)\n\u001b[0;32m---> 28\u001b[0m best_params \u001b[39m=\u001b[39m search\u001b[39m.\u001b[39;49mrun(objective, \u001b[39m\"\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m\"\u001b[39;49m, time, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, seeding_ratio\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m)\n\u001b[1;32m     30\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mDATA\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mmodel_fn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m_best_params.txt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     31\u001b[0m         f\u001b[39m.\u001b[39mwrite(\u001b[39mstr\u001b[39m(best_params))\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/pyhopper/search.py:895\u001b[0m, in \u001b[0;36mSearch.run\u001b[0;34m(self, objective_function, direction, runtime, steps, endless_mode, seeding_steps, seeding_runtime, seeding_ratio, pruner, n_jobs, quiet, ignore_nans, mp_backend, enable_rejection_cache, callbacks, start_temperature, end_temperature, kwargs, checkpoint_path, overwrite_checkpoint, keep_history)\u001b[0m\n\u001b[1;32m    890\u001b[0m     c\u001b[39m.\u001b[39mon_search_start(\u001b[39mself\u001b[39m)\n\u001b[1;32m    892\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_best_f \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_queue_count \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    893\u001b[0m     \u001b[39m# Evaluate initial guess, this gives the user some estimate of how much PyHopper could tune the parameters\u001b[39;00m\n\u001b[1;32m    894\u001b[0m     \u001b[39m# self._fill_missing_init_values()\u001b[39;00m\n\u001b[0;32m--> 895\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_submit_candidate(\n\u001b[1;32m    896\u001b[0m         objective_function,\n\u001b[1;32m    897\u001b[0m         CandidateType\u001b[39m.\u001b[39;49mINIT,\n\u001b[1;32m    898\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_best_solution,\n\u001b[1;32m    899\u001b[0m         kwargs,\n\u001b[1;32m    900\u001b[0m     )\n\u001b[1;32m    901\u001b[0m     schedule\u001b[39m.\u001b[39mincrement_step()\n\u001b[1;32m    903\u001b[0m current_temperature \u001b[39m=\u001b[39m schedule\u001b[39m.\u001b[39mtemperature\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/pyhopper/search.py:644\u001b[0m, in \u001b[0;36mSearch._submit_candidate\u001b[0;34m(self, objective_function, candidate_type, candidate, kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m     candidate_result \u001b[39m=\u001b[39m execute(\n\u001b[1;32m    638\u001b[0m         objective_function,\n\u001b[1;32m    639\u001b[0m         candidate,\n\u001b[1;32m    640\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_context\u001b[39m.\u001b[39mpruner,\n\u001b[1;32m    641\u001b[0m         kwargs,\n\u001b[1;32m    642\u001b[0m     )\n\u001b[1;32m    643\u001b[0m     param_info\u001b[39m.\u001b[39mfinished_at \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 644\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_async_result_ready(candidate, param_info, candidate_result)\n\u001b[1;32m    645\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    646\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_context\u001b[39m.\u001b[39mtask_executor\u001b[39m.\u001b[39msubmit(\n\u001b[1;32m    647\u001b[0m         objective_function,\n\u001b[1;32m    648\u001b[0m         candidate,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m         kwargs,\n\u001b[1;32m    652\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/pyhopper/search.py:689\u001b[0m, in \u001b[0;36mSearch._async_result_ready\u001b[0;34m(self, candidate, param_info, candidate_result)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[39mprint\u001b[39m(candidate_result\u001b[39m.\u001b[39merror)\n\u001b[1;32m    686\u001b[0m         \u001b[39mprint\u001b[39m(\n\u001b[1;32m    687\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m======================================================\u001b[39m\u001b[39m\"\u001b[39m, flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    688\u001b[0m         )\n\u001b[0;32m--> 689\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPyhopper - Remote process caught exception\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    690\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[39mif\u001b[39;00m candidate_result\u001b[39m.\u001b[39mis_nan \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_context\u001b[39m.\u001b[39mignore_nans:\n",
      "\u001b[0;31mValueError\u001b[0m: Pyhopper - Remote process caught exception"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"epochs\": pyhopper.choice([100, 150, 200, 300, 400, 500]),\n",
    "    \"masks_no\": pyhopper.choice([10, 20, 50, 80, 100, 150, 200]),\n",
    "    \"mask_size\": pyhopper.choice([2, 3, 5, 8]),\n",
    "    \"target_size\": pyhopper.choice([5, 10, 20, 50]),\n",
    "    \"batch_size\": pyhopper.choice([32, 64]),\n",
    "}\n",
    "#{'epochs': 100, 'masks_no': 10, 'mask_size': 2, 'target_size': 5, 'lr': 3e-05, 'batch_size': 32}\n",
    "hp_best_params = pyhopper_best_params(\n",
    "    get_parametrized_hypertab_fn(DEVICE=DEVICE, n_classes=n_classes, n_features=n_features), param_grid, data=(X_train, y_train), train_size=train_max_size, time=\"10m\"\n",
    ")\n",
    "hp_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e32c64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:57<00:00,  3.48it/s]\n",
      "100%|██████████| 200/200 [00:43<00:00,  4.62it/s]\n",
      "100%|██████████| 200/200 [00:44<00:00,  4.53it/s]\n",
      "100%|██████████| 200/200 [00:44<00:00,  4.50it/s]\n",
      "100%|██████████| 200/200 [00:43<00:00,  4.64it/s]\n",
      "100%|██████████| 200/200 [00:42<00:00,  4.75it/s]\n",
      "100%|██████████| 200/200 [00:42<00:00,  4.66it/s]\n",
      "100%|██████████| 200/200 [00:43<00:00,  4.59it/s]\n",
      "100%|██████████| 200/200 [00:44<00:00,  4.54it/s]\n",
      "100%|██████████| 200/200 [00:45<00:00,  4.42it/s]\n"
     ]
    }
   ],
   "source": [
    "epochs = hp_best_params['epochs']\n",
    "masks_no = hp_best_params['masks_no']\n",
    "mask_size = hp_best_params['mask_size']\n",
    "target_size = hp_best_params['target_size']\n",
    "lr = 3e-4\n",
    "batch_size = hp_best_params['batch_size']\n",
    "\n",
    "full_res = []\n",
    "for i in range(10):\n",
    "    model = get_parametrized_hypertab_fn(DEVICE=DEVICE, n_classes=n_classes, n_features=n_features)(\n",
    "        epochs, \n",
    "        masks_no, \n",
    "        mask_size, \n",
    "        target_size, \n",
    "        lr,\n",
    "        batch_size=batch_size,\n",
    "        verbose=True)()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_score = model.predict_proba(X_test)\n",
    "    hyper_results = _summarize_results(y_pred, \n",
    "                                    y_score, \n",
    "                                    torch.from_numpy(y_test), \n",
    "                                    torch.from_numpy(np.unique(y)))\n",
    "    hyper_results = pd.DataFrame(hyper_results)\n",
    "    res = hyper_results[hyper_results[\"Class\"]==\"Total\"].reset_index(drop=True)[\"Metric\"]\n",
    "    full_res.append(res)\n",
    "\n",
    "full_res = pd.DataFrame(full_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "707cc49e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"results/\" + DATA + \"_hypertab.txt\", \"w\") as f:\n",
    "    f.write(f\"{eval_max_size}: {full_res.mean().values[0]:.3f} ~ {full_res.std().values[0]:.2f}, (max: {full_res.max().values[0]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72a59e8",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e39e721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.4'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "xgboost.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04eb6928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xgboost(**params):\n",
    "    random_seed = np.random.randint(1024)\n",
    "    def _inner():\n",
    "        return xgboost.XGBClassifier(\n",
    "            verbosity=0,\n",
    "            random_state=random_seed,\n",
    "            **params\n",
    "        )\n",
    "    return _inner    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b46c8900",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyhopper (166, 60) (166,) 124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | [00:00<?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 10.00 s\n",
      "params {'n_estimators': 50, 'max_depth': 2, 'learning_rate': 0.0010000000000000002, 'min_child_weight': 1, 'gamma': 0}\n",
      "iter 1 of 5 X_train shape torch.Size([124, 60])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/MCB/wwydmanski/miniconda3/envs/torch/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5 X_train shape torch.Size([124, 60])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/MCB/wwydmanski/miniconda3/envs/torch/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5 X_train shape torch.Size([124, 60])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/MCB/wwydmanski/miniconda3/envs/torch/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5 X_train shape torch.Size([124, 60])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/MCB/wwydmanski/miniconda3/envs/torch/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5 X_train shape torch.Size([124, 60])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/MCB/wwydmanski/miniconda3/envs/torch/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "Best f: 66.8 (out of 1 params): 100%|██████████| [00:39<00:00, 0.0 param/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Summary ================\n",
      "Mode              : Best f : Steps : Time\n",
      "----------------  : ----   : ----  : ----\n",
      "Initial solution  : 66.77  : 1     : 40 s\n",
      "----------------  : ----   : ----  : ----\n",
      "Total             : 66.77  : 1     : 40 s\n",
      "=========================================\n",
      "Connectionist_get_xgboost_{'n_estimators': 50, 'max_depth': 2, 'learning_rate': 0.0010000000000000002, 'min_child_weight': 1, 'gamma': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "                'n_estimators': pyhopper.int(50, 3000, multiple_of=50, init=50),\n",
    "                'max_depth': pyhopper.choice([2, 3, 5, 10, 15]),\n",
    "                'learning_rate': pyhopper.float(1e-5,1e-1, log=True),\n",
    "                'min_child_weight': pyhopper.choice([1, 2, 4, 8, 16, 32]),\n",
    "                'gamma': pyhopper.choice([0, 0.001, 0.1, 1]),\n",
    "             }\n",
    "\n",
    "xgbc = get_xgboost()\n",
    "\n",
    "xgbt_best1 = pyhopper_best_params(get_xgboost, param_grid, data=(X_train, y_train), train_size=train_max_size, time=\"10m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53e43c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 50,\n",
       " 'max_depth': 2,\n",
       " 'learning_rate': 0.0010000000000000002,\n",
       " 'min_child_weight': 1,\n",
       " 'gamma': 0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbt_best1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c99a57b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/MCB/wwydmanski/miniconda3/envs/torch/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/home/MCB/wwydmanski/miniconda3/envs/torch/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/home/MCB/wwydmanski/miniconda3/envs/torch/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/home/MCB/wwydmanski/miniconda3/envs/torch/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/home/MCB/wwydmanski/miniconda3/envs/torch/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/home/MCB/wwydmanski/miniconda3/envs/torch/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/home/MCB/wwydmanski/miniconda3/envs/torch/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/home/MCB/wwydmanski/miniconda3/envs/torch/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/home/MCB/wwydmanski/miniconda3/envs/torch/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/home/MCB/wwydmanski/miniconda3/envs/torch/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    }
   ],
   "source": [
    "full_res = []\n",
    "for i in range(10):\n",
    "    model = get_xgboost(**xgbt_best1)()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_score = model.predict_proba(X_test)\n",
    "    hyper_results = _summarize_results(y_pred, \n",
    "                                    y_score, \n",
    "                                    torch.from_numpy(y_test), \n",
    "                                    torch.from_numpy(np.unique(y)))\n",
    "    hyper_results = pd.DataFrame(hyper_results)\n",
    "    res = hyper_results[hyper_results[\"Class\"]==\"Total\"].reset_index(drop=True)[\"Metric\"]\n",
    "    full_res.append(res)\n",
    "\n",
    "full_res = pd.DataFrame(full_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5adf6f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'166: 0.690 ~ 0.00, (max: 0.690)'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{eval_max_size}: {full_res.mean().values[0]:.3f} ~ {full_res.std().values[0]:.2f}, (max: {full_res.max().values[0]:.3f})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6e5fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/\" + DATA + \"_xgboost.txt\", \"w\") as f:\n",
    "    f.write(f\"{eval_max_size}: {full_res.mean().values[0]:.3f} ~ {full_res.std().values[0]:.2f}, (max: {full_res.max().values[0]:.3f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "3a225e7f5f0716c5f43be099f4239af3cbe74609075170a24804707c423adf33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01de83ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc12a648-b80a-4eca-afc3-79331e4db7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fdadf44-450a-4006-ac5a-bed9840409f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from tqdm import trange\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import sklearn\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "plt.style.use(\"seaborn\")\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7585d3a-dff3-43e2-bc0f-f024306021a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a37b70c-292b-4c14-85ed-3c93020dc182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3085114d-cf61-4625-97c5-10f34c00d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabular_hypernet import HypernetworkPCA, TrainingModes, Hypernetwork\n",
    "from tabular_hypernet.modules import SimpleNetwork\n",
    "from tabular_hypernet.training_utils import train_slow_step, train_model, train_carthesian\n",
    "from tabular_hypernet.interfaces import HypernetworkSklearnInterface, SimpleSklearnInterface\n",
    "# from ipynb.fs.defs.MNIST_benchmark import test_model\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d62c6026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f84a62eb-e16d-4519-ad76-2237037833c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d12953cc-1ec5-46a9-933a-714e5ceafd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from loguru import logger\n",
    "\n",
    "logger.add(\"log.txt\", format='{time:YYYY-MM-DD HH:mm:ss.SSS} | {message}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa3c18d1-1d56-4393-9441-245420fb3c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04d1ae25-987c-4043-9771-829c928723de",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE=\"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a1a1e98-a8b4-4df2-aae6-b593fe61667a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from loguru import logger\n",
    "\n",
    "logger.add(\"log_.txt\", format='{time:YYYY-MM-DD HH:mm:ss.SSS} | {message}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ea8ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82db70f7",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d631c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = \"Libras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba2d025f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 90) 15\n"
     ]
    }
   ],
   "source": [
    "if DATA == \"Ionosphere\":\n",
    "    ionosphere = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data', header=None)\n",
    "    ionosphere = ionosphere.drop(1, axis=1)\n",
    "    X = ionosphere.values[:, :-1].astype(float)\n",
    "    y = ionosphere.values[:, -1]\n",
    "    y = LabelEncoder().fit_transform(y).astype(int)\n",
    "    #(351, 33) 2 \n",
    "    GS_METRIC = \"balanced_accuracy\"\n",
    "    \n",
    "elif DATA == \"Libras\":\n",
    "    libras = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/libras/movement_libras.data', header=None)\n",
    "    X = libras.values[:, :-1].astype(float)\n",
    "    y = libras.values[:, -1].astype(int)\n",
    "    y = LabelEncoder().fit_transform(y).astype(int)\n",
    "    #(360, 90) 15\n",
    "    GS_METRIC = \"balanced_accuracy\"\n",
    "    \n",
    "elif DATA == \"Lymphography\":\n",
    "    lymphography = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/lymphography/lymphography.data', header=None)\n",
    "    X = lymphography.values[:, 1:].astype(float)\n",
    "    y = lymphography.values[:, 0].astype(int)\n",
    "    y = LabelEncoder().fit_transform(y).astype(int)\n",
    "    #(148, 18) 4\n",
    "    GS_METRIC = \"balanced_accuracy\"\n",
    "    \n",
    "print(X.shape, len(np.unique(y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e85869a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = len(np.unique(y))\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6305ff4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 24, 1: 24, 2: 24, 3: 24, 4: 24, 5: 24, 6: 24, 7: 24, 8: 24, 9: 24, 10: 24, 11: 24, 12: 24, 13: 24, 14: 24}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe2c8e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = X.shape[1]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4777a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = int(len(X)*0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38876ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 360 | max training size: 251\n"
     ]
    }
   ],
   "source": [
    "print('dataset size:', len(X), '|', 'max training size:', max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30a5727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RUN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507c32bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c287f46",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdc5ffdd-e04d-425f-8d6c-bd8456644faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "np.random.seed(42)\n",
    "\n",
    "def prepare_data(X, y, size=None):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=size, stratify=y)\n",
    "    # X_train, y_train = imblearn.over_sampling.RandomOverSampler(random_state=42).fit_resample(X_train, y_train)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = [torch.from_numpy(x) for x in [X_train, X_test, y_train, y_test]]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca0a827a-0e1f-4f5c-b15d-3354f075021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data(X, y, size=max_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d223075b-b7d8-414e-97c9-ade8bda5f0fd",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9f92f86-4c40-492c-8d48-f23efa85eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5aa90ca0-8a00-4491-b111-ce7eee0e9c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _summarize_results(y_pred, y_score, y_test, labels):\n",
    "    results = []\n",
    "    for idx, label in enumerate(labels):\n",
    "        y_pred_filt = y_pred[y_test==idx]\n",
    "        y_test_filt = y_test[y_test==idx]\n",
    "        acc = (y_pred_filt==y_test_filt.numpy()).sum()/len(y_test_filt)*100\n",
    "        results.append({\n",
    "            \"Class\": label,\n",
    "            \"Metric\": acc\n",
    "        })\n",
    "        \n",
    "    acc = (y_pred==y_test.numpy()).sum()/len(y_test)*100    \n",
    "    results.append({\n",
    "        \"Class\": \"Total\",\n",
    "        \"Metric\": acc\n",
    "    })\n",
    "    \n",
    "    \n",
    "    results.append({\n",
    "        \"Class\": \"balanced_accuracy\",\n",
    "        \"Metric\": balanced_accuracy_score(y_test, torch.from_numpy(y_pred)).item()*100\n",
    "    })\n",
    "    \n",
    "    try:\n",
    "        results.append({\n",
    "            \"Class\": \"F1 score\",\n",
    "            \"Metric\": f1_score(y_test, torch.from_numpy(y_pred)).item()*100\n",
    "        })\n",
    "        results.append({\n",
    "            \"Class\": \"roc_auc\",\n",
    "            \"Metric\": roc_auc_score(y_test, torch.from_numpy(y_score[:, 1])).item()*100\n",
    "        })\n",
    "        results.append({\n",
    "            \"Class\": \"Precision\",\n",
    "            \"Metric\": precision_score(y_test, torch.from_numpy(y_pred)).item()*100\n",
    "        })\n",
    "        results.append({\n",
    "            \"Class\": \"Recall\",\n",
    "            \"Metric\": recall_score(y_test, torch.from_numpy(y_pred)).item()*100\n",
    "        })\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return results\n",
    "\n",
    "def test_model(model_fn, data, train_size, label_encoder=None, iters=10, as_numpy=False):\n",
    "    if TEST_RUN:\n",
    "        iters = 1\n",
    "        \n",
    "    if label_encoder is not None:\n",
    "        labels = label_encoder.classes_\n",
    "    else:\n",
    "        labels = sorted(pd.unique(data[1]))\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for i in range(iters):\n",
    "        print('iter', i+1, 'of', iters)\n",
    "        X_train, X_test, y_train, y_test = prepare_data(*data, train_size)\n",
    "        \n",
    "        model = model_fn()\n",
    "\n",
    "        if as_numpy:\n",
    "            model.fit(X_train.numpy(), y_train.numpy());\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        y_score = model.predict_proba(X_test)\n",
    "        results.extend(_summarize_results(y_pred, y_score, y_test, labels))\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    dframe = pd.DataFrame.from_dict(results)\n",
    "#     sns.violinplot(data=dframe[dframe[\"Class\"]!=\"Loss\"], y=\"Class\", x=\"Metric\", orient='h')\n",
    "    return dframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f351cf",
   "metadata": {},
   "source": [
    "### Param search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1a95790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def grid_search_best_params(model_fn, param_grid, data_size=max_size, scoring=GS_METRIC):\n",
    "#     if TEST_RUN:\n",
    "#         tmp = {k: [v[0]] for k, v in param_grid.items()}\n",
    "#         param_grid = tmp\n",
    "        \n",
    "#     X_train, X_test, y_train, y_test = prepare_data(X, y, data_size)\n",
    "\n",
    "#     cv_clf = GridSearchCV(\n",
    "#         estimator=model_fn(), \n",
    "#         param_grid=param_grid,\n",
    "#         scoring=scoring, \n",
    "#         return_train_score=True,\n",
    "#         verbose=1, \n",
    "#         cv=5,\n",
    "#     )\n",
    "\n",
    "#     res = cv_clf.fit(X_train, y_train)\n",
    "\n",
    "#     print(f'best params for {DATA}', res.best_params_)\n",
    "#     print('mean_train_score', cv_clf.cv_results_['mean_train_score'].mean())\n",
    "#     print('std_train_score', cv_clf.cv_results_['std_train_score'].mean())\n",
    "\n",
    "#     predictions = cv_clf.predict(X_test) \n",
    "#     print(classification_report(y_test, predictions))\n",
    "    \n",
    "#     with open(f\"{DATA}_{model_fn.__name__}_best_params.txt\", \"a\") as f:\n",
    "#             f.write(str(res.best_params_) + \", \" + str(balanced_accuracy_score(y_test, predictions)) + \"\\n\")\n",
    "    \n",
    "#     print(f\"{DATA}_{model_fn.__name__}_{res.best_params_}\")\n",
    "    \n",
    "#     return res.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ecee618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyhopper_best_params(model_fn, param_grid, data_size=GS_DATA_SIZE, metric=GS_METRIC, time=\"30m\", default_params={}, n_jobs=1):\n",
    "    if TEST_RUN:\n",
    "        time = 30\n",
    "        if 'epochs' in param_grid:\n",
    "            param_grid[\"epochs\"] = pyhopper.choice([10])\n",
    "        \n",
    "    logger.info(f\"pyhopper_best_params {model_fn.__name__}\")\n",
    "    \n",
    "    def objective(params):\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        model_results = test_model(\n",
    "                        model_fn(\n",
    "                            **default_params,\n",
    "                            **params\n",
    "                        ),\n",
    "                        (X, y),\n",
    "                        data_size,\n",
    "                        None, 5)\n",
    "        with open(f\"{DATA}_{model_fn.__name__}_params.txt\", \"a\") as f:\n",
    "            f.write(str(datetime.datetime.now()) + \", \" + str(params) + \", \" + str(model_results[model_results[\"Class\"]==metric][\"Metric\"].mean()) + \"\\n\")\n",
    "        return model_results[model_results[\"Class\"]==metric][\"Metric\"].mean()\n",
    "\n",
    "    from pyhopper.callbacks import History\n",
    "    search = pyhopper.Search(param_grid)\n",
    "\n",
    "    best_params = search.run(objective, \"maximize\", time, n_jobs=n_jobs, seeding_ratio=0.5)\n",
    "    \n",
    "    with open(f\"{DATA}_{model_fn.__name__}_best_params.txt\", \"a\") as f:\n",
    "            f.write(str(best_params))\n",
    "    \n",
    "    print(f\"{DATA}_{model_fn.__name__}_{best_params}\")\n",
    "    return best_params, search.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f3796d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20f51db3",
   "metadata": {},
   "source": [
    "# TRAIN MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf59445b-c0f0-4ee7-bfe9-5c8a57c22b86",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aacc321b-420a-47f3-88af-6bb02aa0ddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "50c27ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "xgboost.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "63e24c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xgboost(**params):\n",
    "    random_seed = np.random.randint(1024)\n",
    "    def _inner(**args):\n",
    "        return XGBClassifier(\n",
    "            verbosity=0,\n",
    "            random_state=random_seed,\n",
    "            use_label_encoder=False,\n",
    "            **params,\n",
    "            **args\n",
    "        )\n",
    "    return _inner    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8213082c",
   "metadata": {},
   "source": [
    "#### Hyperparam tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da7af406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 23:32:06.483 | INFO     | __main__:pyhopper_best_params:5 - pyhopper_best_params get_xgboost\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb747b285df44285b3589ced83bb2aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 01:30:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 58.38  : 1     : 31 s            \n",
      "Random seeding    : 73.9   : 114   : 45:24 (m:s)     \n",
      "Local sampling    : 76.07  : 99    : 45:11 (m:s)     \n",
      "Duplicates        : -      : 21    : -               \n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 76.07  : 235   : 01:31:06 (h:m:s)\n",
      "=====================================================\n",
      "Libras_get_xgboost_{'n_estimators': 1050, 'max_depth': 5, 'learning_rate': 0.08514892722983261, 'min_child_weight': 1, 'gamma': 0}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_grid = {\n",
    "                'n_estimators': pyhopper.int(50, 1500, multiple_of=50),\n",
    "                'max_depth': pyhopper.choice([2, 3, 5, 10, 15]),\n",
    "                'learning_rate': pyhopper.float(1e-5,1e-1, log=True),\n",
    "                'min_child_weight': pyhopper.choice([1, 2, 4, 8, 16, 32]),\n",
    "                'gamma': pyhopper.choice([0, 0.001, 0.1, 1]),\n",
    "             }\n",
    "\n",
    "xgbt_best1 = pyhopper_best_params(get_xgboost, param_grid, time=\"90m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d8fb3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "858bc970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 01:03:39.618 | INFO     | __main__:pyhopper_best_params:5 - pyhopper_best_params get_xgboost\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c5994333204bdbb7bcc589a9a2cd80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 01:30:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 73.33  : 1     : 16.83 s         \n",
      "Random seeding    : 78.17  : 138   : 45:04 (m:s)     \n",
      "Local sampling    : 78.45  : 122   : 44:41 (m:s)     \n",
      "Duplicates        : -      : 28    : -               \n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 78.45  : 289   : 01:30:02 (h:m:s)\n",
      "=====================================================\n",
      "Libras_get_xgboost_{'subsample': 0.8, 'reg_lambda': 7.043302192975942, 'reg_alpha': 0.12395205154550162}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_grid = {\n",
    "                'subsample': pyhopper.choice([0.5, 0.6, 0.7, 0.8, 0.9, 1]),\n",
    "                'reg_lambda': pyhopper.float(1e-5, 10, init=0, log=True),\n",
    "                'reg_alpha': pyhopper.float(1e-5, 10, init=0, log=True),\n",
    "             }\n",
    "\n",
    "\n",
    "xgbt_best2 = pyhopper_best_params(get_xgboost, param_grid, time=\"90m\", default_params=xgbt_best1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fb0f7b",
   "metadata": {},
   "source": [
    "#### Best Params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2aa500",
   "metadata": {},
   "source": [
    "'Ionosphere' {'gamma': 0, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 1500}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "511d7466",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_best = {**xgbt_best1, **xgbt_best2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5cedd88-43b4-465c-b1e1-6a0b620ae73a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 10\n",
      "iter 2 of 10\n",
      "iter 3 of 10\n",
      "iter 4 of 10\n",
      "iter 5 of 10\n",
      "iter 6 of 10\n",
      "iter 7 of 10\n",
      "iter 8 of 10\n",
      "iter 9 of 10\n",
      "iter 10 of 10\n"
     ]
    }
   ],
   "source": [
    "data_size = max_size\n",
    "\n",
    "xgb_dframe = test_model(get_xgboost(**xgboost_best),\n",
    "                        (X, y),\n",
    "                        data_size,\n",
    "                        label_encoder=None, iters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f530a0df-271a-495f-b49d-2cffe523c328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251: 74.40 ~ 4.62 (max: 83.49)\n"
     ]
    }
   ],
   "source": [
    "res = xgb_dframe[xgb_dframe[\"Class\"]==\"Total\"].reset_index(drop=True)[\"Metric\"]\n",
    "print(f\"{data_size}: {res.mean():.2f} ~ {res.std():.2f} (max: {res.max():.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e53148cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.821429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60.892857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>63.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>54.464286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>72.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>56.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>37.678571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>70.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>46.964286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>73.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>68.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>63.577982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>63.714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Metric\n",
       "Class                       \n",
       "0                  60.714286\n",
       "1                  49.821429\n",
       "2                  83.928571\n",
       "3                  71.607143\n",
       "4                  85.535714\n",
       "5                  60.892857\n",
       "6                  63.035714\n",
       "7                  54.464286\n",
       "8                  72.142857\n",
       "9                  56.071429\n",
       "10                 37.678571\n",
       "11                 70.535714\n",
       "12                 46.964286\n",
       "13                 73.750000\n",
       "14                 68.571429\n",
       "Total              63.577982\n",
       "balanced_accuracy  63.714286"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_dframe.groupby(['Class']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08dcdab-2c4b-4a05-822b-912037488763",
   "metadata": {},
   "source": [
    "### NODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64d10cad-57b5-488c-9a94-63259bd0c13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qhoptim.pyt import QHAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "806be7a7-e4c8-4525-a38f-9ae16a3bd229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_fn(layer_dim=128, num_layers=1, depth=3):\n",
    "    def _inner():\n",
    "        network = torch.nn.Sequential(\n",
    "            node.DenseBlock(X_train.shape[1], \n",
    "                            layer_dim=layer_dim,\n",
    "                            num_layers=num_layers, \n",
    "                            tree_dim=n_classes+1, \n",
    "                            depth=depth, \n",
    "                            flatten_output=False,\n",
    "                            choice_function=node.entmax15, \n",
    "                            bin_function=node.entmoid15\n",
    "                           ),\n",
    "            node.Lambda(lambda x: x.mean(dim=1))\n",
    "        )\n",
    "        \n",
    "        \n",
    "        network = network.to(DEVICE)\n",
    "        network.device=DEVICE\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            res = network(torch.as_tensor(X_train, device=DEVICE).to(torch.float32))\n",
    "        \n",
    "            \n",
    "        optimizer_params = { 'nus':(0.7, 1.0), 'betas':(0.95, 0.998) }\n",
    "        optim = QHAdam(network.parameters(), **optimizer_params)\n",
    "            \n",
    "        network = SimpleSklearnInterface(network, device=DEVICE, epochs=150, batch_size=32)\n",
    "        network.optimizer = optim\n",
    "        return network\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aa8960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d404841f",
   "metadata": {},
   "source": [
    "#### Tune hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "816a242b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 13:43:30.042 | INFO     | __main__:pyhopper_best_params:5 - pyhopper_best_params node_fn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4234019ce3654482be19cd4dfff5eb24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 01:30:00 (h:m:s)\n",
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 79.76  : 1     : 05:27 (m:s)     \n",
      "Random seeding    : 81.36  : 8     : 49:28 (m:s)     \n",
      "Local sampling    : 83.43  : 8     : 35:33 (m:s)     \n",
      "Duplicates        : -      : 7     : -               \n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 83.43  : 24    : 01:30:28 (h:m:s)\n",
      "=====================================================\n",
      "Libras_node_fn_{'layer_dim': 256, 'num_layers': 4, 'depth': 5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'layer_dim': 256, 'num_layers': 4, 'depth': 5}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'layer_dim': hp.quniform('layer_dim', 100, 1200, 100),\n",
    "# 'num_layers': hp.quniform('num_layers', 1, 4, 1),\n",
    "# 'depth': hp.quniform('depth', 2, 7, 1)\n",
    "                    \n",
    "param_grid = {\n",
    "    'layer_dim': pyhopper.int(64, 1024, power_of=2),\n",
    "    'num_layers': pyhopper.int(1, 5),\n",
    "    'depth': pyhopper.int(2, 7),\n",
    "}\n",
    "\n",
    "node_best = pyhopper_best_params(node_fn, param_grid, time=\"90m\")\n",
    "node_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6c8e91b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_reserved()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7772daf",
   "metadata": {},
   "source": [
    "#### Use best hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f6e447c1-63a6-4c90-b22e-5e0852817f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 20\n",
      "iter 2 of 20\n",
      "iter 3 of 20\n",
      "iter 4 of 20\n",
      "iter 5 of 20\n",
      "iter 6 of 20\n",
      "iter 7 of 20\n",
      "iter 8 of 20\n",
      "iter 9 of 20\n",
      "iter 10 of 20\n",
      "iter 11 of 20\n",
      "iter 12 of 20\n",
      "iter 13 of 20\n",
      "iter 14 of 20\n",
      "iter 15 of 20\n",
      "iter 16 of 20\n",
      "iter 17 of 20\n",
      "iter 18 of 20\n",
      "iter 19 of 20\n",
      "iter 20 of 20\n",
      "251: nan ~ nan, (max: nan)\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "size=max_size\n",
    "\n",
    "node_results = test_model(node_fn(**node_best),\n",
    "                    (X, y),\n",
    "                    size,\n",
    "                    label_encoder=None, iters=20)\n",
    "res = node_results[node_results[\"Class\"]==\"roc_auc\"].reset_index(drop=True)[\"Metric\"]\n",
    "print(f\"{size}: {res.mean():.2f} ~ {res.std():.2f}, (max: {res.max():.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8437ea73-72bf-4b18-94d4-eb58a8da9792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d696b0-f5b6-4508-9fff-5166fad29e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "753c2e4d-aca4-4eb1-b3ea-a1926fd44efe",
   "metadata": {},
   "source": [
    "### Dropout Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9c97f270-5e57-4cea-b2f1-3204451b0f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_fn1(epochs=100, drop1=0.3, drop2=0.5, batch_size=32, lr=3e-4):\n",
    "    \n",
    "    def _inner():\n",
    "        network = torch.nn.Sequential(\n",
    "                        torch.nn.Dropout(drop1),\n",
    "                        torch.nn.Linear(n_features, 128),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout(drop2),\n",
    "                        torch.nn.Linear(128, n_classes)\n",
    "                    ).to(DEVICE).train()\n",
    "\n",
    "        network = SimpleSklearnInterface(network, epochs=epochs, batch_size=batch_size, lr=3e-4)\n",
    "        return network\n",
    "    return _inner\n",
    "\n",
    "\n",
    "\n",
    "def network_fn2(epochs=100, drop1=0.3, drop2=0.5, drop3=0.5, batch_size=32, lr=3e-4):\n",
    "    \n",
    "    def _inner():\n",
    "        network = torch.nn.Sequential(\n",
    "                        torch.nn.Dropout(drop1),\n",
    "                        torch.nn.Linear(n_features, 128),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout(drop2),\n",
    "                        torch.nn.Linear(128, 128),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout(drop3),\n",
    "                        torch.nn.Linear(128, n_classes)\n",
    "                    ).to(DEVICE).train()\n",
    "\n",
    "        network = SimpleSklearnInterface(network, epochs=epochs, batch_size=batch_size, lr=3e-4)\n",
    "        return network\n",
    "    return _inner\n",
    "\n",
    "\n",
    "\n",
    "def network_fn3(epochs=100, drop1=0.3, drop2=0.5, drop3=0.5, drop4=0.5, batch_size=32, lr=3e-4):\n",
    "    \n",
    "    def _inner():\n",
    "        network = torch.nn.Sequential(\n",
    "                        torch.nn.Dropout(drop1),\n",
    "                        torch.nn.Linear(n_features, 128),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout(drop2),\n",
    "                        torch.nn.Linear(128, 256),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout(drop3),\n",
    "                        torch.nn.Linear(256, 128),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout(drop4),\n",
    "                        torch.nn.Linear(128, n_classes)\n",
    "                    ).to(DEVICE).train()\n",
    "\n",
    "        network = SimpleSklearnInterface(network, epochs=epochs, batch_size=batch_size, lr=3e-4)\n",
    "        return network\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7bb2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64652732",
   "metadata": {},
   "source": [
    "#### Find Hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256e43a3",
   "metadata": {},
   "source": [
    "### Dropout 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "41850a57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 16:09:06.802 | INFO     | __main__:pyhopper_best_params:5 - pyhopper_best_params network_fn1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aeabaabf20a4b138183ac5b1826d6aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 01:00:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "==================== Summary ===================\n",
      "Mode              : Best f : Steps : Time       \n",
      "----------------  : ----   : ----  : ----       \n",
      "Initial solution  : 74.07  : 1     : 01:45 (m:s)\n",
      "Random seeding    : 77.05  : 14    : 30:30 (m:s)\n",
      "Local sampling    : 81.45  : 12    : 25:56 (m:s)\n",
      "Duplicates        : -      : 8     : -          \n",
      "----------------  : ----   : ----  : ----       \n",
      "Total             : 81.45  : 35    : 58:11 (m:s)\n",
      "================================================\n",
      "Libras_network_fn1_{'epochs': 150, 'drop1': 0.1, 'drop2': 0.5, 'lr': 0.0003, 'batch_size': 32}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs': 150, 'drop1': 0.1, 'drop2': 0.5, 'lr': 0.0003, 'batch_size': 32}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "                \"epochs\": pyhopper.choice([100, 150]),\n",
    "                \"drop1\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"drop2\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"lr\": pyhopper.choice([3e-5, 3e-4, 3e-3, 3e-2, 3e-1]),\n",
    "                \"batch_size\": pyhopper.choice([32, 64]),\n",
    "             }\n",
    "\n",
    "nn_fn1_best_params = pyhopper_best_params(network_fn1, param_grid, time=\"60m\")\n",
    "nn_fn1_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7b0143ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 20\n",
      "iter 2 of 20\n",
      "iter 3 of 20\n",
      "iter 4 of 20\n",
      "iter 5 of 20\n",
      "iter 6 of 20\n",
      "iter 7 of 20\n",
      "iter 8 of 20\n",
      "iter 9 of 20\n",
      "iter 10 of 20\n",
      "iter 11 of 20\n",
      "iter 12 of 20\n",
      "iter 13 of 20\n",
      "iter 14 of 20\n",
      "iter 15 of 20\n",
      "iter 16 of 20\n",
      "iter 17 of 20\n",
      "iter 18 of 20\n",
      "iter 19 of 20\n",
      "iter 20 of 20\n"
     ]
    }
   ],
   "source": [
    "data_size = max_size\n",
    "\n",
    "nn1_results = test_model(network_fn1(**nn_fn1_best_params),\n",
    "                (X, y),\n",
    "                data_size,\n",
    "                None, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fb03b139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251: nan ~ nan (max: nan)\n"
     ]
    }
   ],
   "source": [
    "res = nn1_results[nn1_results[\"Class\"]==\"Balanced Acc score\"][\"Metric\"]\n",
    "print(f\"{data_size}: {res.mean():.2f} ~ {res.std():.2f} (max: {res.max():.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc25ca37",
   "metadata": {},
   "source": [
    "### Dropout 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6ded59e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 17:18:13.796 | INFO     | __main__:pyhopper_best_params:5 - pyhopper_best_params network_fn2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1170bf24eccc4602ac9064e484610e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 01:10:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 77.05  : 1     : 01:52 (m:s)     \n",
      "Random seeding    : 81.1   : 17    : 34:12 (m:s)     \n",
      "Local sampling    : 84.31  : 16    : 32:57 (m:s)     \n",
      "Duplicates        : -      : 11    : -               \n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 84.31  : 45    : 01:09:01 (h:m:s)\n",
      "=====================================================\n",
      "Libras_network_fn2_{'epochs': 150, 'drop1': 0.1, 'drop2': 0.3, 'drop3': 0.1, 'lr': 0.003, 'batch_size': 32}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs': 150,\n",
       " 'drop1': 0.1,\n",
       " 'drop2': 0.3,\n",
       " 'drop3': 0.1,\n",
       " 'lr': 0.003,\n",
       " 'batch_size': 32}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "                \"epochs\": pyhopper.choice([100, 150]),\n",
    "                \"drop1\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"drop2\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"drop3\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"lr\": pyhopper.choice([3e-5, 3e-4, 3e-3, 3e-2, 3e-1]),\n",
    "                \"batch_size\": pyhopper.choice([32, 64]),\n",
    "             }\n",
    "\n",
    "nn_fn2_best_params = pyhopper_best_params(network_fn2, param_grid, time=\"70m\")\n",
    "nn_fn2_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "326bbde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 20\n",
      "iter 2 of 20\n",
      "iter 3 of 20\n",
      "iter 4 of 20\n",
      "iter 5 of 20\n",
      "iter 6 of 20\n",
      "iter 7 of 20\n",
      "iter 8 of 20\n",
      "iter 9 of 20\n",
      "iter 10 of 20\n",
      "iter 11 of 20\n",
      "iter 12 of 20\n",
      "iter 13 of 20\n",
      "iter 14 of 20\n",
      "iter 15 of 20\n",
      "iter 16 of 20\n",
      "iter 17 of 20\n",
      "iter 18 of 20\n",
      "iter 19 of 20\n",
      "iter 20 of 20\n"
     ]
    }
   ],
   "source": [
    "data_size = max_size\n",
    "\n",
    "nn2_results = test_model(network_fn2(**nn_fn2_best_params),\n",
    "                (X, y),\n",
    "                data_size,\n",
    "                None, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8349efaf",
   "metadata": {},
   "source": [
    "### Dropout 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5321d73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 18:38:01.138 | INFO     | __main__:pyhopper_best_params:5 - pyhopper_best_params network_fn3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2bda8d1f6946b390ead6fbe154df29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 01:15:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 78.43  : 1     : 01:49 (m:s)     \n",
      "Random seeding    : 82.55  : 16    : 36:29 (m:s)     \n",
      "Local sampling    : 84.6   : 17    : 35:16 (m:s)     \n",
      "Duplicates        : -      : 12    : -               \n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 84.6   : 46    : 01:13:34 (h:m:s)\n",
      "=====================================================\n",
      "Libras_network_fn3_{'epochs': 150, 'drop1': 0.1, 'drop2': 0.1, 'drop3': 0.1, 'drop4': 0.1, 'lr': 0.0003, 'batch_size': 64}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs': 150,\n",
       " 'drop1': 0.1,\n",
       " 'drop2': 0.1,\n",
       " 'drop3': 0.1,\n",
       " 'drop4': 0.1,\n",
       " 'lr': 0.0003,\n",
       " 'batch_size': 64}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "                \"epochs\": pyhopper.choice([100, 150]),\n",
    "                \"drop1\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"drop2\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"drop3\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"drop4\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"lr\": pyhopper.choice([3e-5, 3e-4, 3e-3, 3e-2, 3e-1]),\n",
    "                \"batch_size\": pyhopper.choice([32, 64]),\n",
    "             }\n",
    "\n",
    "nn_fn3_best_params = pyhopper_best_params(network_fn3, param_grid, time=\"75m\")\n",
    "nn_fn3_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aa8b864e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 20\n",
      "iter 2 of 20\n",
      "iter 3 of 20\n",
      "iter 4 of 20\n",
      "iter 5 of 20\n",
      "iter 6 of 20\n",
      "iter 7 of 20\n",
      "iter 8 of 20\n",
      "iter 9 of 20\n",
      "iter 10 of 20\n",
      "iter 11 of 20\n",
      "iter 12 of 20\n",
      "iter 13 of 20\n",
      "iter 14 of 20\n",
      "iter 15 of 20\n",
      "iter 16 of 20\n"
     ]
    }
   ],
   "source": [
    "data_size = max_size\n",
    "\n",
    "nn3_results = test_model(network_fn3(**nn_fn3_best_params),\n",
    "                (X, y),\n",
    "                data_size,\n",
    "                None, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb86765-3874-4023-8e26-b40ccc6df903",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933db2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d60779d-0042-49af-8a32-e6d0b59e1589",
   "metadata": {
    "tags": []
   },
   "source": [
    "### HypernetworkPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e5536d6-cf9d-4a2b-9d7b-184c0ac27a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_pca_fn(epochs=100, masks_no=100, mask_size=100, target_size=100, n_comp=5, lr=3e-4, batch_size=64):\n",
    "    def _inner():\n",
    "        hypernet = HypernetworkPCA(\n",
    "                        target_architecture=[(mask_size, target_size), (target_size, n_classes)], \n",
    "                        test_nodes=masks_no,\n",
    "                        architecture=torch.nn.Sequential(torch.nn.Linear(n_comp, 64), \n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(64, 256),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Dropout(),\n",
    "                            torch.nn.Linear(256, 256),\n",
    "                            torch.nn.ReLU(),\n",
    "                        ),\n",
    "                        mode=TrainingModes.CARTHESIAN,\n",
    "                        input_size=n_features\n",
    "                    ).to(DEVICE)    \n",
    "        hypernet = hypernet.train()\n",
    "\n",
    "        network = HypernetworkSklearnInterface(hypernet, device=DEVICE, epochs=epochs, batch_size=batch_size, verbose=False, lr=3e-4)\n",
    "        return network\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1e43b7af-9be5-427a-be2e-4f134ba1e644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_to_html():\n",
    "    tmpfile = BytesIO()\n",
    "    plt.gcf().savefig(tmpfile, format='png')\n",
    "    encoded = base64.b64encode(tmpfile.getvalue()).decode('utf-8')\n",
    "\n",
    "    html = '<img src=\\'data:image/png;base64,{}\\'>'.format(encoded)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6a257e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1] // 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2e5638-be6d-4a42-8eb4-be84078643bb",
   "metadata": {},
   "source": [
    "#### Find hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "45f2e4fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 21:14:46.069 | INFO     | __main__:pyhopper_best_params:5 - pyhopper_best_params network_pca_fn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d005441ffdbf4ff99a693ec7a198b081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 02:00:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 2 of 5\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 3 of 5\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 4 of 5\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 5 of 5\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 1 of 5\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 2 of 5\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 3 of 5\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 4 of 5\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 5 of 5\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 1 of 5\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 2 of 5\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 3 of 5\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 4 of 5\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 5 of 5\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 1 of 5\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 2 of 5\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 3 of 5\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 4 of 5\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 5 of 5\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 73.83  : 1     : 19:33 (m:s)     \n",
      "Random seeding    : 89.07  : 2     : 01:06:13 (h:m:s)\n",
      "Local sampling    : 71.64  : 1     : 26:12 (m:s)     \n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 89.07  : 4     : 01:51:58 (h:m:s)\n",
      "=====================================================\n",
      "Libras_network_pca_fn_{'epochs': 150, 'masks_no': 70, 'mask_size': 30, 'target_size': 150, 'n_comp': 10, 'lr': 0.03, 'batch_size': 32}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs': 150,\n",
       " 'masks_no': 70,\n",
       " 'mask_size': 30,\n",
       " 'target_size': 150,\n",
       " 'n_comp': 10,\n",
       " 'lr': 0.03,\n",
       " 'batch_size': 32}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"epochs\": pyhopper.choice([100, 150]),\n",
    "    \"masks_no\": pyhopper.int(40, 110, multiple_of=10),\n",
    "    \"mask_size\": pyhopper.int(5, 70),\n",
    "    \"target_size\": pyhopper.choice([5, 10, 20, 50, 100, 150]),\n",
    "    \"n_comp\": pyhopper.int(5, 40),\n",
    "    \"lr\": pyhopper.choice([3e-5, 3e-4, 3e-3, 3e-2, 3e-1]),\n",
    "    \"batch_size\": pyhopper.choice([32, 64]),\n",
    "\n",
    "}\n",
    "\n",
    "hp_pca_best_params = pyhopper_best_params(network_pca_fn, param_grid, time=\"120m\")\n",
    "hp_pca_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9569bae-98d8-4d2b-9643-3e57fe6bdcbf",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "df7c4b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 150,\n",
       " 'masks_no': 70,\n",
       " 'mask_size': 30,\n",
       " 'target_size': 150,\n",
       " 'n_comp': 10,\n",
       " 'lr': 0.03,\n",
       " 'batch_size': 32}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_pca_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa4f868",
   "metadata": {},
   "source": [
    "'Libras'\n",
    "{'epochs': 150,\n",
    " 'masks_no': 70,\n",
    " 'mask_size': 20,\n",
    " 'target_size': 10,\n",
    " 'n_comp': 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8454fdc",
   "metadata": {},
   "source": [
    "'Lymphography' {'epochs': 120, 'masks_no': 50, 'mask_size': 4, 'target_size': 20, 'n_comp': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e81b7e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Libras'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803eafa7",
   "metadata": {},
   "source": [
    "Ionosphere\n",
    "{'epochs': 100, 'masks_no': 60, 'mask_size': 5, 'target_size': 10}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f5b3a72c-14cf-4d70-bb83-1f0a8aad5144",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 20\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 2 of 20\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 3 of 20\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 4 of 20\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 5 of 20\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 6 of 20\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 7 of 20\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 8 of 20\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 9 of 20\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 10 of 20\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 11 of 20\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 12 of 20\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 13 of 20\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 14 of 20\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 15 of 20\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 16 of 20\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 17 of 20\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 18 of 20\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 19 of 20\n",
      "torch.Size([1, 256])\n",
      "90\n",
      "iter 20 of 20\n",
      "torch.Size([1, 256])\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "epochs = hp_pca_best_params['epochs']\n",
    "masks_no = hp_pca_best_params['masks_no']\n",
    "mask_size = hp_pca_best_params['mask_size']\n",
    "target_size = hp_pca_best_params['target_size']\n",
    "n_comp = hp_pca_best_params['n_comp']\n",
    "data_size = max_size\n",
    "\n",
    "nn_pca_results = test_model(network_pca_fn(target_size=target_size, mask_size=mask_size, masks_no=masks_no, n_comp=n_comp),\n",
    "                (X, y),\n",
    "                data_size,\n",
    "                None, 20)\n",
    "\n",
    "# exp.log_table(\"metrics.csv\", nn_pca_results.groupby(\"Class\").mean())\n",
    "# exp.log_metric(\"f1_score\", nn_pca_results.groupby(\"Class\").mean().loc[\"F1 score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b950280b-188d-4321-8db6-9cb69912a242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251: 86.33 ~ 2.36 (max: 90.83)\n"
     ]
    }
   ],
   "source": [
    "res = nn_pca_results[nn_pca_results[\"Class\"]==\"Total\"].reset_index(drop=True)[\"Metric\"]\n",
    "print(f\"{data_size}: {res.mean():.2f} ~ {res.std():.2f} (max: {res.max():.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6e0de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d82e3c9a-94c1-4984-a311-e0091c453333",
   "metadata": {},
   "source": [
    "### Hypernetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f81bdd75-482c-47ee-a9b3-4c2348f3b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_hp_fn(epochs=150, masks_no=100, mask_size=100, target_size=100, lr=3e-4, batch_size=64):\n",
    "    def _inner():\n",
    "        hypernet = Hypernetwork(\n",
    "                        target_architecture=[(mask_size, target_size), (target_size, n_classes)],\n",
    "                        test_nodes=masks_no,\n",
    "                        architecture=torch.nn.Sequential(torch.nn.Linear(n_features, 128), \n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(128, 256),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Dropout(),\n",
    "                            torch.nn.Linear(256, 256),\n",
    "                            torch.nn.ReLU(),\n",
    "                        ),\n",
    "                        mode=TrainingModes.CARTHESIAN,\n",
    "                    ).to(DEVICE)    \n",
    "        hypernet = hypernet.train()\n",
    "\n",
    "        network = HypernetworkSklearnInterface(hypernet, device=DEVICE, epochs=epochs, batch_size=batch_size, verbose=False, lr=3e-4)\n",
    "        return network\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76e319a",
   "metadata": {},
   "source": [
    "#### Find hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5235e59c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 23:45:18.176 | INFO     | __main__:pyhopper_best_params:5 - pyhopper_best_params network_hp_fn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d46758dcc6248cba6cd7f448ef5d70f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 02:00:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 256])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 256])\n",
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 70.57  : 1     : 14:09 (m:s)     \n",
      "Random seeding    : 89.24  : 5     : 50:44 (m:s)     \n",
      "Local sampling    : 83.98  : 3     : 41:37 (m:s)     \n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 89.24  : 9     : 01:46:30 (h:m:s)\n",
      "=====================================================\n",
      "Libras_network_hp_fn_{'epochs': 100, 'masks_no': 70, 'mask_size': 61, 'target_size': 100, 'lr': 3e-05, 'batch_size': 32}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs': 100,\n",
       " 'masks_no': 70,\n",
       " 'mask_size': 61,\n",
       " 'target_size': 100,\n",
       " 'lr': 3e-05,\n",
       " 'batch_size': 32}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"epochs\": pyhopper.choice([100, 150]),\n",
    "    \"masks_no\": pyhopper.int(10, 100, multiple_of=10),\n",
    "    \"mask_size\": pyhopper.int(5, 70),\n",
    "    \"target_size\": pyhopper.choice([5, 10, 20, 50, 100, 150]),\n",
    "    \"lr\": pyhopper.choice([3e-5, 3e-4, 3e-3, 3e-2, 3e-1]),\n",
    "    \"batch_size\": pyhopper.choice([32, 64]),\n",
    "}\n",
    "\n",
    "hp_best_params = pyhopper_best_params(network_hp_fn, param_grid, time=\"120m\")\n",
    "hp_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b9203a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fe02f07-52f6-4735-93f5-8e14bd22803f",
   "metadata": {},
   "source": [
    "#### Train using the best hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "283d9aca-1f98-42e6-b229-e14e937cb431",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 20\n",
      "torch.Size([1, 256])\n",
      "iter 2 of 20\n",
      "torch.Size([1, 256])\n",
      "iter 3 of 20\n",
      "torch.Size([1, 256])\n",
      "iter 4 of 20\n",
      "torch.Size([1, 256])\n",
      "iter 5 of 20\n",
      "torch.Size([1, 256])\n",
      "iter 6 of 20\n",
      "torch.Size([1, 256])\n",
      "iter 7 of 20\n",
      "torch.Size([1, 256])\n",
      "iter 8 of 20\n",
      "torch.Size([1, 256])\n",
      "iter 9 of 20\n",
      "torch.Size([1, 256])\n",
      "iter 10 of 20\n",
      "torch.Size([1, 256])\n",
      "iter 11 of 20\n",
      "torch.Size([1, 256])\n",
      "iter 13 of 20\n",
      "torch.Size([1, 256])\n",
      "iter 14 of 20\n",
      "torch.Size([1, 256])\n",
      "iter 15 of 20\n",
      "torch.Size([1, 256])\n",
      "iter 16 of 20\n",
      "torch.Size([1, 256])\n",
      "iter 17 of 20\n",
      "torch.Size([1, 256])\n",
      "iter 18 of 20\n",
      "torch.Size([1, 256])\n",
      "iter 19 of 20\n",
      "torch.Size([1, 256])\n",
      "iter 20 of 20\n",
      "torch.Size([1, 256])\n"
     ]
    }
   ],
   "source": [
    "epochs = hp_best_params['epochs']\n",
    "masks_no = hp_best_params['masks_no']\n",
    "mask_size = hp_best_params['mask_size']\n",
    "target_size = hp_best_params['target_size']\n",
    "data_size = max_size\n",
    "\n",
    "hyper_results = test_model(network_hp_fn(epochs, masks_no, mask_size, target_size),\n",
    "                    (X, y),\n",
    "                    data_size,\n",
    "                    None, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b2129c6b-2c65-458e-b175-51aaf313fa42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251: 85.18 ~ 2.86, (max: 89.91)\n"
     ]
    }
   ],
   "source": [
    "res = hyper_results[hyper_results[\"Class\"]==\"Total\"].reset_index(drop=True)[\"Metric\"]\n",
    "print(f\"{data_size}: {res.mean():.2f} ~ {res.std():.2f}, (max: {res.max():.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdb5810-96c6-4010-af1e-a59b0b9f6b65",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6758728e-d6c8-4d23-9aa7-ba7998704411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6da01b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rf(**params):\n",
    "    random_seed = np.random.randint(1024)\n",
    "    def _inner():\n",
    "        return RandomForestClassifier(\n",
    "            random_state=random_seed,\n",
    "            **params\n",
    "        )\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73ccafa",
   "metadata": {},
   "source": [
    "#### Find hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8dc080fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 02:07:55.292 | INFO     | __main__:pyhopper_best_params:5 - pyhopper_best_params get_rf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75f90c0835b40d2b8d2649d722def68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 01:30:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 77.52  : 1     : 01:07 (m:s)     \n",
      "Random seeding    : 82.43  : 58    : 44:21 (m:s)     \n",
      "Local sampling    : 82.21  : 29    : 45:41 (m:s)     \n",
      "Duplicates        : -      : 7     : -               \n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 82.43  : 95    : 01:31:11 (h:m:s)\n",
      "=====================================================\n",
      "Libras_get_rf_{'n_estimators': 2700, 'max_features': None, 'criterion': 'gini', 'max_depth': 16}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 2700,\n",
       " 'max_features': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 16}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "                'n_estimators': pyhopper.int(50, 3000, multiple_of=50),\n",
    "                'max_features': pyhopper.choice([None, 'sqrt', 0.2, 0.3, 0.5, 0.7]),\n",
    "                'criterion' : pyhopper.choice(['gini', 'entropy']),\n",
    "                'max_depth': pyhopper.choice([None, 2, 4, 8, 16]),\n",
    "             }\n",
    "\n",
    "rf_best = pyhopper_best_params(get_rf, param_grid, time=\"90m\")\n",
    "rf_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf8eaa2",
   "metadata": {},
   "source": [
    "#### Use best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f27a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TMP\n",
    "\n",
    "rf_best = {'n_estimators': 3500, 'max_features': 'sqrt', 'criterion': 'gini', 'max_depth': None}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3325fd3b-8a85-46eb-896c-46bf8d768a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 10\n",
      "iter 2 of 10\n",
      "iter 3 of 10\n",
      "iter 4 of 10\n",
      "iter 5 of 10\n",
      "iter 6 of 10\n",
      "iter 7 of 10\n",
      "iter 8 of 10\n",
      "iter 9 of 10\n",
      "iter 10 of 10\n"
     ]
    }
   ],
   "source": [
    "size = max_size\n",
    "\n",
    "rf_dframe = test_model(get_rf(**rf_best), \n",
    "                        (X, y),\n",
    "                        size,\n",
    "                        None, iters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a543f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.178571</td>\n",
       "      <td>12.153648</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.178571</td>\n",
       "      <td>13.766610</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95.892857</td>\n",
       "      <td>6.630963</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82.142857</td>\n",
       "      <td>17.189916</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.750000</td>\n",
       "      <td>14.726580</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>77.678571</td>\n",
       "      <td>13.812859</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>90.714286</td>\n",
       "      <td>13.826959</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>51.607143</td>\n",
       "      <td>12.998833</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>69.285714</td>\n",
       "      <td>17.733700</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>53.392857</td>\n",
       "      <td>13.843605</td>\n",
       "      <td>71.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>83.214286</td>\n",
       "      <td>12.827346</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>74.285714</td>\n",
       "      <td>14.754222</td>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>88.750000</td>\n",
       "      <td>14.726580</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>82.857143</td>\n",
       "      <td>11.268723</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>80.091743</td>\n",
       "      <td>3.059633</td>\n",
       "      <td>86.238532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>79.928571</td>\n",
       "      <td>3.020673</td>\n",
       "      <td>86.071429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         mean        std         max\n",
       "Class                                               \n",
       "0                   80.178571  12.153648  100.000000\n",
       "1                   80.178571  13.766610  100.000000\n",
       "2                   95.892857   6.630963  100.000000\n",
       "3                   82.142857  17.189916  100.000000\n",
       "4                   88.750000  14.726580  100.000000\n",
       "5                   77.678571  13.812859  100.000000\n",
       "6                   90.714286  13.826959  100.000000\n",
       "7                   51.607143  12.998833   75.000000\n",
       "8                  100.000000   0.000000  100.000000\n",
       "9                   69.285714  17.733700  100.000000\n",
       "10                  53.392857  13.843605   71.428571\n",
       "11                  83.214286  12.827346  100.000000\n",
       "12                  74.285714  14.754222   85.714286\n",
       "13                  88.750000  14.726580  100.000000\n",
       "14                  82.857143  11.268723  100.000000\n",
       "Total               80.091743   3.059633   86.238532\n",
       "balanced_accuracy   79.928571   3.020673   86.071429"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_dframe.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa987cfe",
   "metadata": {},
   "source": [
    "# Collect analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6ffd69a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6c53193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['Random forest'] = rf_dframe.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['Hypernet'] = hyper_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['HypernetPCA'] = nn_pca_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['Dropout_1'] = nn1_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['Dropout_2'] = nn2_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['Dropout_3'] = nn3_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['Node'] = node_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['XGBoost'] = xgb_dframe.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7f523ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Random forest</th>\n",
       "      <th>0</th>\n",
       "      <td>82.142857</td>\n",
       "      <td>10.635677</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.410714</td>\n",
       "      <td>17.306113</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94.464286</td>\n",
       "      <td>8.373738</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83.214286</td>\n",
       "      <td>18.812775</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.232143</td>\n",
       "      <td>13.992227</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">XGBoost</th>\n",
       "      <th>12</th>\n",
       "      <td>48.928571</td>\n",
       "      <td>20.330579</td>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>80.892857</td>\n",
       "      <td>17.236391</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>81.071429</td>\n",
       "      <td>13.849060</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>74.403670</td>\n",
       "      <td>4.619874</td>\n",
       "      <td>83.486239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>74.375000</td>\n",
       "      <td>4.552553</td>\n",
       "      <td>83.452381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      mean        std         max\n",
       "              Class                                              \n",
       "Random forest 0                  82.142857  10.635677  100.000000\n",
       "              1                  77.410714  17.306113  100.000000\n",
       "              2                  94.464286   8.373738  100.000000\n",
       "              3                  83.214286  18.812775  100.000000\n",
       "              4                  87.232143  13.992227  100.000000\n",
       "...                                    ...        ...         ...\n",
       "XGBoost       12                 48.928571  20.330579   85.714286\n",
       "              13                 80.892857  17.236391  100.000000\n",
       "              14                 81.071429  13.849060  100.000000\n",
       "              Total              74.403670   4.619874   83.486239\n",
       "              balanced_accuracy  74.375000   4.552553   83.452381\n",
       "\n",
       "[136 rows x 3 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models_df=pd.concat(d, axis=0)\n",
    "all_models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da446f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3af2d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_df.to_csv(f\"{DATA}_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60823a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['COMET_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "85239424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UXrV5UxyhTK3cyQNG6BDuc4bE'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ.get(\"COMET_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49796d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6425adbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0654fd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.com/abulenok/hypernet-uci-tune/3bc1bbf39d0f44279027223ed35f43eb\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'web': 'https://www.comet.com/api/asset/download?assetId=b1025f15ce7646f5ad5c8bd28aa16ca5&experimentKey=3bc1bbf39d0f44279027223ed35f43eb',\n",
       " 'api': 'https://www.comet.com/api/rest/v2/experiment/asset/get-asset?assetId=b1025f15ce7646f5ad5c8bd28aa16ca5&experimentKey=3bc1bbf39d0f44279027223ed35f43eb',\n",
       " 'assetId': 'b1025f15ce7646f5ad5c8bd28aa16ca5'}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = Experiment(os.environ.get(\"COMET_KEY\"), 'hypernet-uci-tune')\n",
    "# exp.log_parameters({\"epochs\": epochs, \"mask_size\": mask_size, \"masks_no\": masks_no, \"data_size\": data_size})\n",
    "exp.add_tag(f\"hypernet-tune2{DATA}\")\n",
    "exp.log_table(f\"{DATA}_metrics.csv\", all_models_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdbf166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cc3246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b6d6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{DATA}_metrics.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a061329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_models_df = pd.read_csv(f\"{DATA}_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e39d56bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Random forest</th>\n",
       "      <th>0</th>\n",
       "      <td>82.142857</td>\n",
       "      <td>10.635677</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.410714</td>\n",
       "      <td>17.306113</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94.464286</td>\n",
       "      <td>8.373738</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83.214286</td>\n",
       "      <td>18.812775</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.232143</td>\n",
       "      <td>13.992227</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">XGBoost</th>\n",
       "      <th>12</th>\n",
       "      <td>48.928571</td>\n",
       "      <td>20.330579</td>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>80.892857</td>\n",
       "      <td>17.236391</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>81.071429</td>\n",
       "      <td>13.849060</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>74.403670</td>\n",
       "      <td>4.619874</td>\n",
       "      <td>83.486239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>74.375000</td>\n",
       "      <td>4.552553</td>\n",
       "      <td>83.452381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      mean        std         max\n",
       "              Class                                              \n",
       "Random forest 0                  82.142857  10.635677  100.000000\n",
       "              1                  77.410714  17.306113  100.000000\n",
       "              2                  94.464286   8.373738  100.000000\n",
       "              3                  83.214286  18.812775  100.000000\n",
       "              4                  87.232143  13.992227  100.000000\n",
       "...                                    ...        ...         ...\n",
       "XGBoost       12                 48.928571  20.330579   85.714286\n",
       "              13                 80.892857  17.236391  100.000000\n",
       "              14                 81.071429  13.849060  100.000000\n",
       "              Total              74.403670   4.619874   83.486239\n",
       "              balanced_accuracy  74.375000   4.552553   83.452381\n",
       "\n",
       "[136 rows x 3 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7beddf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = all_models_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1996040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp.rename(columns={tmp.columns[0]: DATA})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b9ee21a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Libras</th>\n",
       "      <th>Class</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>77.422619</td>\n",
       "      <td>3.876155</td>\n",
       "      <td>85.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Hypernet</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>85.220238</td>\n",
       "      <td>2.927617</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>HypernetPCA</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>86.470238</td>\n",
       "      <td>2.411234</td>\n",
       "      <td>91.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Dropout_1</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>78.125000</td>\n",
       "      <td>3.618090</td>\n",
       "      <td>83.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Dropout_2</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>81.398810</td>\n",
       "      <td>3.422953</td>\n",
       "      <td>87.738095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Dropout_3</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>81.541667</td>\n",
       "      <td>3.985495</td>\n",
       "      <td>87.738095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Node</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>82.720238</td>\n",
       "      <td>3.274015</td>\n",
       "      <td>88.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>74.375000</td>\n",
       "      <td>4.552553</td>\n",
       "      <td>83.452381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Libras              Class       mean       std        max\n",
       "16   Random forest  balanced_accuracy  77.422619  3.876155  85.357143\n",
       "33        Hypernet  balanced_accuracy  85.220238  2.927617  90.000000\n",
       "50     HypernetPCA  balanced_accuracy  86.470238  2.411234  91.071429\n",
       "67       Dropout_1  balanced_accuracy  78.125000  3.618090  83.333333\n",
       "84       Dropout_2  balanced_accuracy  81.398810  3.422953  87.738095\n",
       "101      Dropout_3  balanced_accuracy  81.541667  3.985495  87.738095\n",
       "118           Node  balanced_accuracy  82.720238  3.274015  88.095238\n",
       "135        XGBoost  balanced_accuracy  74.375000  4.552553  83.452381"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[tmp['Class'] == \"balanced_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f287e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393e362b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

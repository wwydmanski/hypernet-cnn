{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01de83ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc12a648-b80a-4eca-afc3-79331e4db7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fdadf44-450a-4006-ac5a-bed9840409f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from tqdm import trange\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import sklearn\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "plt.style.use(\"seaborn\")\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbdec3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7585d3a-dff3-43e2-bc0f-f024306021a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a37b70c-292b-4c14-85ed-3c93020dc182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3085114d-cf61-4625-97c5-10f34c00d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabular_hypernet import HypernetworkPCA, TrainingModes, Hypernetwork\n",
    "from tabular_hypernet.modules import SimpleNetwork\n",
    "from tabular_hypernet.training_utils import train_slow_step, train_model, train_carthesian\n",
    "from tabular_hypernet.interfaces import HypernetworkSklearnInterface, SimpleSklearnInterface\n",
    "# from ipynb.fs.defs.MNIST_benchmark import test_model\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d62c6026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c014884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f84a62eb-e16d-4519-ad76-2237037833c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d12953cc-1ec5-46a9-933a-714e5ceafd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from loguru import logger\n",
    "\n",
    "logger.add(\"log_Lymf.txt\", format='{time:YYYY-MM-DD HH:mm:ss.SSS} | {message}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa3c18d1-1d56-4393-9441-245420fb3c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04d1ae25-987c-4043-9771-829c928723de",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE=\"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a1a1e98-a8b4-4df2-aae6-b593fe61667a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from loguru import logger\n",
    "\n",
    "logger.add(\"log.txt\", format='{time:YYYY-MM-DD HH:mm:ss.SSS} | {message}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81b884da",
   "metadata": {},
   "outputs": [],
   "source": [
    "GS_METRIC = \"balanced_accuracy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82db70f7",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e7c31ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = \"Blastchar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c35c736f-294c-4eea-b7d3-364079f184b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/WA_Fn-UseC_-Telco-Customer-Churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cfa70a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>6840-RESVB</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>24</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>One year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>84.80</td>\n",
       "      <td>1990.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7039</th>\n",
       "      <td>2234-XADUH</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>72</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>One year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>103.20</td>\n",
       "      <td>7362.9</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7040</th>\n",
       "      <td>4801-JZAZL</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.60</td>\n",
       "      <td>346.45</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7041</th>\n",
       "      <td>8361-LTMKD</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>74.40</td>\n",
       "      <td>306.6</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7042</th>\n",
       "      <td>3186-AJIEK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>66</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Two year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>105.65</td>\n",
       "      <td>6844.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7043 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      customerID  gender  SeniorCitizen Partner Dependents  tenure  \\\n",
       "0     7590-VHVEG  Female              0     Yes         No       1   \n",
       "1     5575-GNVDE    Male              0      No         No      34   \n",
       "2     3668-QPYBK    Male              0      No         No       2   \n",
       "3     7795-CFOCW    Male              0      No         No      45   \n",
       "4     9237-HQITU  Female              0      No         No       2   \n",
       "...          ...     ...            ...     ...        ...     ...   \n",
       "7038  6840-RESVB    Male              0     Yes        Yes      24   \n",
       "7039  2234-XADUH  Female              0     Yes        Yes      72   \n",
       "7040  4801-JZAZL  Female              0     Yes        Yes      11   \n",
       "7041  8361-LTMKD    Male              1     Yes         No       4   \n",
       "7042  3186-AJIEK    Male              0      No         No      66   \n",
       "\n",
       "     PhoneService     MultipleLines InternetService OnlineSecurity  ...  \\\n",
       "0              No  No phone service             DSL             No  ...   \n",
       "1             Yes                No             DSL            Yes  ...   \n",
       "2             Yes                No             DSL            Yes  ...   \n",
       "3              No  No phone service             DSL            Yes  ...   \n",
       "4             Yes                No     Fiber optic             No  ...   \n",
       "...           ...               ...             ...            ...  ...   \n",
       "7038          Yes               Yes             DSL            Yes  ...   \n",
       "7039          Yes               Yes     Fiber optic             No  ...   \n",
       "7040           No  No phone service             DSL            Yes  ...   \n",
       "7041          Yes               Yes     Fiber optic             No  ...   \n",
       "7042          Yes                No     Fiber optic            Yes  ...   \n",
       "\n",
       "     DeviceProtection TechSupport StreamingTV StreamingMovies        Contract  \\\n",
       "0                  No          No          No              No  Month-to-month   \n",
       "1                 Yes          No          No              No        One year   \n",
       "2                  No          No          No              No  Month-to-month   \n",
       "3                 Yes         Yes          No              No        One year   \n",
       "4                  No          No          No              No  Month-to-month   \n",
       "...               ...         ...         ...             ...             ...   \n",
       "7038              Yes         Yes         Yes             Yes        One year   \n",
       "7039              Yes          No         Yes             Yes        One year   \n",
       "7040               No          No          No              No  Month-to-month   \n",
       "7041               No          No          No              No  Month-to-month   \n",
       "7042              Yes         Yes         Yes             Yes        Two year   \n",
       "\n",
       "     PaperlessBilling              PaymentMethod MonthlyCharges  TotalCharges  \\\n",
       "0                 Yes           Electronic check          29.85         29.85   \n",
       "1                  No               Mailed check          56.95        1889.5   \n",
       "2                 Yes               Mailed check          53.85        108.15   \n",
       "3                  No  Bank transfer (automatic)          42.30       1840.75   \n",
       "4                 Yes           Electronic check          70.70        151.65   \n",
       "...               ...                        ...            ...           ...   \n",
       "7038              Yes               Mailed check          84.80        1990.5   \n",
       "7039              Yes    Credit card (automatic)         103.20        7362.9   \n",
       "7040              Yes           Electronic check          29.60        346.45   \n",
       "7041              Yes               Mailed check          74.40         306.6   \n",
       "7042              Yes  Bank transfer (automatic)         105.65        6844.5   \n",
       "\n",
       "     Churn  \n",
       "0       No  \n",
       "1       No  \n",
       "2      Yes  \n",
       "3       No  \n",
       "4      Yes  \n",
       "...    ...  \n",
       "7038    No  \n",
       "7039    No  \n",
       "7040    No  \n",
       "7041   Yes  \n",
       "7042    No  \n",
       "\n",
       "[7043 rows x 21 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb145598-e52e-4595-8c5b-ad94767e5f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = data.copy()\n",
    "del processed_data[\"customerID\"]\n",
    "processed_data = processed_data[processed_data['TotalCharges'] != \" \"]\n",
    "processed_data['TotalCharges'] = pd.to_numeric(processed_data['TotalCharges'])\n",
    "\n",
    "y_label_enc = LabelEncoder()\n",
    "y = y_label_enc.fit_transform(processed_data[\"Churn\"].values)\n",
    "del processed_data[\"Churn\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093dc563-0b76-4420-8785-3512e51681dd",
   "metadata": {},
   "source": [
    "### Preprocess features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdb8b71b-7c57-4a04-8f51-4b8bdd6177ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7032, 19)\n"
     ]
    }
   ],
   "source": [
    "label_encoders = {}\n",
    "for col in processed_data.columns:\n",
    "    if processed_data[col].dtype == 'object':\n",
    "        encoder = LabelEncoder()\n",
    "        processed_data[col] = encoder.fit_transform(processed_data[col].values)\n",
    "        label_encoders[col] = encoder\n",
    "        \n",
    "X = processed_data.values\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5291dd39-89bc-4df8-82a7-229febccd510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7032, 19)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "912e3a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7032,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e85869a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = len(np.unique(y if not isinstance(y, tuple) else y_train))\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6305ff4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5163, 1: 1869}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y if not isinstance(y, tuple) else y_train, return_counts=True)\n",
    "\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe2c8e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = X.shape[1] if not isinstance(X, tuple) else X_train.shape[1]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4777a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = int(len(X)*0.7) if not isinstance(X, tuple) else len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e7a0ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38876ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('dataset size:', len(X), '|', 'max training size:', max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30a5727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RUN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507c32bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa56e0fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b77cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c287f46",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdc5ffdd-e04d-425f-8d6c-bd8456644faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "def prepare_data(X, y, size=None):\n",
    "    if isinstance(X, tuple) and isinstance(y, tuple):\n",
    "        X_train, X_test = X\n",
    "        y_train, y_test = y\n",
    "    else:    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=size, stratify=y)\n",
    "    # X_train, y_train = imblearn.over_sampling.RandomOverSampler(random_state=42).fit_resample(X_train, y_train)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = [torch.from_numpy(x) for x in [X_train, X_test, y_train, y_test]]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca0a827a-0e1f-4f5c-b15d-3354f075021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data(X, y, size=max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281d7f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d223075b-b7d8-414e-97c9-ade8bda5f0fd",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9f92f86-4c40-492c-8d48-f23efa85eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5aa90ca0-8a00-4491-b111-ce7eee0e9c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _summarize_results(y_pred, y_score, y_test, labels):\n",
    "    results = []\n",
    "    for idx, label in enumerate(labels):\n",
    "        y_pred_filt = y_pred[y_test==idx]\n",
    "        y_test_filt = y_test[y_test==idx]\n",
    "        acc = (y_pred_filt==y_test_filt.numpy()).sum()/len(y_test_filt)*100\n",
    "        results.append({\n",
    "            \"Class\": label,\n",
    "            \"Metric\": acc\n",
    "        })\n",
    "        \n",
    "    acc = (y_pred==y_test.numpy()).sum()/len(y_test)*100    \n",
    "    results.append({\n",
    "        \"Class\": \"Total\",\n",
    "        \"Metric\": acc\n",
    "    })\n",
    "    \n",
    "    \n",
    "    results.append({\n",
    "        \"Class\": \"balanced_accuracy\",\n",
    "        \"Metric\": balanced_accuracy_score(y_test, torch.from_numpy(y_pred)).item()*100\n",
    "    })\n",
    "    \n",
    "    try:\n",
    "        results.append({\n",
    "            \"Class\": \"F1 score\",\n",
    "            \"Metric\": f1_score(y_test, torch.from_numpy(y_pred)).item()*100\n",
    "        })\n",
    "        results.append({\n",
    "            \"Class\": \"roc_auc\",\n",
    "            \"Metric\": roc_auc_score(y_test, torch.from_numpy(y_score[:, 1])).item()*100\n",
    "        })\n",
    "        results.append({\n",
    "            \"Class\": \"Precision\",\n",
    "            \"Metric\": precision_score(y_test, torch.from_numpy(y_pred)).item()*100\n",
    "        })\n",
    "        results.append({\n",
    "            \"Class\": \"Recall\",\n",
    "            \"Metric\": recall_score(y_test, torch.from_numpy(y_pred)).item()*100\n",
    "        })\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return results\n",
    "\n",
    "def test_model(model_fn, data, train_size, label_encoder=None, iters=10, as_numpy=False):\n",
    "    if TEST_RUN:\n",
    "        iters = 1\n",
    "        \n",
    "    if label_encoder is not None:\n",
    "        labels = label_encoder.classes_\n",
    "    else:\n",
    "        labels = sorted(pd.unique(data[1][0] if isinstance(data[1], tuple) else data[1]))\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for i in range(iters):\n",
    "        print('iter', i+1, 'of', iters)\n",
    "        X_train, X_test, y_train, y_test = prepare_data(*data, train_size)\n",
    "        \n",
    "        print('X_train_size', X_train.shape)\n",
    "        print('y_train_size', y_train.shape)\n",
    "        \n",
    "        model = model_fn()\n",
    "\n",
    "        if as_numpy:\n",
    "            model.fit(X_train.numpy(), y_train.numpy());\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        y_score = model.predict_proba(X_test)\n",
    "        results.extend(_summarize_results(y_pred, y_score, y_test, labels))\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    dframe = pd.DataFrame.from_dict(results)\n",
    "#     sns.violinplot(data=dframe[dframe[\"Class\"]!=\"Loss\"], y=\"Class\", x=\"Metric\", orient='h')\n",
    "    return dframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f351cf",
   "metadata": {},
   "source": [
    "### Param search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a95790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ecee618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyhopper_best_params(model_fn, param_grid, data_size=max_size, metric=GS_METRIC, time=\"30m\", default_params={}, n_jobs=1):\n",
    "    if TEST_RUN:\n",
    "        time = 30\n",
    "        if 'epochs' in param_grid:\n",
    "            param_grid[\"epochs\"] = pyhopper.choice([10])\n",
    "        \n",
    "    logger.info(f\"pyhopper_best_params {model_fn.__name__}\")\n",
    "    \n",
    "    def objective(params):\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        model_results = test_model(\n",
    "                        model_fn(\n",
    "                            **default_params,\n",
    "                            **params\n",
    "                        ),\n",
    "                        (X, y),\n",
    "                        data_size,\n",
    "                        None, 5)\n",
    "        with open(f\"{DATA}_{model_fn.__name__}_params.txt\", \"a\") as f:\n",
    "            f.write(str(datetime.datetime.now()) + \", \" + str(params) + \", \" + str(model_results[model_results[\"Class\"]==metric][\"Metric\"].mean()) + \"\\n\")\n",
    "        return model_results[model_results[\"Class\"]==metric][\"Metric\"].mean()\n",
    "\n",
    "    from pyhopper.callbacks import History\n",
    "    search = pyhopper.Search(param_grid)\n",
    "\n",
    "    best_params = search.run(objective, \"maximize\", time, n_jobs=n_jobs, seeding_ratio=0.5)\n",
    "    \n",
    "    with open(f\"{DATA}_{model_fn.__name__}_best_params.txt\", \"a\") as f:\n",
    "            f.write(str(best_params))\n",
    "    \n",
    "    print(f\"{DATA}_{model_fn.__name__}_{best_params}\")\n",
    "    return best_params, search.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f3796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228c7d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db460f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20f51db3",
   "metadata": {},
   "source": [
    "# TRAIN MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf59445b-c0f0-4ee7-bfe9-5c8a57c22b86",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aacc321b-420a-47f3-88af-6bb02aa0ddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "50c27ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "xgboost.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "63e24c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xgboost(**params):\n",
    "    random_seed = np.random.randint(1024)\n",
    "    def _inner(**args):\n",
    "        return XGBClassifier(\n",
    "            verbosity=0,\n",
    "            random_state=random_seed,\n",
    "            use_label_encoder=False,\n",
    "            **params,\n",
    "            **args\n",
    "        )\n",
    "    return _inner    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8213082c",
   "metadata": {},
   "source": [
    "#### Hyperparam tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "da7af406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-18 21:52:07.097 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params get_xgboost\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b9e713ed2e42448f818221b9c96b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 01:30:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "CTRL+C received. Will terminate once the currently running candidates finished\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "==================== Summary ===================\n",
      "Mode              : Best f : Steps : Time       \n",
      "----------------  : ----   : ----  : ----       \n",
      "Initial solution  : 65.81  : 1     : 6.67 s     \n",
      "Random seeding    : 72.44  : 171   : 42:60 (m:s)\n",
      "----------------  : ----   : ----  : ----       \n",
      "Total             : 72.44  : 172   : 43:07 (m:s)\n",
      "================================================\n",
      "Blastchar_get_xgboost_{'n_estimators': 1350, 'max_depth': 2, 'learning_rate': 2.4965347918426673e-05, 'min_child_weight': 2, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "                'n_estimators': pyhopper.choice([50, 100, 250, 500, 1000, 1750, 3000]),\n",
    "                'max_depth': pyhopper.choice([2, 3, 5, 10, 15]),\n",
    "                'learning_rate': pyhopper.float(1e-5,1e-1, log=True),\n",
    "                'min_child_weight': pyhopper.choice([1, 2, 4, 8, 16, 32]),\n",
    "                'gamma': pyhopper.choice([0, 0.001, 0.1, 1]),\n",
    "             }\n",
    "\n",
    "xgbt_best1, xgbt_history1 = pyhopper_best_params(get_xgboost, param_grid, time=\"90m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d8fb3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "858bc970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-18 22:35:14.075 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params get_xgboost\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c30c59b18a4fa5919ad8b484eb641f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 01:30:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 1 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "CTRL+C received. Will terminate once the currently running candidates finished\n",
      "iter 2 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 4 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 5 of 5\n",
      "data_size torch.Size([3000, 19])\n",
      "================== Summary =================\n",
      "Mode              : Best f : Steps : Time   \n",
      "----------------  : ----   : ----  : ----   \n",
      "Initial solution  : 67.23  : 1     : 5.90 s \n",
      "Random seeding    : 69.92  : 2     : 12.07 s\n",
      "----------------  : ----   : ----  : ----   \n",
      "Total             : 69.92  : 3     : 18.00 s\n",
      "============================================\n",
      "Blastchar_get_xgboost_{'subsample': 0.9, 'reg_lambda': 0.004055665696395483, 'reg_alpha': 0.47172083737402604}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "                'subsample': pyhopper.choice([0.5, 0.6, 0.7, 0.8, 0.9, 1]),\n",
    "                'reg_lambda': pyhopper.float(1e-5, 10, init=0, log=True),\n",
    "                'reg_alpha': pyhopper.float(1e-5, 10, init=0, log=True),\n",
    "             }\n",
    "\n",
    "\n",
    "xgbt_best2, xgbt_history2 = pyhopper_best_params(get_xgboost, param_grid, time=\"90m\", default_params=xgbt_best1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fb0f7b",
   "metadata": {},
   "source": [
    "#### Best Params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2aa500",
   "metadata": {},
   "source": [
    "'Ionosphere' {'gamma': 0, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 1500}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "511d7466",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_best = {**xgbt_best1, **xgbt_best2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d5cedd88-43b4-465c-b1e1-6a0b620ae73a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 6 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 7 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 8 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 9 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 10 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 11 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 12 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 13 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 14 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 15 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 16 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 17 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 18 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 19 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 20 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 21 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 22 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 23 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 24 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 25 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 26 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 27 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 28 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 29 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 30 of 30\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    }
   ],
   "source": [
    "data_size = max_size\n",
    "\n",
    "xgb_dframe = test_model(get_xgboost(**xgboost_best),\n",
    "                        (X, y),\n",
    "                        data_size,\n",
    "                        label_encoder=None, iters=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f530a0df-271a-495f-b49d-2cffe523c328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000: 69.87 ~ 3.08 (max: 73.87)\n"
     ]
    }
   ],
   "source": [
    "res = xgb_dframe[xgb_dframe[\"Class\"]==\"balanced_accuracy\"].reset_index(drop=True)[\"Metric\"]\n",
    "print(f\"{data_size}: {res.mean():.2f} ~ {res.std():.2f} (max: {res.max():.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e53148cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83.362613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.383706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 score</th>\n",
       "      <td>55.093448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>56.551714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>56.383706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>76.189649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>69.873160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>81.051233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Metric\n",
       "Class                       \n",
       "0                  83.362613\n",
       "1                  56.383706\n",
       "F1 score           55.093448\n",
       "Precision          56.551714\n",
       "Recall             56.383706\n",
       "Total              76.189649\n",
       "balanced_accuracy  69.873160\n",
       "roc_auc            81.051233"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_dframe.groupby(['Class']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08dcdab-2c4b-4a05-822b-912037488763",
   "metadata": {},
   "source": [
    "### NODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64d10cad-57b5-488c-9a94-63259bd0c13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qhoptim.pyt import QHAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "806be7a7-e4c8-4525-a38f-9ae16a3bd229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_fn(layer_dim=128, num_layers=1, depth=3):\n",
    "    def _inner():\n",
    "        network = torch.nn.Sequential(\n",
    "            node.DenseBlock(X_train.shape[1], \n",
    "                            layer_dim=layer_dim,\n",
    "                            num_layers=num_layers, \n",
    "                            tree_dim=n_classes+1, \n",
    "                            depth=depth, \n",
    "                            flatten_output=False,\n",
    "                            choice_function=node.entmax15, \n",
    "                            bin_function=node.entmoid15\n",
    "                           ),\n",
    "            node.Lambda(lambda x: x.mean(dim=1))\n",
    "        )\n",
    "        \n",
    "        \n",
    "        network = network.to(DEVICE)\n",
    "        network.device=DEVICE\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            res = network(torch.as_tensor(X_train, device=DEVICE).to(torch.float32))\n",
    "        \n",
    "            \n",
    "        optimizer_params = { 'nus':(0.7, 1.0), 'betas':(0.95, 0.998) }\n",
    "        optim = QHAdam(network.parameters(), **optimizer_params)\n",
    "            \n",
    "        network = SimpleSklearnInterface(network, device=DEVICE, epochs=100, batch_size=128)\n",
    "        network.optimizer = optim\n",
    "        return network\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d404841f",
   "metadata": {},
   "source": [
    "#### Tune hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "816a242b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 00:59:29.518 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params node_fn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9a840d512d497ab7f993dfc73deb5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 05:00:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/deps/node/node/lib/odst.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bin_codes = (indices.view(1, -1) // offsets.view(-1, 1) % 2).to(torch.float32)\n",
      "../aten/src/ATen/native/cuda/ScatterGatherKernel.cu:111: operator(): block: [11,0,0], thread: [16,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/ScatterGatherKernel.cu:111: operator(): block: [11,0,0], thread: [18,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/ScatterGatherKernel.cu:111: operator(): block: [11,0,0], thread: [19,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/ScatterGatherKernel.cu:111: operator(): block: [11,0,0], thread: [20,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remote process caught exception in objective function: \n",
      "======================================================\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/pyhopper/parallel.py\", line 223, in execute\n",
      "    iter_or_result = objective_function(candidate, **kwargs)\n",
      "  File \"/tmp/ipykernel_340065/567169155.py\", line 12, in objective\n",
      "    model_results = test_model(\n",
      "  File \"/tmp/ipykernel_340065/3937386562.py\", line 68, in test_model\n",
      "    model.fit(X_train, y_train)\n",
      "  File \"/home/z1157095/hypernet-cnn/hypernet/tabular_hypernet/interfaces.py\", line 21, in fit\n",
      "    basic_train_loop(self.network, self.optimizer, self.criterion, train_data, self.epochs, self.device)\n",
      "  File \"/home/z1157095/hypernet-cnn/hypernet/tabular_hypernet/training_utils.py\", line 320, in basic_train_loop\n",
      "    loss.backward()\n",
      "  File \"/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/torch/_tensor.py\", line 363, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/torch/autograd/__init__.py\", line 173, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "\n",
      "======================================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Pyhopper - Remote process caught exception",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [137]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 'layer_dim': hp.quniform('layer_dim', 100, 1200, 100),\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 'num_layers': hp.quniform('num_layers', 1, 4, 1),\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 'depth': hp.quniform('depth', 2, 7, 1)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer_dim\u001b[39m\u001b[38;5;124m'\u001b[39m: pyhopper\u001b[38;5;241m.\u001b[39mint(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m1024\u001b[39m, power_of\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_layers\u001b[39m\u001b[38;5;124m'\u001b[39m: pyhopper\u001b[38;5;241m.\u001b[39mint(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m),\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m'\u001b[39m: pyhopper\u001b[38;5;241m.\u001b[39mint(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m7\u001b[39m),\n\u001b[1;32m      9\u001b[0m }\n\u001b[0;32m---> 11\u001b[0m node_best, node_history \u001b[38;5;241m=\u001b[39m \u001b[43mpyhopper_best_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;241;43m5\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m node_best\n",
      "Input \u001b[0;32mIn [102]\u001b[0m, in \u001b[0;36mpyhopper_best_params\u001b[0;34m(model_fn, param_grid, data_size, metric, time, default_params, n_jobs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyhopper\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m History\n\u001b[1;32m     25\u001b[0m search \u001b[38;5;241m=\u001b[39m pyhopper\u001b[38;5;241m.\u001b[39mSearch(param_grid)\n\u001b[0;32m---> 27\u001b[0m best_params \u001b[38;5;241m=\u001b[39m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseeding_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_best_params.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     30\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28mstr\u001b[39m(best_params))\n",
      "File \u001b[0;32m~/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/pyhopper/search.py:737\u001b[0m, in \u001b[0;36mSearch.run\u001b[0;34m(self, objective_function, direction, runtime, steps, endless_mode, seeding_steps, seeding_runtime, seeding_ratio, pruner, n_jobs, quiet, ignore_nans, mp_backend, enable_rejection_cache, callbacks, start_temperature, end_temperature, kwargs, checkpoint_path, overwrite_checkpoint, keep_history)\u001b[0m\n\u001b[1;32m    734\u001b[0m     candidate_type \u001b[38;5;241m=\u001b[39m CandidateType\u001b[38;5;241m.\u001b[39mLOCAL_SAMPLING\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m candidate \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_f_cache:\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;66;03m# If candidate was already run before, let's skip this step\u001b[39;00m\n\u001b[0;32m--> 737\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_submit_candidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjective_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    743\u001b[0m     current_temperature \u001b[38;5;241m=\u001b[39m schedule\u001b[38;5;241m.\u001b[39mtemperature\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/pyhopper/search.py:471\u001b[0m, in \u001b[0;36mSearch._submit_candidate\u001b[0;34m(self, objective_function, candidate_type, candidate, kwargs)\u001b[0m\n\u001b[1;32m    464\u001b[0m     candidate_result \u001b[38;5;241m=\u001b[39m execute(\n\u001b[1;32m    465\u001b[0m         objective_function,\n\u001b[1;32m    466\u001b[0m         candidate,\n\u001b[1;32m    467\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_context\u001b[38;5;241m.\u001b[39mpruner,\n\u001b[1;32m    468\u001b[0m         kwargs,\n\u001b[1;32m    469\u001b[0m     )\n\u001b[1;32m    470\u001b[0m     param_info\u001b[38;5;241m.\u001b[39mfinished_at \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 471\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_async_result_ready\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidate_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_context\u001b[38;5;241m.\u001b[39mtask_executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m    474\u001b[0m         objective_function,\n\u001b[1;32m    475\u001b[0m         candidate,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    478\u001b[0m         kwargs,\n\u001b[1;32m    479\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/pyhopper/search.py:515\u001b[0m, in \u001b[0;36mSearch._async_result_ready\u001b[0;34m(self, candidate, param_info, candidate_result)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;28mprint\u001b[39m(candidate_result\u001b[38;5;241m.\u001b[39merror)\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    513\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m======================================================\u001b[39m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         )\n\u001b[0;32m--> 515\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyhopper - Remote process caught exception\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m candidate_result\u001b[38;5;241m.\u001b[39mis_nan \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_context\u001b[38;5;241m.\u001b[39mignore_nans:\n",
      "\u001b[0;31mValueError\u001b[0m: Pyhopper - Remote process caught exception"
     ]
    }
   ],
   "source": [
    "# 'layer_dim': hp.quniform('layer_dim', 100, 1200, 100),\n",
    "# 'num_layers': hp.quniform('num_layers', 1, 4, 1),\n",
    "# 'depth': hp.quniform('depth', 2, 7, 1)\n",
    "                    \n",
    "param_grid = {\n",
    "    'layer_dim': pyhopper.int(64, 1024, power_of=2),\n",
    "    'num_layers': pyhopper.int(1, 5),\n",
    "    'depth': pyhopper.int(2, 7),\n",
    "}\n",
    "\n",
    "node_best, node_history = pyhopper_best_params(node_fn, param_grid, time=f\"{5*60}m\", n_jobs=1)\n",
    "node_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c8e91b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_best = {'layer_dim': 256, 'num_layers': 3, 'depth': 7}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7772daf",
   "metadata": {},
   "source": [
    "#### Use best hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f6e447c1-63a6-4c90-b22e-5e0852817f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 10\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 10\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 10\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 10\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 10\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 6 of 10\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 7 of 10\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 8 of 10\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 9 of 10\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 10 of 10\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "3000: 69.75 ~ 1.29, (max: 72.26)\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "size=max_size\n",
    "\n",
    "node_results = test_model(node_fn(**node_best),\n",
    "                    (X, y),\n",
    "                    size,\n",
    "                    label_encoder=None, iters=10)\n",
    "res = node_results[node_results[\"Class\"]==\"balanced_accuracy\"].reset_index(drop=True)[\"Metric\"]\n",
    "print(f\"{size}: {res.mean():.2f} ~ {res.std():.2f}, (max: {res.max():.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8437ea73-72bf-4b18-94d4-eb58a8da9792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000: 69.75 ~ 1.29, (max: 72.26)\n"
     ]
    }
   ],
   "source": [
    "res = node_results[node_results[\"Class\"]==\"balanced_accuracy\"].reset_index(drop=True)[\"Metric\"]\n",
    "print(f\"{size}: {res.mean():.2f} ~ {res.std():.2f}, (max: {res.max():.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31df3a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_results[node_results[\"Class\"]==\"balanced_accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba0727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_results.groupby(['Class']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d696b0-f5b6-4508-9fff-5166fad29e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_results.groupby(['Class']).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753c2e4d-aca4-4eb1-b3ea-a1926fd44efe",
   "metadata": {},
   "source": [
    "### Dropout Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9c97f270-5e57-4cea-b2f1-3204451b0f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_fn1(epochs=100, drop1=0.3, drop2=0.5, batch_size=32, lr=3e-4):\n",
    "    \n",
    "    def _inner():\n",
    "        network = torch.nn.Sequential(\n",
    "                        torch.nn.Dropout(drop1),\n",
    "                        torch.nn.Linear(n_features, 64),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout(drop2),\n",
    "                        torch.nn.Linear(64, n_classes)\n",
    "                    ).to(DEVICE).train()\n",
    "\n",
    "        network = SimpleSklearnInterface(network, epochs=epochs, batch_size=batch_size, lr=lr)\n",
    "        return network\n",
    "    return _inner\n",
    "\n",
    "\n",
    "\n",
    "def network_fn2(epochs=100, drop1=0.3, drop2=0.5, drop3=0.5, batch_size=32, lr=3e-4):\n",
    "    \n",
    "    def _inner():\n",
    "        network = torch.nn.Sequential(\n",
    "                        torch.nn.Dropout(drop1),\n",
    "                        torch.nn.Linear(n_features, 64),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout(drop2),\n",
    "                        torch.nn.Linear(64, 64),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout(drop3),\n",
    "                        torch.nn.Linear(64, n_classes)\n",
    "                    ).to(DEVICE).train()\n",
    "\n",
    "        network = SimpleSklearnInterface(network, epochs=epochs, batch_size=batch_size, lr=lr)\n",
    "        return network\n",
    "    return _inner\n",
    "\n",
    "\n",
    "\n",
    "def network_fn3(epochs=100, drop1=0.3, drop2=0.5, drop3=0.5, drop4=0.5, batch_size=32, lr=3e-4):\n",
    "    \n",
    "    def _inner():\n",
    "        network = torch.nn.Sequential(\n",
    "                        torch.nn.Dropout(drop1),\n",
    "                        torch.nn.Linear(n_features, 64),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout(drop2),\n",
    "                        torch.nn.Linear(64, 128),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout(drop3),\n",
    "                        torch.nn.Linear(128, 64),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout(drop4),\n",
    "                        torch.nn.Linear(64, n_classes)\n",
    "                    ).to(DEVICE).train()\n",
    "\n",
    "        network = SimpleSklearnInterface(network, epochs=epochs, batch_size=batch_size, lr=lr)\n",
    "        return network\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7bb2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64652732",
   "metadata": {},
   "source": [
    "#### Find Hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256e43a3",
   "metadata": {},
   "source": [
    "### Dropout 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41850a57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 16:12:27.803 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params network_fn1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a395f41174d4cc8899dfcf6570e3712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 01:00:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "==================== Summary ===================\n",
      "Mode              : Best f : Steps : Time       \n",
      "----------------  : ----   : ----  : ----       \n",
      "Initial solution  : 92.47  : 1     : 01:44 (m:s)\n",
      "Random seeding    : 95.62  : 14    : 28:26 (m:s)\n",
      "Local sampling    : 95.68  : 15    : 28:42 (m:s)\n",
      "Duplicates        : -      : 10    : -          \n",
      "----------------  : ----   : ----  : ----       \n",
      "Total             : 95.68  : 40    : 58:53 (m:s)\n",
      "================================================\n",
      "cnae_network_fn1_{'epochs': 100, 'drop1': 0.5, 'drop2': 0.7, 'lr': 0.0003, 'batch_size': 32}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs': 100, 'drop1': 0.5, 'drop2': 0.7, 'lr': 0.0003, 'batch_size': 32}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "                \"epochs\": pyhopper.choice([100, 150]),\n",
    "                \"drop1\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"drop2\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"lr\": pyhopper.choice([3e-5, 3e-4, 3e-3, 3e-2, 3e-1]),\n",
    "                \"batch_size\": pyhopper.choice([32, 64]),\n",
    "             }\n",
    "\n",
    "nn_fn1_best_params, nn_fn1_history = pyhopper_best_params(network_fn1, param_grid, time=\"60m\")\n",
    "nn_fn1_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b0143ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 10\n",
      "iter 2 of 10\n",
      "iter 3 of 10\n",
      "iter 4 of 10\n",
      "iter 5 of 10\n",
      "iter 6 of 10\n",
      "iter 7 of 10\n",
      "iter 8 of 10\n",
      "iter 9 of 10\n",
      "iter 10 of 10\n"
     ]
    }
   ],
   "source": [
    "data_size = max_size\n",
    "\n",
    "nn1_results = test_model(network_fn1(**nn_fn1_best_params),\n",
    "                (X, y),\n",
    "                data_size,\n",
    "                None, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb03b139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756: nan ~ nan (max: nan)\n"
     ]
    }
   ],
   "source": [
    "res = nn1_results[nn1_results[\"Class\"]==\"Balanced Acc score\"][\"Metric\"]\n",
    "print(f\"{data_size}: {res.mean():.2f} ~ {res.std():.2f} (max: {res.max():.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc25ca37",
   "metadata": {},
   "source": [
    "### Dropout 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ded59e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 17:17:56.668 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params network_fn2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47bf740c732c42b0a7c6d3559167bf02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 01:10:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 90.68  : 1     : 01:43 (m:s)     \n",
      "Random seeding    : 95.49  : 19    : 35:36 (m:s)     \n",
      "Local sampling    : 95.43  : 16    : 31:25 (m:s)     \n",
      "Duplicates        : -      : 10    : -               \n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 95.49  : 46    : 01:08:44 (h:m:s)\n",
      "=====================================================\n",
      "cnae_network_fn2_{'epochs': 100, 'drop1': 0.5, 'drop2': 0.1, 'drop3': 0.7, 'lr': 0.0003, 'batch_size': 64}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs': 100,\n",
       " 'drop1': 0.5,\n",
       " 'drop2': 0.1,\n",
       " 'drop3': 0.7,\n",
       " 'lr': 0.0003,\n",
       " 'batch_size': 64}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "                \"epochs\": pyhopper.choice([100, 150]),\n",
    "                \"drop1\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"drop2\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"drop3\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"lr\": pyhopper.choice([3e-5, 3e-4, 3e-3, 3e-2, 3e-1]),\n",
    "                \"batch_size\": pyhopper.choice([32, 64]),\n",
    "             }\n",
    "\n",
    "nn_fn2_best_params, nn_fn2_history = pyhopper_best_params(network_fn2, param_grid, time=\"70m\")\n",
    "nn_fn2_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "326bbde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 10\n",
      "iter 2 of 10\n",
      "iter 3 of 10\n",
      "iter 4 of 10\n",
      "iter 5 of 10\n",
      "iter 6 of 10\n",
      "iter 7 of 10\n",
      "iter 8 of 10\n",
      "iter 9 of 10\n",
      "iter 10 of 10\n"
     ]
    }
   ],
   "source": [
    "data_size = max_size\n",
    "\n",
    "nn2_results = test_model(network_fn2(**nn_fn2_best_params),\n",
    "                (X, y),\n",
    "                data_size,\n",
    "                None, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8349efaf",
   "metadata": {},
   "source": [
    "### Dropout 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5321d73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-18 17:19:44.938 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params network_fn3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5691b1d64454433be2b5ad842cc4f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 01:30:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n",
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "iter 1 of 5\n",
      "iter 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n",
      "iter 3 of 5\n",
      "iter 4 of 5\n",
      "iter 5 of 5\n",
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 72.51  : 1     : 04:01 (m:s)     \n",
      "Random seeding    : 72.42  : 10    : 41:31 (m:s)     \n",
      "Local sampling    : 72.64  : 10    : 45:59 (m:s)     \n",
      "Duplicates        : -      : 4     : -               \n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 72.64  : 25    : 01:31:31 (h:m:s)\n",
      "=====================================================\n",
      "Blastchar_network_fn3_{'epochs': 100, 'drop1': 0.3, 'drop2': 0.3, 'drop3': 0.3, 'drop4': 0.3, 'lr': 3e-05, 'batch_size': 64}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs': 100,\n",
       " 'drop1': 0.3,\n",
       " 'drop2': 0.3,\n",
       " 'drop3': 0.3,\n",
       " 'drop4': 0.3,\n",
       " 'lr': 3e-05,\n",
       " 'batch_size': 64}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "                \"epochs\": pyhopper.choice([100, 150]),\n",
    "                \"drop1\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"drop2\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"drop3\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"drop4\": pyhopper.choice([0.1, 0.3, 0.5, 0.7], is_ordinal=True),\n",
    "                \"lr\": pyhopper.choice([3e-5, 3e-4, 3e-3, 3e-2, 3e-1]),\n",
    "                \"batch_size\": pyhopper.choice([32, 64]),\n",
    "             }\n",
    "\n",
    "nn_fn3_best_params, nn_fn3_history = pyhopper_best_params(network_fn3, param_grid, time=\"90m\")\n",
    "nn_fn3_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "97a6abb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 100,\n",
       " 'drop1': 0.3,\n",
       " 'drop2': 0.3,\n",
       " 'drop3': 0.3,\n",
       " 'drop4': 0.3,\n",
       " 'lr': 3e-05,\n",
       " 'batch_size': 64}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_fn3_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dc451797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "aa8b864e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 10\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 2 of 10\n",
      "data_size torch.Size([3000, 19])\n",
      "iter 3 of 10\n",
      "data_size torch.Size([3000, 19])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [89]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m data_size \u001b[38;5;241m=\u001b[39m max_size\n\u001b[0;32m----> 3\u001b[0m nn3_results \u001b[38;5;241m=\u001b[39m \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork_fn3\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnn_fn3_best_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdata_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [88]\u001b[0m, in \u001b[0;36mtest_model\u001b[0;34m(model_fn, data, train_size, label_encoder, iters, as_numpy)\u001b[0m\n\u001b[1;32m     65\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train\u001b[38;5;241m.\u001b[39mnumpy(), y_train\u001b[38;5;241m.\u001b[39mnumpy());\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     70\u001b[0m y_score \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)\n",
      "File \u001b[0;32m~/hypernet-cnn/hypernet/tabular_hypernet/interfaces.py:21\u001b[0m, in \u001b[0;36mSimpleSklearnInterface.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     20\u001b[0m train_data \u001b[38;5;241m=\u001b[39m get_dataloader(X, y, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mbasic_train_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/hypernet-cnn/hypernet/tabular_hypernet/training_utils.py:311\u001b[0m, in \u001b[0;36mbasic_train_loop\u001b[0;34m(network, optimizer, criterion, trainloader, epochs, device)\u001b[0m\n\u001b[1;32m    309\u001b[0m network\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    310\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader):\n\u001b[1;32m    312\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    313\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1207\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1207\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1173\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1169\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1173\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1175\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1011\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1011\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1013\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1014\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hyper-mnist/lib/python3.9/multiprocessing/queues.py:122\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/torch/multiprocessing/reductions.py:295\u001b[0m, in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrebuild_storage_fd\u001b[39m(\u001b[38;5;28mcls\u001b[39m, df, size):\n\u001b[0;32m--> 295\u001b[0m     fd \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m         storage \u001b[38;5;241m=\u001b[39m storage_from_cache(\u001b[38;5;28mcls\u001b[39m, fd_id(fd))\n",
      "File \u001b[0;32m~/anaconda3/envs/hyper-mnist/lib/python3.9/multiprocessing/resource_sharer.py:57\u001b[0m, in \u001b[0;36mDupFd.detach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetach\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;124;03m'''Get the fd.  This should only be called once.'''\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_resource_sharer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reduction\u001b[38;5;241m.\u001b[39mrecv_handle(conn)\n",
      "File \u001b[0;32m~/anaconda3/envs/hyper-mnist/lib/python3.9/multiprocessing/resource_sharer.py:86\u001b[0m, in \u001b[0;36m_ResourceSharer.get_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[1;32m     85\u001b[0m address, key \u001b[38;5;241m=\u001b[39m ident\n\u001b[0;32m---> 86\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauthkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m c\u001b[38;5;241m.\u001b[39msend((key, os\u001b[38;5;241m.\u001b[39mgetpid()))\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[0;32m~/anaconda3/envs/hyper-mnist/lib/python3.9/multiprocessing/connection.py:513\u001b[0m, in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthkey should be a byte string\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m authkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 513\u001b[0m     \u001b[43manswer_challenge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m     deliver_challenge(c, authkey)\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[0;32m~/anaconda3/envs/hyper-mnist/lib/python3.9/multiprocessing/connection.py:762\u001b[0m, in \u001b[0;36manswer_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    760\u001b[0m digest \u001b[38;5;241m=\u001b[39m hmac\u001b[38;5;241m.\u001b[39mnew(authkey, message, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmd5\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdigest()\n\u001b[1;32m    761\u001b[0m connection\u001b[38;5;241m.\u001b[39msend_bytes(digest)\n\u001b[0;32m--> 762\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m        \u001b[38;5;66;03m# reject large message\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;241m!=\u001b[39m WELCOME:\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AuthenticationError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdigest sent was rejected\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/hyper-mnist/lib/python3.9/multiprocessing/connection.py:221\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative maxlength\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 221\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m~/anaconda3/envs/hyper-mnist/lib/python3.9/multiprocessing/connection.py:419\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 419\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/hyper-mnist/lib/python3.9/multiprocessing/connection.py:384\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    382\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 384\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_size = max_size\n",
    "\n",
    "nn3_results = test_model(network_fn3(**nn_fn3_best_params),\n",
    "                (X, y),\n",
    "                data_size,\n",
    "                None, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fdb86765-3874-4023-8e26-b40ccc6df903",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>86.858108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>59.235075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>79.513889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>73.046591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1 score</td>\n",
       "      <td>60.591603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>72.039885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>F1 score</td>\n",
       "      <td>59.244728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>roc_auc</td>\n",
       "      <td>83.373525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Precision</td>\n",
       "      <td>62.461220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Recall</td>\n",
       "      <td>56.343284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Class     Metric\n",
       "0                   0  86.858108\n",
       "1                   1  59.235075\n",
       "2               Total  79.513889\n",
       "3   balanced_accuracy  73.046591\n",
       "4            F1 score  60.591603\n",
       "..                ...        ...\n",
       "75  balanced_accuracy  72.039885\n",
       "76           F1 score  59.244728\n",
       "77            roc_auc  83.373525\n",
       "78          Precision  62.461220\n",
       "79             Recall  56.343284\n",
       "\n",
       "[80 rows x 2 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn3_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "98b56785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.293919</td>\n",
       "      <td>1.046516</td>\n",
       "      <td>87.736486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.339552</td>\n",
       "      <td>2.394965</td>\n",
       "      <td>61.660448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 score</th>\n",
       "      <td>59.456400</td>\n",
       "      <td>1.189401</td>\n",
       "      <td>61.459786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>60.692145</td>\n",
       "      <td>1.219709</td>\n",
       "      <td>62.461220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>58.339552</td>\n",
       "      <td>2.394965</td>\n",
       "      <td>61.660448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>78.861607</td>\n",
       "      <td>0.488821</td>\n",
       "      <td>79.513889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>72.316736</td>\n",
       "      <td>0.859346</td>\n",
       "      <td>73.769413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>83.182302</td>\n",
       "      <td>0.460967</td>\n",
       "      <td>83.655834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mean       std        max\n",
       "Class                                            \n",
       "0                  86.293919  1.046516  87.736486\n",
       "1                  58.339552  2.394965  61.660448\n",
       "F1 score           59.456400  1.189401  61.459786\n",
       "Precision          60.692145  1.219709  62.461220\n",
       "Recall             58.339552  2.394965  61.660448\n",
       "Total              78.861607  0.488821  79.513889\n",
       "balanced_accuracy  72.316736  0.859346  73.769413\n",
       "roc_auc            83.182302  0.460967  83.655834"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn3_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e933db2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blastchar: 72.32 ~ 0.86, (max: 73.77)\n"
     ]
    }
   ],
   "source": [
    "res = nn3_results[nn3_results[\"Class\"]==\"balanced_accuracy\"].reset_index(drop=True)[\"Metric\"]\n",
    "print(f\"{DATA}: {res.mean():.2f} ~ {res.std():.2f}, (max: {res.max():.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d60779d-0042-49af-8a32-e6d0b59e1589",
   "metadata": {
    "tags": []
   },
   "source": [
    "### HypernetworkPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6e5536d6-cf9d-4a2b-9d7b-184c0ac27a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_pca_fn(epochs=100, masks_no=100, mask_size=100, target_size=100, n_comp=5, lr=3e-4, batch_size=64, verbose=False):\n",
    "    def _inner():\n",
    "        hypernet = HypernetworkPCA(\n",
    "                        target_architecture=[(mask_size, target_size), (target_size, n_classes)], \n",
    "                        test_nodes=masks_no,\n",
    "                        architecture=torch.nn.Sequential(torch.nn.Linear(n_comp, 64), \n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(64, 128),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Dropout(),\n",
    "                            torch.nn.Linear(128, 128),\n",
    "                            torch.nn.ReLU(),\n",
    "                        ),\n",
    "                        mode=TrainingModes.CARTHESIAN,\n",
    "                        input_size=n_features\n",
    "                    ).to(DEVICE)    \n",
    "        hypernet = hypernet.train()\n",
    "\n",
    "        network = HypernetworkSklearnInterface(hypernet, device=DEVICE, epochs=epochs, batch_size=batch_size, verbose=verbose, lr=lr)\n",
    "        return network\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1e43b7af-9be5-427a-be2e-4f134ba1e644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_to_html():\n",
    "    tmpfile = BytesIO()\n",
    "    plt.gcf().savefig(tmpfile, format='png')\n",
    "    encoded = base64.b64encode(tmpfile.getvalue()).decode('utf-8')\n",
    "\n",
    "    html = '<img src=\\'data:image/png;base64,{}\\'>'.format(encoded)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a257e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be2e5638-be6d-4a42-8eb4-be84078643bb",
   "metadata": {},
   "source": [
    "#### Find hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "45f2e4fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 19:56:50.812 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params network_pca_fn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c121208dc9344f3ac24b389b59616cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 08:00:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "855\n",
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 13.7   : 1     : 42:14 (m:s)     \n",
      "Random seeding    : 86.48  : 4     : 04:55:18 (h:m:s)\n",
      "Local sampling    : 80.68  : 2     : 01:46:22 (h:m:s)\n",
      "Duplicates        : -      : 1     : -               \n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 86.48  : 8     : 07:23:54 (h:m:s)\n",
      "=====================================================\n",
      "cnae_network_pca_fn_{'epochs': 100, 'masks_no': 200, 'mask_size': 200, 'target_size': 50, 'n_comp': 3, 'lr': 3e-05, 'batch_size': 32}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs': 100,\n",
       " 'masks_no': 200,\n",
       " 'mask_size': 200,\n",
       " 'target_size': 50,\n",
       " 'n_comp': 3,\n",
       " 'lr': 3e-05,\n",
       " 'batch_size': 32}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"epochs\": pyhopper.choice([100]),\n",
    "    \"masks_no\": pyhopper.choice([100, 150, 200, 300, 500]),#pyhopper.int(50, 200, multiple_of=10),\n",
    "    \"mask_size\": pyhopper.choice([5, 10, 20, 50, 100, 200, 400]),\n",
    "    \"target_size\": pyhopper.choice([5, 10, 20, 50]),\n",
    "    \"n_comp\": pyhopper.choice([3, 10, 25, 50, 80]),\n",
    "    \"lr\": pyhopper.choice([3e-5, 3e-4, 3e-3, 3e-2, 3e-1]),\n",
    "    \"batch_size\": pyhopper.choice([32, 64]),\n",
    "\n",
    "}\n",
    "\n",
    "hp_pca_best_params, hp_pca_history = pyhopper_best_params(network_pca_fn, param_grid, time=\"480m\")\n",
    "hp_pca_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9569bae-98d8-4d2b-9643-3e57fe6bdcbf",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "df7c4b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 100,\n",
       " 'masks_no': 50,\n",
       " 'mask_size': 400,\n",
       " 'target_size': 50,\n",
       " 'n_comp': 3,\n",
       " 'lr': 3e-05,\n",
       " 'batch_size': 32}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_pca_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa4f868",
   "metadata": {},
   "source": [
    "'Libras'\n",
    "{'epochs': 150,\n",
    " 'masks_no': 70,\n",
    " 'mask_size': 20,\n",
    " 'target_size': 10,\n",
    " 'n_comp': 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8454fdc",
   "metadata": {},
   "source": [
    "'Lymphography' {'epochs': 120, 'masks_no': 50, 'mask_size': 4, 'target_size': 20, 'n_comp': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81b7e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803eafa7",
   "metadata": {},
   "source": [
    "Ionosphere\n",
    "{'epochs': 100, 'masks_no': 60, 'mask_size': 5, 'target_size': 10}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f5b3a72c-14cf-4d70-bb83-1f0a8aad5144",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 10\n",
      "torch.Size([1, 128])\n",
      "855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:50<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 10\n",
      "torch.Size([1, 128])\n",
      "855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:49<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 10\n",
      "torch.Size([1, 128])\n",
      "855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:49<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 10\n",
      "torch.Size([1, 128])\n",
      "855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:49<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 10\n",
      "torch.Size([1, 128])\n",
      "855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:50<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 6 of 10\n",
      "torch.Size([1, 128])\n",
      "855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:50<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 7 of 10\n",
      "torch.Size([1, 128])\n",
      "855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:49<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 8 of 10\n",
      "torch.Size([1, 128])\n",
      "855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:49<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 9 of 10\n",
      "torch.Size([1, 128])\n",
      "855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:50<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 10 of 10\n",
      "torch.Size([1, 128])\n",
      "855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:50<00:00,  1.70s/it]\n"
     ]
    }
   ],
   "source": [
    "epochs = 100#hp_pca_best_params['epochs']\n",
    "masks_no = hp_pca_best_params['masks_no']\n",
    "mask_size = hp_pca_best_params['mask_size']\n",
    "target_size = hp_pca_best_params['target_size']\n",
    "n_comp = hp_pca_best_params['n_comp']\n",
    "lr = hp_pca_best_params['lr']\n",
    "batch_size = hp_pca_best_params['batch_size']\n",
    "data_size = max_size\n",
    "\n",
    "nn_pca_results = test_model(network_pca_fn(target_size=target_size, mask_size=mask_size, masks_no=masks_no, n_comp=n_comp, epochs=epochs, verbose=True),\n",
    "                (X, y),\n",
    "                data_size,\n",
    "                None, 10)\n",
    "\n",
    "# exp.log_table(\"metrics.csv\", nn_pca_results.groupby(\"Class\").mean())\n",
    "# exp.log_metric(\"f1_score\", nn_pca_results.groupby(\"Class\").mean().loc[\"F1 score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b950280b-188d-4321-8db6-9cb69912a242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756: 94.97 ~ 0.97 (max: 96.60)\n"
     ]
    }
   ],
   "source": [
    "res = nn_pca_results[nn_pca_results[\"Class\"]==\"Total\"].reset_index(drop=True)[\"Metric\"]\n",
    "print(f\"{data_size}: {res.mean():.2f} ~ {res.std():.2f} (max: {res.max():.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6e0de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d82e3c9a-94c1-4984-a311-e0091c453333",
   "metadata": {},
   "source": [
    "### Hypernetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f81bdd75-482c-47ee-a9b3-4c2348f3b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_hp_fn(epochs=150, masks_no=100, mask_size=100, target_size=100, lr=3e-4, batch_size=64, verbose=False):\n",
    "    def _inner():\n",
    "        hypernet = Hypernetwork(\n",
    "                        target_architecture=[(mask_size, target_size), (target_size, n_classes)],\n",
    "                        test_nodes=masks_no,\n",
    "                        architecture=torch.nn.Sequential(torch.nn.Linear(n_features, 64), \n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(64, 128),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Dropout(),\n",
    "                            torch.nn.Linear(128, 128),\n",
    "                            torch.nn.ReLU(),\n",
    "                        ),\n",
    "                        mode=TrainingModes.CARTHESIAN,\n",
    "                    ).to(DEVICE)    \n",
    "        hypernet = hypernet.train()\n",
    "\n",
    "        network = HypernetworkSklearnInterface(hypernet, device=DEVICE, epochs=epochs, batch_size=batch_size, verbose=verbose, lr=lr)\n",
    "        return network\n",
    "    return _inner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76e319a",
   "metadata": {},
   "source": [
    "#### Find hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5235e59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-18 00:47:30.079 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params network_hp_fn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f93517881564ed5b033eb6f8ea69699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 09:00:00 (h:m:s)\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 1 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 2 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 3 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 4 of 5\n",
      "torch.Size([1, 128])\n",
      "iter 5 of 5\n",
      "torch.Size([1, 128])\n",
      "====================== Summary ======================\n",
      "Mode              : Best f : Steps : Time            \n",
      "----------------  : ----   : ----  : ----            \n",
      "Initial solution  : 77.26  : 1     : 01:53 (m:s)     \n",
      "Random seeding    : 81.79  : 17    : 04:33:54 (h:m:s)\n",
      "Local sampling    : 81.43  : 13    : 04:09:30 (h:m:s)\n",
      "Duplicates        : -      : 1     : -               \n",
      "----------------  : ----   : ----  : ----            \n",
      "Total             : 81.79  : 32    : 08:45:18 (h:m:s)\n",
      "=====================================================\n",
      "Cleveland_network_hp_fn_{'epochs': 100, 'masks_no': 150, 'mask_size': 2, 'target_size': 5, 'lr': 0.0003, 'batch_size': 64}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs': 100,\n",
       " 'masks_no': 150,\n",
       " 'mask_size': 2,\n",
       " 'target_size': 5,\n",
       " 'lr': 0.0003,\n",
       " 'batch_size': 64}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"epochs\": pyhopper.choice([100]),\n",
    "    \"masks_no\": pyhopper.choice([3, 5, 10, 50, 75, 100, 150, 200, 300, 500]), #pyhopper.int(10, 400, multiple_of=10),\n",
    "    \"mask_size\": pyhopper.choice([2, 3, 5, 7, 10, 12, 13]),\n",
    "    \"target_size\": pyhopper.choice([5, 10, 20, 50]),\n",
    "    \"lr\": pyhopper.choice([3e-5, 3e-4, 3e-3, 3e-2, 3e-1]),\n",
    "    \"batch_size\": pyhopper.choice([32, 64]),\n",
    "}\n",
    "\n",
    "hp_best_params, hp_history = pyhopper_best_params(network_hp_fn, param_grid, time=f\"{9*60}m\")\n",
    "hp_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b4b9203a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 100,\n",
       " 'masks_no': 150,\n",
       " 'mask_size': 2,\n",
       " 'target_size': 5,\n",
       " 'lr': 0.0003,\n",
       " 'batch_size': 64}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe02f07-52f6-4735-93f5-8e14bd22803f",
   "metadata": {},
   "source": [
    "#### Train using the best hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "283d9aca-1f98-42e6-b229-e14e937cb431",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 10\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:02<03:34,  2.17s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:04<03:30,  2.15s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [00:06<03:28,  2.15s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [00:08<03:12,  2.00s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [00:09<03:00,  1.90s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [00:11<02:51,  1.83s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [00:13<03:00,  1.94s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [00:15<03:04,  2.01s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [00:18<03:07,  2.06s/it]\u001b[A\n",
      " 10%|█         | 10/100 [00:20<03:07,  2.09s/it]\u001b[A\n",
      " 11%|█         | 11/100 [00:22<03:08,  2.11s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:24<03:07,  2.13s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:26<03:07,  2.16s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:28<03:05,  2.16s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:31<03:07,  2.21s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:33<03:04,  2.19s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:35<03:02,  2.19s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:37<02:59,  2.19s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:40<02:56,  2.18s/it]\u001b[A\n",
      " 20%|██        | 20/100 [00:42<02:54,  2.18s/it]\u001b[A\n",
      " 21%|██        | 21/100 [00:44<02:52,  2.18s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:46<02:55,  2.25s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [00:48<02:52,  2.24s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:51<02:48,  2.22s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:53<02:44,  2.20s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:55<02:42,  2.19s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:57<02:39,  2.19s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [00:59<02:36,  2.18s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [01:01<02:34,  2.17s/it]\u001b[A\n",
      " 30%|███       | 30/100 [01:03<02:24,  2.06s/it]\u001b[A\n",
      " 31%|███       | 31/100 [01:06<02:27,  2.13s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [01:08<02:29,  2.19s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [01:10<02:27,  2.20s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [01:12<02:24,  2.19s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [01:15<02:22,  2.19s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [01:17<02:20,  2.19s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [01:19<02:17,  2.18s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [01:21<02:15,  2.18s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [01:23<02:12,  2.18s/it]\u001b[A\n",
      " 40%|████      | 40/100 [01:25<02:10,  2.18s/it]\u001b[A\n",
      " 41%|████      | 41/100 [01:28<02:08,  2.18s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [01:30<02:06,  2.18s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [01:32<02:04,  2.18s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [01:34<02:01,  2.18s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [01:36<02:00,  2.19s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [01:38<01:57,  2.18s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [01:41<01:55,  2.17s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [01:43<01:52,  2.17s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [01:45<01:44,  2.04s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [01:47<01:40,  2.02s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [01:49<01:41,  2.06s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [01:51<01:40,  2.09s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [01:53<01:39,  2.11s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [01:55<01:37,  2.13s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [01:57<01:36,  2.14s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [02:00<01:36,  2.20s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [02:02<01:33,  2.19s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [02:04<01:31,  2.17s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [02:06<01:29,  2.18s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [02:08<01:27,  2.18s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [02:10<01:24,  2.17s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [02:13<01:22,  2.17s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [02:15<01:20,  2.17s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [02:17<01:17,  2.17s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [02:19<01:15,  2.17s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [02:21<01:13,  2.17s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [02:23<01:11,  2.16s/it]\u001b[A\n",
      " 68%|██████▊   | 68/100 [02:26<01:09,  2.16s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [02:28<01:07,  2.16s/it]\u001b[A\n",
      " 70%|███████   | 70/100 [02:30<01:05,  2.17s/it]\u001b[A\n",
      " 71%|███████   | 71/100 [02:32<01:03,  2.18s/it]\u001b[A\n",
      " 72%|███████▏  | 72/100 [02:34<01:01,  2.18s/it]\u001b[A\n",
      " 73%|███████▎  | 73/100 [02:37<00:58,  2.18s/it]\u001b[A\n",
      " 74%|███████▍  | 74/100 [02:39<00:56,  2.18s/it]\u001b[A\n",
      " 75%|███████▌  | 75/100 [02:41<00:51,  2.06s/it]\u001b[A\n",
      " 76%|███████▌  | 76/100 [02:42<00:46,  1.96s/it]\u001b[A\n",
      " 77%|███████▋  | 77/100 [02:44<00:43,  1.88s/it]\u001b[A\n",
      " 78%|███████▊  | 78/100 [02:46<00:40,  1.83s/it]\u001b[A\n",
      " 79%|███████▉  | 79/100 [02:47<00:37,  1.80s/it]\u001b[A\n",
      " 80%|████████  | 80/100 [02:49<00:35,  1.77s/it]\u001b[A\n",
      " 81%|████████  | 81/100 [02:51<00:33,  1.75s/it]\u001b[A\n",
      " 82%|████████▏ | 82/100 [02:52<00:31,  1.74s/it]\u001b[A\n",
      " 83%|████████▎ | 83/100 [02:54<00:29,  1.73s/it]\u001b[A\n",
      " 84%|████████▍ | 84/100 [02:56<00:27,  1.72s/it]\u001b[A\n",
      " 85%|████████▌ | 85/100 [02:58<00:28,  1.89s/it]\u001b[A\n",
      " 86%|████████▌ | 86/100 [03:00<00:27,  1.98s/it]\u001b[A\n",
      " 87%|████████▋ | 87/100 [03:03<00:26,  2.03s/it]\u001b[A\n",
      " 88%|████████▊ | 88/100 [03:05<00:25,  2.11s/it]\u001b[A\n",
      " 89%|████████▉ | 89/100 [03:07<00:23,  2.12s/it]\u001b[A\n",
      " 90%|█████████ | 90/100 [03:09<00:21,  2.13s/it]\u001b[A\n",
      " 91%|█████████ | 91/100 [03:11<00:19,  2.14s/it]\u001b[A\n",
      " 92%|█████████▏| 92/100 [03:13<00:17,  2.14s/it]\u001b[A\n",
      " 93%|█████████▎| 93/100 [03:16<00:15,  2.14s/it]\u001b[A\n",
      " 94%|█████████▍| 94/100 [03:18<00:12,  2.14s/it]\u001b[A\n",
      " 95%|█████████▌| 95/100 [03:20<00:10,  2.14s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [03:22<00:08,  2.15s/it]\u001b[A\n",
      " 97%|█████████▋| 97/100 [03:24<00:06,  2.16s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [03:26<00:04,  2.17s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [03:29<00:02,  2.17s/it]\u001b[A\n",
      "100%|██████████| 100/100 [03:31<00:00,  2.11s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 10\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:02<03:40,  2.23s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:04<03:35,  2.19s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [00:06<03:32,  2.19s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [00:08<03:30,  2.20s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [00:10<03:27,  2.19s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [00:13<03:25,  2.18s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [00:15<03:23,  2.19s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [00:17<03:20,  2.18s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [00:19<03:17,  2.17s/it]\u001b[A\n",
      " 10%|█         | 10/100 [00:21<03:16,  2.19s/it]\u001b[A\n",
      " 11%|█         | 11/100 [00:24<03:14,  2.18s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:26<03:11,  2.18s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:28<03:10,  2.19s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:30<03:07,  2.18s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:32<03:04,  2.18s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:34<03:02,  2.17s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:37<03:00,  2.17s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:39<02:58,  2.17s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:41<02:55,  2.17s/it]\u001b[A\n",
      " 20%|██        | 20/100 [00:43<02:53,  2.17s/it]\u001b[A\n",
      " 21%|██        | 21/100 [00:45<02:51,  2.16s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:47<02:48,  2.17s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [00:50<02:46,  2.16s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:52<02:44,  2.17s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:54<02:41,  2.16s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:56<02:39,  2.15s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:58<02:37,  2.15s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [01:00<02:36,  2.17s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [01:02<02:25,  2.04s/it]\u001b[A\n",
      " 30%|███       | 30/100 [01:04<02:21,  2.02s/it]\u001b[A\n",
      " 31%|███       | 31/100 [01:06<02:22,  2.06s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [01:08<02:21,  2.09s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [01:11<02:21,  2.11s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [01:13<02:20,  2.14s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [01:15<02:18,  2.14s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [01:17<02:17,  2.15s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [01:19<02:15,  2.15s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [01:21<02:13,  2.16s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [01:24<02:11,  2.16s/it]\u001b[A\n",
      " 40%|████      | 40/100 [01:26<02:09,  2.16s/it]\u001b[A\n",
      " 41%|████      | 41/100 [01:28<02:07,  2.16s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [01:30<02:05,  2.17s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [01:32<02:06,  2.21s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [01:35<02:02,  2.19s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [01:37<01:59,  2.18s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [01:39<01:57,  2.17s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [01:41<01:54,  2.16s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [01:43<01:52,  2.17s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [01:45<01:50,  2.16s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [01:48<01:48,  2.17s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [01:50<01:46,  2.17s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [01:52<01:43,  2.17s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [01:54<01:41,  2.17s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [01:56<01:40,  2.17s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [01:58<01:37,  2.18s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [02:01<01:36,  2.20s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [02:03<01:34,  2.19s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [02:05<01:33,  2.21s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [02:07<01:32,  2.24s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [02:10<01:28,  2.22s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [02:12<01:25,  2.20s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [02:14<01:23,  2.19s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [02:16<01:20,  2.18s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [02:18<01:18,  2.19s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [02:20<01:16,  2.18s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [02:23<01:14,  2.20s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [02:25<01:12,  2.19s/it]\u001b[A\n",
      " 68%|██████▊   | 68/100 [02:27<01:10,  2.19s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [02:29<01:08,  2.20s/it]\u001b[A\n",
      " 70%|███████   | 70/100 [02:31<01:05,  2.19s/it]\u001b[A\n",
      " 71%|███████   | 71/100 [02:34<01:03,  2.18s/it]\u001b[A\n",
      " 72%|███████▏  | 72/100 [02:36<01:00,  2.18s/it]\u001b[A\n",
      " 73%|███████▎  | 73/100 [02:38<00:59,  2.20s/it]\u001b[A\n",
      " 74%|███████▍  | 74/100 [02:40<00:56,  2.19s/it]\u001b[A\n",
      " 75%|███████▌  | 75/100 [02:42<00:54,  2.18s/it]\u001b[A\n",
      " 76%|███████▌  | 76/100 [02:44<00:52,  2.17s/it]\u001b[A\n",
      " 77%|███████▋  | 77/100 [02:47<00:50,  2.18s/it]\u001b[A\n",
      " 78%|███████▊  | 78/100 [02:49<00:47,  2.18s/it]\u001b[A\n",
      " 79%|███████▉  | 79/100 [02:51<00:45,  2.18s/it]\u001b[A\n",
      " 80%|████████  | 80/100 [02:53<00:43,  2.17s/it]\u001b[A\n",
      " 81%|████████  | 81/100 [02:55<00:41,  2.17s/it]\u001b[A\n",
      " 82%|████████▏ | 82/100 [02:57<00:38,  2.16s/it]\u001b[A\n",
      " 83%|████████▎ | 83/100 [03:00<00:36,  2.16s/it]\u001b[A\n",
      " 84%|████████▍ | 84/100 [03:02<00:34,  2.17s/it]\u001b[A\n",
      " 85%|████████▌ | 85/100 [03:04<00:32,  2.16s/it]\u001b[A\n",
      " 86%|████████▌ | 86/100 [03:06<00:30,  2.17s/it]\u001b[A\n",
      " 87%|████████▋ | 87/100 [03:08<00:28,  2.16s/it]\u001b[A\n",
      " 88%|████████▊ | 88/100 [03:11<00:26,  2.21s/it]\u001b[A\n",
      " 89%|████████▉ | 89/100 [03:12<00:22,  2.08s/it]\u001b[A\n",
      " 90%|█████████ | 90/100 [03:14<00:19,  1.97s/it]\u001b[A\n",
      " 91%|█████████ | 91/100 [03:16<00:17,  1.89s/it]\u001b[A\n",
      " 92%|█████████▏| 92/100 [03:17<00:14,  1.83s/it]\u001b[A\n",
      " 93%|█████████▎| 93/100 [03:19<00:12,  1.80s/it]\u001b[A\n",
      " 94%|█████████▍| 94/100 [03:21<00:10,  1.77s/it]\u001b[A\n",
      " 95%|█████████▌| 95/100 [03:23<00:09,  1.90s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [03:25<00:07,  1.98s/it]\u001b[A\n",
      " 97%|█████████▋| 97/100 [03:27<00:06,  2.04s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [03:30<00:04,  2.09s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [03:32<00:02,  2.11s/it]\u001b[A\n",
      "100%|██████████| 100/100 [03:34<00:00,  2.15s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 10\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:02<03:32,  2.15s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:04<03:32,  2.16s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [00:06<03:30,  2.17s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [00:08<03:30,  2.19s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [00:10<03:27,  2.19s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [00:13<03:25,  2.18s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [00:15<03:21,  2.17s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [00:17<03:19,  2.16s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [00:19<03:16,  2.16s/it]\u001b[A\n",
      " 10%|█         | 10/100 [00:21<03:14,  2.16s/it]\u001b[A\n",
      " 11%|█         | 11/100 [00:23<03:11,  2.15s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:25<03:09,  2.15s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:28<03:06,  2.15s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:30<03:04,  2.15s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:32<03:02,  2.15s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:34<03:00,  2.15s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:36<02:59,  2.16s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:38<02:57,  2.16s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:41<02:55,  2.17s/it]\u001b[A\n",
      " 20%|██        | 20/100 [00:43<02:53,  2.17s/it]\u001b[A\n",
      " 21%|██        | 21/100 [00:45<02:51,  2.17s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:47<02:48,  2.16s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [00:49<02:45,  2.15s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:52<02:51,  2.26s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:54<02:47,  2.23s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:56<02:43,  2.21s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:58<02:40,  2.20s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [01:00<02:38,  2.20s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [01:03<02:35,  2.18s/it]\u001b[A\n",
      " 30%|███       | 30/100 [01:04<02:24,  2.07s/it]\u001b[A\n",
      " 31%|███       | 31/100 [01:06<02:15,  1.96s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [01:08<02:08,  1.89s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [01:10<02:08,  1.92s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [01:12<02:11,  1.99s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [01:14<02:12,  2.03s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [01:16<02:12,  2.07s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [01:18<02:12,  2.10s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [01:21<02:11,  2.12s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [01:23<02:10,  2.13s/it]\u001b[A\n",
      " 40%|████      | 40/100 [01:25<02:08,  2.14s/it]\u001b[A\n",
      " 41%|████      | 41/100 [01:27<02:06,  2.14s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [01:29<02:04,  2.14s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [01:31<02:02,  2.15s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [01:33<02:00,  2.14s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [01:36<01:57,  2.14s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [01:38<01:55,  2.14s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [01:40<01:53,  2.14s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [01:42<01:51,  2.14s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [01:44<01:49,  2.14s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [01:46<01:47,  2.14s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [01:48<01:45,  2.15s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [01:51<01:43,  2.15s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [01:53<01:41,  2.15s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [01:55<01:39,  2.15s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [01:57<01:36,  2.15s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [01:59<01:34,  2.15s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [02:01<01:32,  2.15s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [02:04<01:31,  2.18s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [02:06<01:29,  2.17s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [02:08<01:27,  2.18s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [02:10<01:24,  2.18s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [02:12<01:22,  2.18s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [02:15<01:20,  2.18s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [02:17<01:18,  2.17s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [02:19<01:16,  2.18s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [02:21<01:13,  2.17s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [02:23<01:11,  2.17s/it]\u001b[A\n",
      " 68%|██████▊   | 68/100 [02:25<01:09,  2.17s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [02:28<01:08,  2.21s/it]\u001b[A\n",
      " 70%|███████   | 70/100 [02:30<01:05,  2.20s/it]\u001b[A\n",
      " 71%|███████   | 71/100 [02:32<01:05,  2.25s/it]\u001b[A\n",
      " 72%|███████▏  | 72/100 [02:34<01:02,  2.24s/it]\u001b[A\n",
      " 73%|███████▎  | 73/100 [02:37<00:59,  2.21s/it]\u001b[A\n",
      " 74%|███████▍  | 74/100 [02:39<00:57,  2.21s/it]\u001b[A\n",
      " 75%|███████▌  | 75/100 [02:41<00:54,  2.20s/it]\u001b[A\n",
      " 76%|███████▌  | 76/100 [02:43<00:52,  2.20s/it]\u001b[A\n",
      " 77%|███████▋  | 77/100 [02:45<00:50,  2.20s/it]\u001b[A\n",
      " 78%|███████▊  | 78/100 [02:48<00:48,  2.19s/it]\u001b[A\n",
      " 79%|███████▉  | 79/100 [02:50<00:46,  2.21s/it]\u001b[A\n",
      " 80%|████████  | 80/100 [02:52<00:44,  2.23s/it]\u001b[A\n",
      " 81%|████████  | 81/100 [02:54<00:42,  2.24s/it]\u001b[A\n",
      " 82%|████████▏ | 82/100 [02:57<00:40,  2.22s/it]\u001b[A\n",
      " 83%|████████▎ | 83/100 [02:59<00:37,  2.20s/it]\u001b[A\n",
      " 84%|████████▍ | 84/100 [03:01<00:34,  2.19s/it]\u001b[A\n",
      " 85%|████████▌ | 85/100 [03:03<00:32,  2.17s/it]\u001b[A\n",
      " 86%|████████▌ | 86/100 [03:05<00:30,  2.16s/it]\u001b[A\n",
      " 87%|████████▋ | 87/100 [03:07<00:28,  2.16s/it]\u001b[A\n",
      " 88%|████████▊ | 88/100 [03:09<00:25,  2.16s/it]\u001b[A\n",
      " 89%|████████▉ | 89/100 [03:12<00:23,  2.15s/it]\u001b[A\n",
      " 90%|█████████ | 90/100 [03:13<00:20,  2.03s/it]\u001b[A\n",
      " 91%|█████████ | 91/100 [03:15<00:17,  1.94s/it]\u001b[A\n",
      " 92%|█████████▏| 92/100 [03:17<00:16,  2.00s/it]\u001b[A\n",
      " 93%|█████████▎| 93/100 [03:19<00:14,  2.05s/it]\u001b[A\n",
      " 94%|█████████▍| 94/100 [03:22<00:12,  2.11s/it]\u001b[A\n",
      " 95%|█████████▌| 95/100 [03:24<00:10,  2.12s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [03:26<00:08,  2.13s/it]\u001b[A\n",
      " 97%|█████████▋| 97/100 [03:28<00:06,  2.02s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [03:29<00:03,  1.93s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [03:32<00:02,  2.01s/it]\u001b[A\n",
      "100%|██████████| 100/100 [03:34<00:00,  2.14s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 10\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:02<03:49,  2.32s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:04<03:39,  2.24s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [00:06<03:37,  2.24s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [00:08<03:32,  2.21s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [00:11<03:28,  2.20s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [00:12<03:13,  2.06s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [00:15<03:16,  2.11s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [00:17<03:16,  2.13s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [00:19<03:15,  2.15s/it]\u001b[A\n",
      " 10%|█         | 10/100 [00:21<03:14,  2.16s/it]\u001b[A\n",
      " 11%|█         | 11/100 [00:23<03:12,  2.16s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:26<03:11,  2.18s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:28<03:09,  2.18s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:30<03:08,  2.19s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:32<03:05,  2.19s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:34<03:05,  2.21s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:37<03:02,  2.20s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:39<02:59,  2.19s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:41<02:57,  2.19s/it]\u001b[A\n",
      " 20%|██        | 20/100 [00:43<02:54,  2.18s/it]\u001b[A\n",
      " 21%|██        | 21/100 [00:45<02:52,  2.18s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:47<02:50,  2.18s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [00:50<02:48,  2.18s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:52<02:45,  2.18s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:54<02:44,  2.19s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:56<02:41,  2.19s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:58<02:38,  2.18s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [01:00<02:36,  2.17s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [01:03<02:33,  2.17s/it]\u001b[A\n",
      " 30%|███       | 30/100 [01:05<02:31,  2.16s/it]\u001b[A\n",
      " 31%|███       | 31/100 [01:07<02:29,  2.16s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [01:09<02:18,  2.04s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [01:11<02:20,  2.10s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [01:13<02:19,  2.12s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [01:15<02:18,  2.13s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [01:17<02:16,  2.14s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [01:19<02:08,  2.03s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [01:21<02:10,  2.10s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [01:24<02:09,  2.12s/it]\u001b[A\n",
      " 40%|████      | 40/100 [01:26<02:07,  2.13s/it]\u001b[A\n",
      " 41%|████      | 41/100 [01:28<02:05,  2.13s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [01:30<02:04,  2.14s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [01:32<02:01,  2.14s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [01:34<01:59,  2.14s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [01:37<01:58,  2.15s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [01:39<01:56,  2.15s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [01:41<01:54,  2.16s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [01:43<01:51,  2.15s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [01:45<01:50,  2.16s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [01:47<01:47,  2.16s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [01:49<01:46,  2.16s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [01:52<01:44,  2.17s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [01:54<01:42,  2.17s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [01:56<01:39,  2.17s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [01:58<01:38,  2.18s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [02:00<01:35,  2.18s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [02:03<01:35,  2.22s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [02:05<01:33,  2.22s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [02:07<01:30,  2.20s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [02:09<01:27,  2.19s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [02:11<01:25,  2.18s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [02:14<01:22,  2.18s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [02:16<01:20,  2.18s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [02:18<01:17,  2.16s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [02:20<01:15,  2.16s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [02:22<01:13,  2.17s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [02:25<01:12,  2.21s/it]\u001b[A\n",
      " 68%|██████▊   | 68/100 [02:27<01:10,  2.20s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [02:29<01:07,  2.19s/it]\u001b[A\n",
      " 70%|███████   | 70/100 [02:31<01:05,  2.17s/it]\u001b[A\n",
      " 71%|███████   | 71/100 [02:33<01:02,  2.17s/it]\u001b[A\n",
      " 72%|███████▏  | 72/100 [02:35<01:00,  2.16s/it]\u001b[A\n",
      " 73%|███████▎  | 73/100 [02:37<00:58,  2.16s/it]\u001b[A\n",
      " 74%|███████▍  | 74/100 [02:40<00:56,  2.16s/it]\u001b[A\n",
      " 75%|███████▌  | 75/100 [02:42<00:54,  2.16s/it]\u001b[A\n",
      " 76%|███████▌  | 76/100 [02:44<00:51,  2.16s/it]\u001b[A\n",
      " 77%|███████▋  | 77/100 [02:46<00:49,  2.16s/it]\u001b[A\n",
      " 78%|███████▊  | 78/100 [02:48<00:47,  2.16s/it]\u001b[A\n",
      " 79%|███████▉  | 79/100 [02:50<00:45,  2.16s/it]\u001b[A\n",
      " 80%|████████  | 80/100 [02:52<00:40,  2.04s/it]\u001b[A\n",
      " 81%|████████  | 81/100 [02:54<00:36,  1.94s/it]\u001b[A\n",
      " 82%|████████▏ | 82/100 [02:56<00:36,  2.03s/it]\u001b[A\n",
      " 83%|████████▎ | 83/100 [02:58<00:35,  2.08s/it]\u001b[A\n",
      " 84%|████████▍ | 84/100 [03:01<00:33,  2.11s/it]\u001b[A\n",
      " 85%|████████▌ | 85/100 [03:03<00:32,  2.13s/it]\u001b[A\n",
      " 86%|████████▌ | 86/100 [03:05<00:30,  2.15s/it]\u001b[A\n",
      " 87%|████████▋ | 87/100 [03:07<00:28,  2.16s/it]\u001b[A\n",
      " 88%|████████▊ | 88/100 [03:09<00:25,  2.16s/it]\u001b[A\n",
      " 89%|████████▉ | 89/100 [03:11<00:23,  2.16s/it]\u001b[A\n",
      " 90%|█████████ | 90/100 [03:14<00:21,  2.16s/it]\u001b[A\n",
      " 91%|█████████ | 91/100 [03:16<00:19,  2.18s/it]\u001b[A\n",
      " 92%|█████████▏| 92/100 [03:18<00:17,  2.18s/it]\u001b[A\n",
      " 93%|█████████▎| 93/100 [03:20<00:15,  2.18s/it]\u001b[A\n",
      " 94%|█████████▍| 94/100 [03:22<00:13,  2.17s/it]\u001b[A\n",
      " 95%|█████████▌| 95/100 [03:24<00:10,  2.16s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [03:27<00:08,  2.16s/it]\u001b[A\n",
      " 97%|█████████▋| 97/100 [03:29<00:06,  2.20s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [03:31<00:04,  2.19s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [03:33<00:02,  2.17s/it]\u001b[A\n",
      "100%|██████████| 100/100 [03:36<00:00,  2.16s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 10\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:02<03:33,  2.16s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:04<03:33,  2.18s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [00:06<03:32,  2.19s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [00:08<03:29,  2.18s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [00:10<03:27,  2.18s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [00:13<03:26,  2.20s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [00:15<03:23,  2.18s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [00:17<03:20,  2.18s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [00:19<03:17,  2.17s/it]\u001b[A\n",
      " 10%|█         | 10/100 [00:21<03:14,  2.17s/it]\u001b[A\n",
      " 11%|█         | 11/100 [00:23<03:12,  2.16s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:25<02:59,  2.04s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:27<02:48,  1.94s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:29<02:41,  1.88s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:30<02:35,  1.83s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:32<02:30,  1.80s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:34<02:26,  1.77s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:35<02:23,  1.75s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:37<02:20,  1.74s/it]\u001b[A\n",
      " 20%|██        | 20/100 [00:39<02:18,  1.73s/it]\u001b[A\n",
      " 21%|██        | 21/100 [00:41<02:15,  1.72s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:42<02:14,  1.72s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [00:44<02:12,  1.72s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:46<02:10,  1.72s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:47<02:08,  1.72s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:49<02:07,  1.72s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:51<02:05,  1.72s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [00:53<02:03,  1.72s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [00:54<02:02,  1.72s/it]\u001b[A\n",
      " 30%|███       | 30/100 [00:56<02:00,  1.72s/it]\u001b[A\n",
      " 31%|███       | 31/100 [00:58<01:58,  1.72s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [01:00<01:57,  1.72s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [01:01<01:55,  1.72s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [01:03<01:53,  1.72s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [01:05<02:02,  1.88s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [01:07<02:05,  1.96s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [01:10<02:07,  2.02s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [01:12<02:08,  2.07s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [01:14<02:07,  2.10s/it]\u001b[A\n",
      " 40%|████      | 40/100 [01:16<02:07,  2.12s/it]\u001b[A\n",
      " 41%|████      | 41/100 [01:18<02:05,  2.13s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [01:20<01:56,  2.01s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [01:22<01:49,  1.92s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [01:24<01:52,  2.01s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [01:26<01:53,  2.07s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [01:28<01:52,  2.09s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [01:30<01:52,  2.12s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [01:33<01:50,  2.13s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [01:35<01:50,  2.16s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [01:37<01:48,  2.16s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [01:39<01:48,  2.20s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [01:41<01:45,  2.19s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [01:44<01:42,  2.18s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [01:46<01:40,  2.18s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [01:48<01:38,  2.18s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [01:50<01:36,  2.18s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [01:52<01:28,  2.05s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [01:54<01:28,  2.11s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [01:56<01:28,  2.16s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [01:59<01:26,  2.16s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [02:01<01:24,  2.16s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [02:03<01:21,  2.15s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [02:05<01:19,  2.16s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [02:07<01:17,  2.16s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [02:09<01:15,  2.16s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [02:11<01:13,  2.16s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [02:14<01:12,  2.19s/it]\u001b[A\n",
      " 68%|██████▊   | 68/100 [02:16<01:09,  2.18s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [02:18<01:04,  2.08s/it]\u001b[A\n",
      " 70%|███████   | 70/100 [02:20<01:03,  2.12s/it]\u001b[A\n",
      " 71%|███████   | 71/100 [02:22<01:01,  2.14s/it]\u001b[A\n",
      " 72%|███████▏  | 72/100 [02:24<01:00,  2.14s/it]\u001b[A\n",
      " 73%|███████▎  | 73/100 [02:26<00:58,  2.15s/it]\u001b[A\n",
      " 74%|███████▍  | 74/100 [02:29<00:56,  2.16s/it]\u001b[A\n",
      " 75%|███████▌  | 75/100 [02:31<00:54,  2.16s/it]\u001b[A\n",
      " 76%|███████▌  | 76/100 [02:33<00:51,  2.16s/it]\u001b[A\n",
      " 77%|███████▋  | 77/100 [02:35<00:49,  2.16s/it]\u001b[A\n",
      " 78%|███████▊  | 78/100 [02:37<00:47,  2.16s/it]\u001b[A\n",
      " 79%|███████▉  | 79/100 [02:40<00:46,  2.22s/it]\u001b[A\n",
      " 80%|████████  | 80/100 [02:42<00:44,  2.20s/it]\u001b[A\n",
      " 81%|████████  | 81/100 [02:44<00:41,  2.19s/it]\u001b[A\n",
      " 82%|████████▏ | 82/100 [02:46<00:39,  2.17s/it]\u001b[A\n",
      " 83%|████████▎ | 83/100 [02:48<00:36,  2.16s/it]\u001b[A\n",
      " 84%|████████▍ | 84/100 [02:50<00:34,  2.16s/it]\u001b[A\n",
      " 85%|████████▌ | 85/100 [02:53<00:32,  2.16s/it]\u001b[A\n",
      " 86%|████████▌ | 86/100 [02:55<00:30,  2.16s/it]\u001b[A\n",
      " 87%|████████▋ | 87/100 [02:57<00:28,  2.16s/it]\u001b[A\n",
      " 88%|████████▊ | 88/100 [02:59<00:25,  2.16s/it]\u001b[A\n",
      " 89%|████████▉ | 89/100 [03:01<00:23,  2.17s/it]\u001b[A\n",
      " 90%|█████████ | 90/100 [03:03<00:20,  2.05s/it]\u001b[A\n",
      " 91%|█████████ | 91/100 [03:05<00:17,  1.95s/it]\u001b[A\n",
      " 92%|█████████▏| 92/100 [03:06<00:14,  1.87s/it]\u001b[A\n",
      " 93%|█████████▎| 93/100 [03:08<00:12,  1.82s/it]\u001b[A\n",
      " 94%|█████████▍| 94/100 [03:10<00:10,  1.79s/it]\u001b[A\n",
      " 95%|█████████▌| 95/100 [03:12<00:08,  1.77s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [03:13<00:07,  1.75s/it]\u001b[A\n",
      " 97%|█████████▋| 97/100 [03:15<00:05,  1.89s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [03:18<00:03,  1.97s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [03:20<00:02,  2.02s/it]\u001b[A\n",
      "100%|██████████| 100/100 [03:22<00:00,  2.02s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 6 of 10\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:02<03:33,  2.16s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:04<03:31,  2.16s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [00:06<03:28,  2.15s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [00:08<03:11,  2.00s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [00:09<03:00,  1.90s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [00:11<02:52,  1.83s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [00:13<02:46,  1.79s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [00:15<02:42,  1.77s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [00:16<02:39,  1.75s/it]\u001b[A\n",
      " 10%|█         | 10/100 [00:19<02:51,  1.91s/it]\u001b[A\n",
      " 11%|█         | 11/100 [00:21<02:56,  1.98s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:23<03:00,  2.06s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:25<03:01,  2.09s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:27<03:01,  2.11s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:29<03:00,  2.12s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:32<02:59,  2.13s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:34<02:57,  2.14s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:36<02:55,  2.14s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:38<02:55,  2.17s/it]\u001b[A\n",
      " 20%|██        | 20/100 [00:40<02:53,  2.17s/it]\u001b[A\n",
      " 21%|██        | 21/100 [00:42<02:52,  2.18s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:45<02:49,  2.18s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [00:47<02:49,  2.21s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:49<02:46,  2.19s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:51<02:44,  2.19s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:53<02:41,  2.18s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:56<02:38,  2.18s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [00:58<02:36,  2.17s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [01:00<02:34,  2.17s/it]\u001b[A\n",
      " 30%|███       | 30/100 [01:02<02:32,  2.17s/it]\u001b[A\n",
      " 31%|███       | 31/100 [01:04<02:30,  2.18s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [01:06<02:28,  2.18s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [01:09<02:26,  2.18s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [01:11<02:23,  2.17s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [01:13<02:23,  2.21s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [01:16<02:26,  2.29s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [01:18<02:22,  2.26s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [01:20<02:18,  2.23s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [01:22<02:15,  2.22s/it]\u001b[A\n",
      " 40%|████      | 40/100 [01:24<02:12,  2.20s/it]\u001b[A\n",
      " 41%|████      | 41/100 [01:26<02:09,  2.19s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [01:29<02:06,  2.18s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [01:31<02:03,  2.17s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [01:33<02:01,  2.16s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [01:35<01:58,  2.15s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [01:37<01:56,  2.15s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [01:39<01:53,  2.15s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [01:41<01:51,  2.15s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [01:44<01:49,  2.15s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [01:46<01:47,  2.15s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [01:48<01:45,  2.15s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [01:50<01:43,  2.15s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [01:52<01:42,  2.18s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [01:54<01:39,  2.17s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [01:57<01:37,  2.17s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [01:59<01:35,  2.17s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [02:01<01:33,  2.17s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [02:03<01:31,  2.17s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [02:05<01:28,  2.16s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [02:07<01:26,  2.16s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [02:10<01:24,  2.16s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [02:12<01:21,  2.16s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [02:14<01:19,  2.15s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [02:16<01:17,  2.15s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [02:18<01:16,  2.19s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [02:21<01:14,  2.18s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [02:23<01:11,  2.17s/it]\u001b[A\n",
      " 68%|██████▊   | 68/100 [02:24<01:05,  2.05s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [02:26<01:00,  1.95s/it]\u001b[A\n",
      " 70%|███████   | 70/100 [02:28<01:00,  2.02s/it]\u001b[A\n",
      " 71%|███████   | 71/100 [02:30<00:59,  2.06s/it]\u001b[A\n",
      " 72%|███████▏  | 72/100 [02:33<00:58,  2.09s/it]\u001b[A\n",
      " 73%|███████▎  | 73/100 [02:35<00:57,  2.11s/it]\u001b[A\n",
      " 74%|███████▍  | 74/100 [02:37<00:55,  2.13s/it]\u001b[A\n",
      " 75%|███████▌  | 75/100 [02:39<00:53,  2.14s/it]\u001b[A\n",
      " 76%|███████▌  | 76/100 [02:41<00:51,  2.14s/it]\u001b[A\n",
      " 77%|███████▋  | 77/100 [02:43<00:49,  2.14s/it]\u001b[A\n",
      " 78%|███████▊  | 78/100 [02:46<00:47,  2.14s/it]\u001b[A\n",
      " 79%|███████▉  | 79/100 [02:48<00:45,  2.14s/it]\u001b[A\n",
      " 80%|████████  | 80/100 [02:50<00:43,  2.16s/it]\u001b[A\n",
      " 81%|████████  | 81/100 [02:52<00:41,  2.16s/it]\u001b[A\n",
      " 82%|████████▏ | 82/100 [02:54<00:39,  2.17s/it]\u001b[A\n",
      " 83%|████████▎ | 83/100 [02:56<00:36,  2.16s/it]\u001b[A\n",
      " 84%|████████▍ | 84/100 [02:59<00:34,  2.17s/it]\u001b[A\n",
      " 85%|████████▌ | 85/100 [03:01<00:32,  2.17s/it]\u001b[A\n",
      " 86%|████████▌ | 86/100 [03:03<00:30,  2.16s/it]\u001b[A\n",
      " 87%|████████▋ | 87/100 [03:05<00:28,  2.21s/it]\u001b[A\n",
      " 88%|████████▊ | 88/100 [03:07<00:26,  2.19s/it]\u001b[A\n",
      " 89%|████████▉ | 89/100 [03:10<00:23,  2.18s/it]\u001b[A\n",
      " 90%|█████████ | 90/100 [03:12<00:21,  2.18s/it]\u001b[A\n",
      " 91%|█████████ | 91/100 [03:14<00:19,  2.17s/it]\u001b[A\n",
      " 92%|█████████▏| 92/100 [03:16<00:17,  2.17s/it]\u001b[A\n",
      " 93%|█████████▎| 93/100 [03:18<00:15,  2.17s/it]\u001b[A\n",
      " 94%|█████████▍| 94/100 [03:20<00:13,  2.18s/it]\u001b[A\n",
      " 95%|█████████▌| 95/100 [03:23<00:10,  2.17s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [03:25<00:08,  2.17s/it]\u001b[A\n",
      " 97%|█████████▋| 97/100 [03:27<00:06,  2.16s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [03:29<00:04,  2.17s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [03:31<00:02,  2.19s/it]\u001b[A\n",
      "100%|██████████| 100/100 [03:33<00:00,  2.14s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 7 of 10\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:02<03:32,  2.15s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:04<03:31,  2.16s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [00:06<03:30,  2.16s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [00:08<03:28,  2.17s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [00:10<03:25,  2.16s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [00:12<03:24,  2.17s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [00:15<03:24,  2.19s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [00:17<03:21,  2.19s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [00:19<03:18,  2.18s/it]\u001b[A\n",
      " 10%|█         | 10/100 [00:21<03:16,  2.18s/it]\u001b[A\n",
      " 11%|█         | 11/100 [00:23<03:13,  2.17s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:26<03:12,  2.19s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:28<03:10,  2.19s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:30<03:07,  2.18s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:32<03:05,  2.18s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:34<03:04,  2.19s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:36<02:50,  2.06s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:38<02:40,  1.95s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:40<02:32,  1.88s/it]\u001b[A\n",
      " 20%|██        | 20/100 [00:41<02:26,  1.83s/it]\u001b[A\n",
      " 21%|██        | 21/100 [00:43<02:21,  1.80s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:45<02:18,  1.77s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [00:46<02:14,  1.75s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:48<02:12,  1.74s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:50<02:10,  1.73s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:52<02:08,  1.73s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:53<02:05,  1.72s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [00:55<02:03,  1.72s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [00:57<02:01,  1.71s/it]\u001b[A\n",
      " 30%|███       | 30/100 [00:58<02:00,  1.71s/it]\u001b[A\n",
      " 31%|███       | 31/100 [01:01<02:08,  1.87s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [01:03<02:13,  1.96s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [01:05<02:15,  2.02s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [01:07<02:16,  2.07s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [01:09<02:16,  2.10s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [01:12<02:15,  2.12s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [01:14<02:14,  2.14s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [01:16<02:13,  2.16s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [01:18<02:12,  2.16s/it]\u001b[A\n",
      " 40%|████      | 40/100 [01:20<02:10,  2.17s/it]\u001b[A\n",
      " 41%|████      | 41/100 [01:22<02:08,  2.17s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [01:25<02:06,  2.17s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [01:27<02:03,  2.17s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [01:29<02:01,  2.17s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [01:31<01:58,  2.16s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [01:33<01:56,  2.16s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [01:35<01:54,  2.16s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [01:38<01:52,  2.16s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [01:40<01:50,  2.16s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [01:42<01:47,  2.16s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [01:44<01:45,  2.16s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [01:46<01:43,  2.15s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [01:48<01:41,  2.16s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [01:50<01:38,  2.15s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [01:53<01:36,  2.15s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [01:55<01:34,  2.15s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [01:57<01:32,  2.15s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [01:59<01:30,  2.15s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [02:01<01:28,  2.16s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [02:03<01:26,  2.16s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [02:06<01:24,  2.17s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [02:08<01:22,  2.17s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [02:10<01:19,  2.16s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [02:12<01:17,  2.16s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [02:14<01:15,  2.16s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [02:16<01:13,  2.16s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [02:19<01:11,  2.16s/it]\u001b[A\n",
      " 68%|██████▊   | 68/100 [02:21<01:08,  2.15s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [02:23<01:08,  2.20s/it]\u001b[A\n",
      " 70%|███████   | 70/100 [02:25<01:05,  2.19s/it]\u001b[A\n",
      " 71%|███████   | 71/100 [02:27<01:03,  2.18s/it]\u001b[A\n",
      " 72%|███████▏  | 72/100 [02:29<00:57,  2.06s/it]\u001b[A\n",
      " 73%|███████▎  | 73/100 [02:31<00:52,  1.96s/it]\u001b[A\n",
      " 74%|███████▍  | 74/100 [02:33<00:49,  1.89s/it]\u001b[A\n",
      " 75%|███████▌  | 75/100 [02:34<00:45,  1.84s/it]\u001b[A\n",
      " 76%|███████▌  | 76/100 [02:36<00:47,  1.96s/it]\u001b[A\n",
      " 77%|███████▋  | 77/100 [02:39<00:46,  2.02s/it]\u001b[A\n",
      " 78%|███████▊  | 78/100 [02:41<00:45,  2.06s/it]\u001b[A\n",
      " 79%|███████▉  | 79/100 [02:43<00:43,  2.08s/it]\u001b[A\n",
      " 80%|████████  | 80/100 [02:45<00:42,  2.10s/it]\u001b[A\n",
      " 81%|████████  | 81/100 [02:47<00:40,  2.12s/it]\u001b[A\n",
      " 82%|████████▏ | 82/100 [02:49<00:38,  2.15s/it]\u001b[A\n",
      " 83%|████████▎ | 83/100 [02:52<00:36,  2.17s/it]\u001b[A\n",
      " 84%|████████▍ | 84/100 [02:54<00:34,  2.17s/it]\u001b[A\n",
      " 85%|████████▌ | 85/100 [02:56<00:32,  2.17s/it]\u001b[A\n",
      " 86%|████████▌ | 86/100 [02:58<00:30,  2.17s/it]\u001b[A\n",
      " 87%|████████▋ | 87/100 [03:00<00:28,  2.17s/it]\u001b[A\n",
      " 88%|████████▊ | 88/100 [03:03<00:26,  2.17s/it]\u001b[A\n",
      " 89%|████████▉ | 89/100 [03:05<00:23,  2.18s/it]\u001b[A\n",
      " 90%|█████████ | 90/100 [03:07<00:22,  2.24s/it]\u001b[A\n",
      " 91%|█████████ | 91/100 [03:09<00:19,  2.22s/it]\u001b[A\n",
      " 92%|█████████▏| 92/100 [03:11<00:17,  2.21s/it]\u001b[A\n",
      " 93%|█████████▎| 93/100 [03:14<00:15,  2.20s/it]\u001b[A\n",
      " 94%|█████████▍| 94/100 [03:16<00:13,  2.19s/it]\u001b[A\n",
      " 95%|█████████▌| 95/100 [03:18<00:10,  2.18s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [03:20<00:08,  2.18s/it]\u001b[A\n",
      " 97%|█████████▋| 97/100 [03:22<00:06,  2.17s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [03:24<00:04,  2.17s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [03:26<00:02,  2.05s/it]\u001b[A\n",
      "100%|██████████| 100/100 [03:28<00:00,  2.08s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 8 of 10\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:01<02:48,  1.70s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:03<02:46,  1.70s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [00:05<03:07,  1.93s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [00:07<02:59,  1.87s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [00:09<03:09,  1.99s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [00:11<02:58,  1.90s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [00:13<02:51,  1.84s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [00:14<02:46,  1.80s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [00:16<02:41,  1.78s/it]\u001b[A\n",
      " 10%|█         | 10/100 [00:18<02:38,  1.76s/it]\u001b[A\n",
      " 11%|█         | 11/100 [00:19<02:35,  1.75s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:21<02:33,  1.74s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:23<02:31,  1.74s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:25<02:41,  1.87s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:27<02:46,  1.96s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:29<02:49,  2.02s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:32<02:51,  2.06s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:34<02:52,  2.10s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:36<02:57,  2.19s/it]\u001b[A\n",
      " 20%|██        | 20/100 [00:38<02:54,  2.18s/it]\u001b[A\n",
      " 21%|██        | 21/100 [00:40<02:52,  2.18s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:43<02:50,  2.18s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [00:45<02:48,  2.19s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:47<02:47,  2.20s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:49<02:44,  2.19s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:51<02:41,  2.19s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:54<02:39,  2.18s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [00:56<02:36,  2.18s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [00:58<02:34,  2.18s/it]\u001b[A\n",
      " 30%|███       | 30/100 [01:00<02:33,  2.19s/it]\u001b[A\n",
      " 31%|███       | 31/100 [01:02<02:31,  2.19s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [01:05<02:28,  2.19s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [01:07<02:26,  2.18s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [01:09<02:24,  2.19s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [01:11<02:22,  2.19s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [01:13<02:19,  2.19s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [01:15<02:17,  2.18s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [01:18<02:14,  2.17s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [01:20<02:12,  2.17s/it]\u001b[A\n",
      " 40%|████      | 40/100 [01:22<02:09,  2.16s/it]\u001b[A\n",
      " 41%|████      | 41/100 [01:24<02:00,  2.03s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [01:25<01:52,  1.94s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [01:27<01:47,  1.88s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [01:29<01:50,  1.97s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [01:31<01:51,  2.03s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [01:34<01:51,  2.06s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [01:36<01:53,  2.15s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [01:38<01:45,  2.03s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [01:39<01:38,  1.93s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [01:41<01:33,  1.87s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [03:18<00:08,  2.14s/it]\u001b[A\n",
      " 97%|█████████▋| 97/100 [03:20<00:06,  2.14s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [03:22<00:04,  2.15s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [03:24<00:02,  2.15s/it]\u001b[A\n",
      "100%|██████████| 100/100 [03:26<00:00,  2.07s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 9 of 10\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:02<03:32,  2.15s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:04<03:30,  2.15s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [00:06<03:28,  2.15s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [00:08<03:26,  2.15s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [00:10<03:11,  2.01s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [00:12<02:59,  1.91s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [00:13<02:51,  1.85s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [00:15<02:45,  1.80s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [00:17<02:41,  1.78s/it]\u001b[A\n",
      " 10%|█         | 10/100 [00:18<02:37,  1.76s/it]\u001b[A\n",
      " 11%|█         | 11/100 [00:21<02:45,  1.86s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:23<02:51,  1.95s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:25<02:55,  2.02s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:27<02:57,  2.06s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:29<02:57,  2.09s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:31<02:57,  2.11s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:34<02:56,  2.13s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:36<02:55,  2.14s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:38<02:57,  2.19s/it]\u001b[A\n",
      " 20%|██        | 20/100 [00:40<02:54,  2.19s/it]\u001b[A\n",
      " 21%|██        | 21/100 [00:42<02:52,  2.18s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:45<02:50,  2.19s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [00:47<02:49,  2.20s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:49<02:46,  2.19s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:51<02:44,  2.19s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:53<02:41,  2.18s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:55<02:39,  2.18s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [00:58<02:39,  2.22s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [01:00<02:36,  2.20s/it]\u001b[A\n",
      " 30%|███       | 30/100 [01:02<02:36,  2.24s/it]\u001b[A\n",
      " 31%|███       | 31/100 [01:04<02:32,  2.21s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [01:07<02:32,  2.24s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [01:09<02:28,  2.22s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [01:11<02:17,  2.08s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [01:12<02:07,  1.97s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [01:14<02:00,  1.89s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [01:16<01:55,  1.84s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [01:18<02:02,  1.97s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [01:20<02:08,  2.11s/it]\u001b[A\n",
      " 40%|████      | 40/100 [01:23<02:07,  2.13s/it]\u001b[A\n",
      " 41%|████      | 41/100 [01:25<02:06,  2.14s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [01:27<02:07,  2.20s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [01:29<02:05,  2.20s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [01:32<02:02,  2.19s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [01:34<02:00,  2.19s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [01:36<02:00,  2.23s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [01:38<01:57,  2.22s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [01:40<01:54,  2.21s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [01:43<01:52,  2.20s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [01:45<01:49,  2.19s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [01:47<01:46,  2.18s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [01:49<01:44,  2.18s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [01:51<01:43,  2.20s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [01:53<01:40,  2.18s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [01:56<01:37,  2.17s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [01:58<01:35,  2.17s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [02:00<01:33,  2.17s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [02:02<01:30,  2.16s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [02:04<01:28,  2.16s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [02:06<01:26,  2.16s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [02:09<01:23,  2.15s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [02:11<01:21,  2.15s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [02:13<01:19,  2.15s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [02:15<01:17,  2.15s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [02:17<01:15,  2.17s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [02:19<01:13,  2.16s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [02:21<01:07,  2.04s/it]\u001b[A\n",
      " 68%|██████▊   | 68/100 [02:23<01:02,  1.95s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [02:25<00:58,  1.88s/it]\u001b[A\n",
      " 70%|███████   | 70/100 [02:26<00:54,  1.83s/it]\u001b[A\n",
      " 71%|███████   | 71/100 [02:28<00:56,  1.94s/it]\u001b[A\n",
      " 72%|███████▏  | 72/100 [02:31<00:56,  2.01s/it]\u001b[A\n",
      " 73%|███████▎  | 73/100 [02:33<00:55,  2.05s/it]\u001b[A\n",
      " 74%|███████▍  | 74/100 [02:35<00:54,  2.08s/it]\u001b[A\n",
      " 75%|███████▌  | 75/100 [02:37<00:52,  2.10s/it]\u001b[A\n",
      " 76%|███████▌  | 76/100 [02:39<00:50,  2.12s/it]\u001b[A\n",
      " 77%|███████▋  | 77/100 [02:41<00:49,  2.14s/it]\u001b[A\n",
      " 78%|███████▊  | 78/100 [02:44<00:47,  2.15s/it]\u001b[A\n",
      " 79%|███████▉  | 79/100 [02:46<00:45,  2.16s/it]\u001b[A\n",
      " 80%|████████  | 80/100 [02:48<00:43,  2.16s/it]\u001b[A\n",
      " 81%|████████  | 81/100 [02:50<00:41,  2.17s/it]\u001b[A\n",
      " 82%|████████▏ | 82/100 [02:52<00:38,  2.16s/it]\u001b[A\n",
      " 83%|████████▎ | 83/100 [02:54<00:36,  2.16s/it]\u001b[A\n",
      " 84%|████████▍ | 84/100 [02:57<00:34,  2.16s/it]\u001b[A\n",
      " 85%|████████▌ | 85/100 [02:59<00:32,  2.16s/it]\u001b[A\n",
      " 86%|████████▌ | 86/100 [03:01<00:30,  2.16s/it]\u001b[A\n",
      " 87%|████████▋ | 87/100 [03:03<00:28,  2.16s/it]\u001b[A\n",
      " 88%|████████▊ | 88/100 [03:05<00:25,  2.16s/it]\u001b[A\n",
      " 89%|████████▉ | 89/100 [03:07<00:23,  2.15s/it]\u001b[A\n",
      " 90%|█████████ | 90/100 [03:10<00:21,  2.15s/it]\u001b[A\n",
      " 91%|█████████ | 91/100 [03:12<00:19,  2.18s/it]\u001b[A\n",
      " 92%|█████████▏| 92/100 [03:14<00:17,  2.17s/it]\u001b[A\n",
      " 93%|█████████▎| 93/100 [03:16<00:15,  2.17s/it]\u001b[A\n",
      " 94%|█████████▍| 94/100 [03:18<00:12,  2.16s/it]\u001b[A\n",
      " 95%|█████████▌| 95/100 [03:20<00:10,  2.16s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [03:23<00:08,  2.16s/it]\u001b[A\n",
      " 97%|█████████▋| 97/100 [03:25<00:06,  2.15s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [03:27<00:04,  2.20s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [03:29<00:02,  2.19s/it]\u001b[A\n",
      "100%|██████████| 100/100 [03:31<00:00,  2.12s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 10 of 10\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:02<03:40,  2.23s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:04<03:34,  2.19s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [00:06<03:31,  2.18s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [00:08<03:28,  2.18s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [00:10<03:26,  2.17s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [00:13<03:24,  2.18s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [00:15<03:22,  2.18s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [00:17<03:20,  2.18s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [00:19<03:17,  2.17s/it]\u001b[A\n",
      " 10%|█         | 10/100 [00:21<03:17,  2.20s/it]\u001b[A\n",
      " 11%|█         | 11/100 [00:24<03:14,  2.19s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:26<03:11,  2.18s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:28<03:08,  2.16s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:30<03:05,  2.16s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:32<03:03,  2.16s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:34<03:01,  2.16s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:36<02:59,  2.16s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:39<02:56,  2.16s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:41<02:54,  2.16s/it]\u001b[A\n",
      " 20%|██        | 20/100 [00:43<02:52,  2.16s/it]\u001b[A\n",
      " 21%|██        | 21/100 [00:45<02:50,  2.16s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:47<02:48,  2.17s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [00:50<02:50,  2.21s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:52<02:48,  2.21s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:54<02:44,  2.19s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:56<02:41,  2.18s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:58<02:38,  2.17s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [01:00<02:36,  2.17s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [01:03<02:33,  2.16s/it]\u001b[A\n",
      " 30%|███       | 30/100 [01:05<02:31,  2.16s/it]\u001b[A\n",
      " 31%|███       | 31/100 [01:06<02:20,  2.04s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [01:08<02:12,  1.95s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [01:10<02:05,  1.87s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [01:12<02:00,  1.83s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [01:13<01:56,  1.79s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [01:15<01:53,  1.77s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [01:17<01:50,  1.76s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [01:18<01:48,  1.75s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [01:20<01:45,  1.74s/it]\u001b[A\n",
      " 40%|████      | 40/100 [01:22<01:51,  1.85s/it]\u001b[A\n",
      " 41%|████      | 41/100 [01:24<01:54,  1.95s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [01:27<01:57,  2.02s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [01:29<01:58,  2.08s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [01:31<01:58,  2.11s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [01:33<01:58,  2.15s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [01:36<01:57,  2.17s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [01:38<01:54,  2.17s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [01:39<01:46,  2.04s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [01:41<01:38,  1.94s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [01:43<01:42,  2.05s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [01:46<01:41,  2.08s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [01:48<01:40,  2.10s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [01:50<01:39,  2.12s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [01:52<01:37,  2.13s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [01:54<01:36,  2.14s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [01:56<01:34,  2.16s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [01:59<01:33,  2.17s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [02:01<01:30,  2.16s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [02:03<01:28,  2.16s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [02:05<01:26,  2.16s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [02:07<01:24,  2.16s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [02:09<01:22,  2.17s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [02:12<01:20,  2.16s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [02:14<01:18,  2.17s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [02:16<01:16,  2.17s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [02:18<01:13,  2.18s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [02:20<01:11,  2.17s/it]\u001b[A\n",
      " 68%|██████▊   | 68/100 [02:22<01:09,  2.17s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [02:25<01:07,  2.17s/it]\u001b[A\n",
      " 70%|███████   | 70/100 [02:27<01:06,  2.23s/it]\u001b[A\n",
      " 71%|███████   | 71/100 [02:29<01:04,  2.21s/it]\u001b[A\n",
      " 72%|███████▏  | 72/100 [02:31<01:01,  2.20s/it]\u001b[A\n",
      " 73%|███████▎  | 73/100 [02:34<01:00,  2.23s/it]\u001b[A\n",
      " 74%|███████▍  | 74/100 [02:36<00:57,  2.21s/it]\u001b[A\n",
      " 75%|███████▌  | 75/100 [02:38<00:54,  2.19s/it]\u001b[A\n",
      " 76%|███████▌  | 76/100 [02:40<00:52,  2.19s/it]\u001b[A\n",
      " 77%|███████▋  | 77/100 [02:42<00:50,  2.18s/it]\u001b[A\n",
      " 78%|███████▊  | 78/100 [02:44<00:47,  2.17s/it]\u001b[A\n",
      " 79%|███████▉  | 79/100 [02:47<00:45,  2.17s/it]\u001b[A\n",
      " 80%|████████  | 80/100 [02:49<00:43,  2.17s/it]\u001b[A\n",
      " 81%|████████  | 81/100 [02:51<00:41,  2.16s/it]\u001b[A\n",
      " 82%|████████▏ | 82/100 [02:53<00:38,  2.16s/it]\u001b[A\n",
      " 83%|████████▎ | 83/100 [02:55<00:36,  2.15s/it]\u001b[A\n",
      " 84%|████████▍ | 84/100 [02:57<00:34,  2.15s/it]\u001b[A\n",
      " 85%|████████▌ | 85/100 [03:00<00:32,  2.16s/it]\u001b[A\n",
      " 86%|████████▌ | 86/100 [03:02<00:30,  2.16s/it]\u001b[A\n",
      " 87%|████████▋ | 87/100 [03:04<00:28,  2.16s/it]\u001b[A\n",
      " 88%|████████▊ | 88/100 [03:06<00:26,  2.17s/it]\u001b[A\n",
      " 89%|████████▉ | 89/100 [03:08<00:23,  2.17s/it]\u001b[A\n",
      " 90%|█████████ | 90/100 [03:10<00:21,  2.16s/it]\u001b[A\n",
      " 91%|█████████ | 91/100 [03:13<00:19,  2.16s/it]\u001b[A\n",
      " 92%|█████████▏| 92/100 [03:15<00:17,  2.15s/it]\u001b[A\n",
      " 93%|█████████▎| 93/100 [03:17<00:15,  2.15s/it]\u001b[A\n",
      " 94%|█████████▍| 94/100 [03:19<00:12,  2.15s/it]\u001b[A\n",
      " 95%|█████████▌| 95/100 [03:21<00:10,  2.15s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [03:23<00:08,  2.14s/it]\u001b[A\n",
      " 97%|█████████▋| 97/100 [03:25<00:06,  2.14s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [03:28<00:04,  2.14s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [03:30<00:02,  2.15s/it]\u001b[A\n",
      "100%|██████████| 100/100 [03:32<00:00,  2.12s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "epochs = 100#hp_best_params['epochs']\n",
    "masks_no = 100#hp_best_params['masks_no']\n",
    "mask_size = 4#hp_best_params['mask_size']\n",
    "target_size = 10#hp_best_params['target_size']\n",
    "data_size = max_size\n",
    "batch_size = 32#hp_best_params['batch_size']\n",
    "lr = hp_best_params['lr']\n",
    "\n",
    "\n",
    "hyper_results = test_model(network_hp_fn(epochs, masks_no, mask_size, target_size, batch_size=batch_size,verbose=True),\n",
    "                    (X, y),\n",
    "                    data_size,\n",
    "                    None, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dd097d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_966419/3655004452.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  hyper_results[hyper_results[\"Class\"]==\"balanced_accuracy\"].mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Metric    82.068452\n",
       "dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_results[hyper_results[\"Class\"]==\"balanced_accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b2129c6b-2c65-458e-b175-51aaf313fa42",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hyper_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [134]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mhyper_results\u001b[49m[hyper_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetric\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ~ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres\u001b[38;5;241m.\u001b[39mstd()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, (max: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hyper_results' is not defined"
     ]
    }
   ],
   "source": [
    "res = hyper_results[hyper_results[\"Class\"]==\"balanced_accuracy\"].reset_index(drop=True)[\"Metric\"]\n",
    "print(f\"{data_size}: {res.mean():.2f} ~ {res.std():.2f}, (max: {res.max():.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdb5810-96c6-4010-af1e-a59b0b9f6b65",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6758728e-d6c8-4d23-9aa7-ba7998704411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6da01b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rf(**params):\n",
    "    random_seed = np.random.randint(1024)\n",
    "    def _inner():\n",
    "        return RandomForestClassifier(\n",
    "            random_state=random_seed,\n",
    "            **params\n",
    "        )\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73ccafa",
   "metadata": {},
   "source": [
    "#### Find hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8dc080fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 10:29:48.254 | INFO     | __main__:pyhopper_best_params:7 - pyhopper_best_params get_rf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c9abed1006489783f18b5909adfdc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search is scheduled for 45:00 (m:s)\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 1 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 5\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "==================== Summary ===================\n",
      "Mode              : Best f : Steps : Time       \n",
      "----------------  : ----   : ----  : ----       \n",
      "Initial solution  : 68.66  : 1     : 2.20 s     \n",
      "Random seeding    : 71.01  : 71    : 23:30 (m:s)\n",
      "Local sampling    : 70.85  : 41    : 21:04 (m:s)\n",
      "Duplicates        : -      : 38    : -          \n",
      "----------------  : ----   : ----  : ----       \n",
      "Total             : 71.01  : 151   : 44:36 (m:s)\n",
      "================================================\n",
      "Blastchar_get_rf_{'n_estimators': 1750, 'max_features': None, 'criterion': 'entropy', 'max_depth': 8}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1750,\n",
       " 'max_features': None,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': 8}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "                'n_estimators': pyhopper.choice([50, 100, 200, 500, 1000, 1750, 3000]),\n",
    "                'max_features': pyhopper.choice([None, 'sqrt', 0.2, 0.3, 0.5, 0.7]),\n",
    "                'criterion' : pyhopper.choice(['gini', 'entropy']),\n",
    "                'max_depth': pyhopper.choice([None, 2, 4, 8, 16]),\n",
    "             }\n",
    "\n",
    "rf_best, rf_history = pyhopper_best_params(get_rf, param_grid, time=\"45m\")\n",
    "rf_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf8eaa2",
   "metadata": {},
   "source": [
    "#### Use best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3325fd3b-8a85-46eb-896c-46bf8d768a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 of 10\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 2 of 10\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 3 of 10\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 4 of 10\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 5 of 10\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 6 of 10\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 7 of 10\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 8 of 10\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 9 of 10\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n",
      "iter 10 of 10\n",
      "X_train_size torch.Size([3000, 19])\n",
      "y_train_size torch.Size([3000])\n"
     ]
    }
   ],
   "source": [
    "size = max_size\n",
    "\n",
    "rf_dframe = test_model(get_rf(**rf_best), \n",
    "                        (X, y),\n",
    "                        size,\n",
    "                        None, iters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4420cbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1240345/2964448691.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  rf_dframe[rf_dframe[\"Class\"]==\"balanced_accuracy\"].mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Metric    70.351351\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_dframe[rf_dframe[\"Class\"]==\"balanced_accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a543f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000: 70.35 ~ 0.61, (max: 71.20)\n"
     ]
    }
   ],
   "source": [
    "res = rf_dframe[rf_dframe[\"Class\"]==\"balanced_accuracy\"].reset_index(drop=True)[\"Metric\"]\n",
    "print(f\"{3000}: {res.mean():.2f} ~ {res.std():.2f}, (max: {res.max():.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa987cfe",
   "metadata": {},
   "source": [
    "# Collect analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6ffd69a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6c53193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['Random forest'] = rf_dframe.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['Hypernet'] = hyper_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['HypernetPCA'] = nn_pca_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['Dropout_1'] = nn1_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['Dropout_2'] = nn2_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['Dropout_3'] = nn3_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['Node'] = node_results.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])\n",
    "d['XGBoost'] = xgb_dframe.groupby(\"Class\")['Metric'].agg(['mean', 'std', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7f523ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Random forest</th>\n",
       "      <th>0</th>\n",
       "      <td>97.777778</td>\n",
       "      <td>2.868877</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93.055556</td>\n",
       "      <td>3.982558</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>3.657114</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.722222</td>\n",
       "      <td>4.192308</td>\n",
       "      <td>88.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">XGBoost</th>\n",
       "      <th>6</th>\n",
       "      <td>91.388889</td>\n",
       "      <td>4.233011</td>\n",
       "      <td>97.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>96.666667</td>\n",
       "      <td>3.414646</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>77.777778</td>\n",
       "      <td>7.407407</td>\n",
       "      <td>91.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>90.493827</td>\n",
       "      <td>2.051431</td>\n",
       "      <td>94.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>90.493827</td>\n",
       "      <td>2.051431</td>\n",
       "      <td>94.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       mean       std         max\n",
       "              Class                                              \n",
       "Random forest 0                   97.777778  2.868877  100.000000\n",
       "              1                   93.055556  3.982558  100.000000\n",
       "              2                   95.000000  3.657114  100.000000\n",
       "              3                   84.722222  4.192308   88.888889\n",
       "              4                  100.000000  0.000000  100.000000\n",
       "...                                     ...       ...         ...\n",
       "XGBoost       6                   91.388889  4.233011   97.222222\n",
       "              7                   96.666667  3.414646  100.000000\n",
       "              8                   77.777778  7.407407   91.666667\n",
       "              Total               90.493827  2.051431   94.444444\n",
       "              balanced_accuracy   90.493827  2.051431   94.444444\n",
       "\n",
       "[88 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models_df=pd.concat(d, axis=0)\n",
    "all_models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aac13dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f8b898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "60823a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UXrV5UxyhTK3cyQNG6BDuc4bE'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['COMET_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1f9da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "80d25d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_df.to_csv(f\"{DATA}_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0654fd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/abulenok/hypernet-uci-tune/cd3d48b8f7b048d1934b06562ea42da7\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     copy                       : True\n",
      "COMET INFO:     iterated_power             : auto\n",
      "COMET INFO:     n_components               : 3\n",
      "COMET INFO:     n_oversamples              : 10\n",
      "COMET INFO:     power_iteration_normalizer : auto\n",
      "COMET INFO:     random_state               : 1\n",
      "COMET INFO:     svd_solver                 : auto\n",
      "COMET INFO:     tol                        : 0.0\n",
      "COMET INFO:     whiten                     : False\n",
      "COMET INFO:     with_mean                  : True\n",
      "COMET INFO:     with_std                   : True\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     asset                    : 1 (5.09 KB)\n",
      "COMET INFO:     conda-info               : 1\n",
      "COMET INFO:     conda-specification      : 1\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (5.21 MB)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO:     source_code              : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.com/abulenok/hypernet-uci-tune/4de718e831d54a9a9d63fd69a09f30c0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'web': 'https://www.comet.com/api/asset/download?assetId=96b7c9337313423fafa70e413639f6d6&experimentKey=4de718e831d54a9a9d63fd69a09f30c0',\n",
       " 'api': 'https://www.comet.com/api/rest/v2/experiment/asset/get-asset?assetId=96b7c9337313423fafa70e413639f6d6&experimentKey=4de718e831d54a9a9d63fd69a09f30c0',\n",
       " 'assetId': '96b7c9337313423fafa70e413639f6d6'}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = Experiment(os.environ.get(\"COMET_KEY\"), 'hypernet-uci-tune')\n",
    "# exp.log_parameters({\"epochs\": epochs, \"mask_size\": mask_size, \"masks_no\": masks_no, \"data_size\": data_size})\n",
    "exp.add_tag(f\"hypernet-tune2{DATA}\")\n",
    "exp.log_table(f\"{DATA}_metrics.csv\", all_models_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce733782",
   "metadata": {},
   "source": [
    "### Replace some data in existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a0a197e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_df = pd.concat(d, axis=0)\n",
    "# tmp_df = tmp_df.reset_index()\n",
    "# tmp_df = tmp_df.rename(columns={tmp_df.columns[0]: DATA})\n",
    "\n",
    "# tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8fdbf166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_models_df = pd.read_csv(f\"{DATA}_metrics.csv\")\n",
    "# all_models_df = all_models_df.rename(columns={all_models_df.columns[0]: DATA})\n",
    "# all_models_df = all_models_df.drop(all_models_df[all_models_df.iloc[:, 0] == 'Hypernet'].index)\n",
    "# all_models_df = all_models_df.drop(all_models_df[all_models_df.iloc[:, 0] == 'HypernetPCA'].index)\n",
    "\n",
    "# all_models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d2cc3246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_models_df = pd.concat([all_models_df, tmp_df])\n",
    "# all_models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff93119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5ebc5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e6b6d6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cnae_metrics.csv'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{DATA}_metrics.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9a061329",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_df = pd.read_csv(f\"{DATA}_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e2fb29bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Class</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Random forest</td>\n",
       "      <td>0</td>\n",
       "      <td>97.777778</td>\n",
       "      <td>2.868877</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Random forest</td>\n",
       "      <td>1</td>\n",
       "      <td>93.055556</td>\n",
       "      <td>3.982558</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Random forest</td>\n",
       "      <td>2</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>3.657114</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Random forest</td>\n",
       "      <td>3</td>\n",
       "      <td>84.722222</td>\n",
       "      <td>4.192308</td>\n",
       "      <td>88.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Random forest</td>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>6</td>\n",
       "      <td>91.388889</td>\n",
       "      <td>4.233011</td>\n",
       "      <td>97.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>7</td>\n",
       "      <td>96.666667</td>\n",
       "      <td>3.414646</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>8</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>7.407407</td>\n",
       "      <td>91.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Total</td>\n",
       "      <td>90.493827</td>\n",
       "      <td>2.051431</td>\n",
       "      <td>94.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>87</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>90.493827</td>\n",
       "      <td>2.051431</td>\n",
       "      <td>94.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index     Unnamed: 0              Class        mean       std         max\n",
       "0       0  Random forest                  0   97.777778  2.868877  100.000000\n",
       "1       1  Random forest                  1   93.055556  3.982558  100.000000\n",
       "2       2  Random forest                  2   95.000000  3.657114  100.000000\n",
       "3       3  Random forest                  3   84.722222  4.192308   88.888889\n",
       "4       4  Random forest                  4  100.000000  0.000000  100.000000\n",
       "..    ...            ...                ...         ...       ...         ...\n",
       "83     83        XGBoost                  6   91.388889  4.233011   97.222222\n",
       "84     84        XGBoost                  7   96.666667  3.414646  100.000000\n",
       "85     85        XGBoost                  8   77.777778  7.407407   91.666667\n",
       "86     86        XGBoost              Total   90.493827  2.051431   94.444444\n",
       "87     87        XGBoost  balanced_accuracy   90.493827  2.051431   94.444444\n",
       "\n",
       "[88 rows x 6 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63595ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcccc753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1bf024fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_models_df = all_models_df.drop(all_models_df.columns[0], axis=1)\n",
    "# all_models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca3f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398b55e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c69f547c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Class</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>91.851852</td>\n",
       "      <td>1.358648</td>\n",
       "      <td>94.135802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Hypernet</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>92.253086</td>\n",
       "      <td>2.551150</td>\n",
       "      <td>95.370370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>HypernetPCA</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>94.969136</td>\n",
       "      <td>0.965654</td>\n",
       "      <td>96.604938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Dropout_1</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>94.537037</td>\n",
       "      <td>1.029321</td>\n",
       "      <td>95.987654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Dropout_2</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>94.012346</td>\n",
       "      <td>0.685528</td>\n",
       "      <td>95.370370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Dropout_3</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>94.969136</td>\n",
       "      <td>0.770575</td>\n",
       "      <td>96.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Node</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>94.722222</td>\n",
       "      <td>1.168047</td>\n",
       "      <td>97.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>90.493827</td>\n",
       "      <td>2.051431</td>\n",
       "      <td>94.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0              Class       mean       std        max\n",
       "10  Random forest  balanced_accuracy  91.851852  1.358648  94.135802\n",
       "21       Hypernet  balanced_accuracy  92.253086  2.551150  95.370370\n",
       "32    HypernetPCA  balanced_accuracy  94.969136  0.965654  96.604938\n",
       "43      Dropout_1  balanced_accuracy  94.537037  1.029321  95.987654\n",
       "54      Dropout_2  balanced_accuracy  94.012346  0.685528  95.370370\n",
       "65      Dropout_3  balanced_accuracy  94.969136  0.770575  96.296296\n",
       "76           Node  balanced_accuracy  94.722222  1.168047  97.222222\n",
       "87        XGBoost  balanced_accuracy  90.493827  2.051431  94.444444"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models_df[all_models_df['Class'] == 'balanced_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7beddf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = all_models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1996040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp.rename(columns={tmp.columns[0]: DATA})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "36d69505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnae</th>\n",
       "      <th>Class</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>0</td>\n",
       "      <td>97.777778</td>\n",
       "      <td>2.868877</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>1</td>\n",
       "      <td>93.055556</td>\n",
       "      <td>3.982558</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>2</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>3.657114</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>3</td>\n",
       "      <td>84.722222</td>\n",
       "      <td>4.192308</td>\n",
       "      <td>88.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>6</td>\n",
       "      <td>91.388889</td>\n",
       "      <td>4.233011</td>\n",
       "      <td>97.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>7</td>\n",
       "      <td>96.666667</td>\n",
       "      <td>3.414646</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>8</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>7.407407</td>\n",
       "      <td>91.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Total</td>\n",
       "      <td>90.493827</td>\n",
       "      <td>2.051431</td>\n",
       "      <td>94.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>90.493827</td>\n",
       "      <td>2.051431</td>\n",
       "      <td>94.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             cnae              Class        mean       std         max\n",
       "0   Random forest                  0   97.777778  2.868877  100.000000\n",
       "1   Random forest                  1   93.055556  3.982558  100.000000\n",
       "2   Random forest                  2   95.000000  3.657114  100.000000\n",
       "3   Random forest                  3   84.722222  4.192308   88.888889\n",
       "4   Random forest                  4  100.000000  0.000000  100.000000\n",
       "..            ...                ...         ...       ...         ...\n",
       "83        XGBoost                  6   91.388889  4.233011   97.222222\n",
       "84        XGBoost                  7   96.666667  3.414646  100.000000\n",
       "85        XGBoost                  8   77.777778  7.407407   91.666667\n",
       "86        XGBoost              Total   90.493827  2.051431   94.444444\n",
       "87        XGBoost  balanced_accuracy   90.493827  2.051431   94.444444\n",
       "\n",
       "[88 rows x 5 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b9ee21a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnae</th>\n",
       "      <th>Class</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>91.851852</td>\n",
       "      <td>1.358648</td>\n",
       "      <td>94.135802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Hypernet</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>92.253086</td>\n",
       "      <td>2.551150</td>\n",
       "      <td>95.370370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>HypernetPCA</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>94.969136</td>\n",
       "      <td>0.965654</td>\n",
       "      <td>96.604938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Dropout_1</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>94.537037</td>\n",
       "      <td>1.029321</td>\n",
       "      <td>95.987654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Dropout_2</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>94.012346</td>\n",
       "      <td>0.685528</td>\n",
       "      <td>95.370370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Dropout_3</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>94.969136</td>\n",
       "      <td>0.770575</td>\n",
       "      <td>96.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Node</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>94.722222</td>\n",
       "      <td>1.168047</td>\n",
       "      <td>97.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>90.493827</td>\n",
       "      <td>2.051431</td>\n",
       "      <td>94.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cnae              Class       mean       std        max\n",
       "10  Random forest  balanced_accuracy  91.851852  1.358648  94.135802\n",
       "21       Hypernet  balanced_accuracy  92.253086  2.551150  95.370370\n",
       "32    HypernetPCA  balanced_accuracy  94.969136  0.965654  96.604938\n",
       "43      Dropout_1  balanced_accuracy  94.537037  1.029321  95.987654\n",
       "54      Dropout_2  balanced_accuracy  94.012346  0.685528  95.370370\n",
       "65      Dropout_3  balanced_accuracy  94.969136  0.770575  96.296296\n",
       "76           Node  balanced_accuracy  94.722222  1.168047  97.222222\n",
       "87        XGBoost  balanced_accuracy  90.493827  2.051431  94.444444"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[tmp['Class'] == \"balanced_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49403f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db453527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/hypernet\n"
     ]
    }
   ],
   "source": [
    "%cd hypernet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ef57058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3439415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment, Optimizer\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f81b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "411db77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabular_hypernet as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfbc97da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tabular_hypernet.training_utils.get_dataset(size=60000, masked=False, mask_no=200, mask_size=700, shared_mask=False, batch_size=32, test_batch_size=32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp.training_utils.get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fd81c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['COMET_KEY'] = 'UXrV5UxyhTK3cyQNG6BDuc4bE'\n",
    "os.environ.get(\"COMET_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "884b2bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tabular_hypernet.semisl.get_dataset(size=(100, 900), masked=False, mask_no=200, mask_size=700, shared_mask=False, batch_size=32, test_batch_size=32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp.semisl.get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fd4cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fc4dc449",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabSSLCrossEntropyLoss(torch.nn.Module):\n",
    "    def __init__(self, beta=0.1, unsup_target_wrapper=torch.nn.functional.softmax, threshold=None):\n",
    "        super(TabSSLCrossEntropyLoss, self).__init__()\n",
    "        \n",
    "        self.y_f1 = torch.nn.CrossEntropyLoss()\n",
    "        self.y_f2 = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.f1_f2 = torch.nn.CrossEntropyLoss()\n",
    "        self.f2_f1 = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.beta = beta\n",
    "        self.unsup_target_wrapper = unsup_target_wrapper\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def forward(self, sup_input, unsup_input):\n",
    "        sup_outputs1, sup_outputs2, sup_labels = sup_input\n",
    "        unsup_outputs1, unsup_outputs2 = unsup_input\n",
    "        \n",
    "        self.supervised_loss = self.y_f1(sup_outputs1, sup_labels) + self.y_f2(sup_outputs2, sup_labels)\n",
    "        \n",
    "        self.self_supervised_loss = 0\n",
    "        if self.threshold:\n",
    "            unsup_outputs1_target = torch.nn.functional.softmax(unsup_outputs1, dim=1)\n",
    "            mask1 = unsup_outputs1_target >= self.threshold\n",
    "            \n",
    "            if len(unsup_outputs1_target[mask1]):\n",
    "                print(unsup_outputs1_target[mask1], flush=True)\n",
    "                unsup_outputs1_target = torch.argmax(unsup_outputs1_target[mask1], dim=1)\n",
    "                self.self_supervised_loss += self.f1_f2(unsup_outputs1[mask2], unsup_outputs2_target)\n",
    "            \n",
    "            unsup_outputs2_target = torch.nn.functional.softmax(unsup_outputs2, dim=1)\n",
    "            mask2 = unsup_outputs2_target >= self.threshold\n",
    "            \n",
    "            if len(unsup_outputs2_target[mask2]):\n",
    "                print(unsup_outputs2_target, flush=True)\n",
    "                print(unsup_outputs2_target[mask2], flush=True)\n",
    "                unsup_outputs2_target = torch.argmax(unsup_outputs2_target[mask2], dim=1)\n",
    "                self.self_supervised_loss += self.f2_f1(unsup_outputs2[mask1], unsup_outputs1_target)\n",
    "        \n",
    "        else:\n",
    "            self.self_supervised_loss = self.f1_f2(unsup_outputs1, self.unsup_target_wrapper(unsup_outputs2, dim=1)) \\\n",
    "                                + self.f2_f1(unsup_outputs2, self.unsup_target_wrapper(unsup_outputs1, dim=1))\n",
    "        \n",
    "        return self.supervised_loss + self.beta * self.self_supervised_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6375b520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2e0ce774",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[0.1, 0.5, -1.0], [0, 1.2, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "36f067a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.requires_grad  = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c3b7d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c938eefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1000,  0.5000, -1.0000],\n",
       "        [ 0.0000,  1.2000,  0.0000]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "06dd095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = X >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8fbeae2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True, False],\n",
       "        [ True,  True,  True]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ca08c410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 2]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = torch.nonzero(mask)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "da023c50",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [72]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for dimension 0 with size 2"
     ]
    }
   ],
   "source": [
    "X[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f920da50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.5000, 0.0000, 1.2000, 0.0000], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff23bd40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0ce322f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "\n",
    "mask_size = 100\n",
    "masks_no = 50\n",
    "\n",
    "results = defaultdict(list)\n",
    "size = (100, 59900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "68697821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                 | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.9393e-02, 2.0805e-02, 4.5298e-02, 1.0215e-01, 1.9716e-02, 1.8063e-02,\n",
      "         3.9598e-03, 1.8617e-01, 2.6066e-01, 2.8379e-01],\n",
      "        [3.8201e-01, 3.5600e-02, 2.4759e-01, 1.0786e-01, 8.6828e-03, 1.5643e-02,\n",
      "         3.0427e-02, 3.1044e-02, 6.4663e-02, 7.6485e-02],\n",
      "        [4.2504e-02, 5.4533e-01, 7.8627e-02, 4.5605e-02, 3.5453e-02, 3.5441e-02,\n",
      "         4.5520e-02, 5.1149e-02, 2.8660e-02, 9.1711e-02],\n",
      "        [5.0133e-02, 1.4162e-01, 6.4472e-02, 6.6837e-02, 2.2700e-01, 2.1753e-02,\n",
      "         1.0158e-01, 1.2453e-01, 4.4120e-02, 1.5795e-01],\n",
      "        [3.2829e-01, 1.3319e-03, 7.7331e-02, 7.4591e-02, 3.9633e-02, 3.0193e-03,\n",
      "         1.4170e-02, 5.5594e-02, 3.0310e-01, 1.0294e-01],\n",
      "        [3.8658e-02, 1.8514e-04, 9.1598e-01, 1.5943e-02, 9.7450e-04, 4.4046e-04,\n",
      "         1.1793e-02, 2.3683e-04, 1.4591e-02, 1.2034e-03],\n",
      "        [2.3874e-01, 4.8199e-02, 8.5324e-02, 2.7520e-01, 2.1499e-02, 5.9305e-03,\n",
      "         8.3476e-03, 7.8078e-02, 7.2637e-02, 1.6605e-01],\n",
      "        [6.4741e-02, 4.5717e-01, 4.9313e-02, 7.2191e-02, 3.6866e-02, 6.1392e-02,\n",
      "         4.0624e-02, 7.8150e-02, 3.9068e-02, 1.0049e-01],\n",
      "        [1.2589e-01, 1.2745e-02, 1.4553e-01, 2.2591e-01, 1.8080e-02, 4.0193e-03,\n",
      "         4.0554e-03, 8.8470e-03, 2.4752e-01, 2.0740e-01],\n",
      "        [5.5919e-02, 1.6083e-01, 5.7923e-02, 9.7219e-02, 1.7403e-01, 1.2894e-02,\n",
      "         1.4309e-01, 3.5269e-02, 9.5452e-02, 1.6737e-01],\n",
      "        [1.4543e-01, 3.1170e-02, 4.4968e-01, 3.5611e-02, 8.2298e-03, 1.5950e-02,\n",
      "         1.7618e-01, 1.0298e-02, 7.9911e-02, 4.7542e-02],\n",
      "        [4.2814e-02, 3.5289e-01, 9.6383e-02, 8.3640e-02, 5.4642e-02, 5.0575e-02,\n",
      "         8.8832e-02, 5.6640e-02, 5.2573e-02, 1.2101e-01],\n",
      "        [2.1840e-01, 1.3409e-01, 1.0888e-01, 1.4301e-01, 2.3288e-02, 2.5644e-02,\n",
      "         1.9622e-02, 7.5115e-02, 7.0395e-02, 1.8155e-01],\n",
      "        [2.6983e-01, 2.1359e-02, 4.2879e-02, 1.6121e-01, 1.4031e-02, 9.2035e-03,\n",
      "         7.1270e-03, 9.3594e-02, 1.8706e-01, 1.9371e-01],\n",
      "        [3.9538e-02, 2.4113e-01, 4.0109e-02, 5.9356e-02, 9.5170e-02, 2.7224e-02,\n",
      "         3.0377e-02, 9.5195e-02, 1.6620e-01, 2.0570e-01],\n",
      "        [2.1879e-01, 2.7326e-03, 4.8757e-01, 3.9128e-02, 1.3007e-02, 3.3433e-03,\n",
      "         1.5260e-01, 3.0944e-03, 5.3837e-02, 2.5899e-02],\n",
      "        [4.0247e-02, 1.1283e-02, 3.7270e-02, 1.2659e-01, 3.3741e-01, 2.6511e-03,\n",
      "         1.5937e-01, 2.9344e-02, 2.6708e-02, 2.2912e-01],\n",
      "        [1.2587e-01, 7.3703e-02, 6.3705e-02, 6.5135e-02, 1.2184e-02, 3.6464e-02,\n",
      "         3.6902e-03, 2.6657e-01, 1.5484e-01, 1.9784e-01],\n",
      "        [2.8577e-01, 2.8161e-02, 1.0589e-01, 3.0713e-01, 3.3362e-02, 5.6097e-03,\n",
      "         1.4300e-02, 3.6997e-02, 7.5312e-02, 1.0747e-01],\n",
      "        [1.6214e-01, 2.1187e-02, 2.7171e-01, 1.1003e-01, 2.2762e-02, 1.4431e-02,\n",
      "         3.7409e-03, 3.4416e-02, 2.7208e-01, 8.7500e-02],\n",
      "        [8.2081e-03, 3.1720e-01, 5.6124e-03, 2.5013e-02, 7.9358e-02, 1.2840e-02,\n",
      "         2.1787e-02, 2.9556e-01, 8.8252e-03, 2.2559e-01],\n",
      "        [3.7756e-02, 4.5060e-01, 2.3315e-02, 1.6898e-01, 5.5834e-02, 1.8445e-02,\n",
      "         1.8171e-02, 4.6092e-02, 4.0538e-02, 1.4026e-01],\n",
      "        [2.2144e-02, 3.7777e-01, 2.9477e-02, 2.0566e-01, 3.6875e-02, 1.2805e-02,\n",
      "         3.4073e-02, 2.3842e-02, 3.5463e-02, 2.2189e-01],\n",
      "        [3.4229e-02, 3.3079e-01, 2.3261e-02, 7.1953e-02, 2.8234e-02, 2.0203e-02,\n",
      "         1.9719e-02, 1.0231e-01, 4.9110e-02, 3.2019e-01],\n",
      "        [1.0013e-02, 4.3087e-02, 1.0780e-02, 1.4424e-02, 5.4071e-01, 3.5229e-03,\n",
      "         2.5666e-01, 7.3571e-03, 4.6205e-02, 6.7237e-02],\n",
      "        [3.9043e-03, 7.8238e-01, 7.1159e-03, 6.3945e-02, 2.0378e-02, 1.0636e-02,\n",
      "         1.5561e-02, 2.3245e-02, 8.5803e-03, 6.4254e-02],\n",
      "        [6.6657e-02, 2.3377e-01, 1.3196e-01, 1.8756e-01, 2.4922e-02, 3.0459e-02,\n",
      "         1.0914e-02, 4.2689e-02, 1.6759e-01, 1.0348e-01],\n",
      "        [2.6952e-01, 1.8575e-02, 2.3541e-01, 2.4580e-01, 1.1045e-02, 5.9032e-03,\n",
      "         1.0479e-02, 1.8400e-02, 9.7838e-02, 8.7022e-02],\n",
      "        [9.1248e-02, 3.6465e-01, 2.1054e-01, 5.4900e-02, 1.7121e-02, 1.9728e-02,\n",
      "         1.2833e-01, 1.7883e-02, 3.6645e-02, 5.8957e-02],\n",
      "        [1.4080e-02, 4.9435e-01, 1.7317e-02, 8.8867e-02, 4.2270e-02, 1.3396e-02,\n",
      "         3.7459e-02, 3.1113e-02, 2.8204e-02, 2.3295e-01],\n",
      "        [4.2388e-01, 2.0296e-03, 4.3221e-01, 2.8298e-02, 2.7052e-03, 4.2705e-03,\n",
      "         9.4887e-03, 4.7162e-03, 7.8294e-02, 1.4106e-02],\n",
      "        [1.1201e-02, 5.0829e-01, 1.6420e-02, 8.4939e-02, 1.0067e-01, 3.3715e-02,\n",
      "         2.5518e-02, 5.2249e-02, 4.8567e-02, 1.1842e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.9160], device='cuda:0', grad_fn=<IndexBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                 | 0/100 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m sup_trainloader, unsup_trainloader, testloader \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39msemisl\u001b[38;5;241m.\u001b[39mget_dataset(size, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, test_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m     12\u001b[0m trainloader \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39msemisl\u001b[38;5;241m.\u001b[39mTrainDataLoaderSemi(sup_trainloader, unsup_trainloader)\n\u001b[0;32m---> 14\u001b[0m results[size]\u001b[38;5;241m.\u001b[39mappend(\u001b[43mhp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msemisl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_semisl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhypernet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mmasks_no\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mchanging_beta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mlog_to_comet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msemisl_whole_dataset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/hypernet-cnn/hypernet/tabular_hypernet/semisl.py:218\u001b[0m, in \u001b[0;36mtrain_semisl\u001b[0;34m(hypernet, optimizer, criterion, loaders, data_size, epochs, masks_no, changing_beta, log_to_comet, experiment, tag, device, project_name, test_every)\u001b[0m\n\u001b[1;32m    213\u001b[0m unsup_outputs2 \u001b[38;5;241m=\u001b[39m hypernet(unsup_inputs, masks2)\n\u001b[1;32m    216\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 218\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43msup_outputs1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msup_outputs2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msup_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43munsup_outputs1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munsup_outputs2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    220\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [63]\u001b[0m, in \u001b[0;36mTabSSLCrossEntropyLoss.forward\u001b[0;34m(self, sup_input, unsup_input)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28mprint\u001b[39m(unsup_outputs2_target, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28mprint\u001b[39m(unsup_outputs2_target[mask2], flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 37\u001b[0m         unsup_outputs2_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43munsup_outputs2_target\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_supervised_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf2_f1(unsup_outputs2[mask1], unsup_outputs1_target)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "for beta in [0.]:\n",
    "    for f in [torch.argmax]:\n",
    "        criterion = hp.semisl.TabSSLCrossEntropyLoss(beta=beta, unsup_target_wrapper=f)\n",
    "\n",
    "        hypernet = hp.Hypernetwork(mask_size=mask_size, node_hidden_size=100, test_nodes=masks_no).cuda()\n",
    "\n",
    "        hypernet = hypernet.train()\n",
    "        optimizer = torch.optim.Adam(hypernet.parameters(), lr=3e-4)\n",
    "\n",
    "        # dataset & loaders\n",
    "        sup_trainloader, unsup_trainloader, testloader = hp.semisl.get_dataset(size, batch_size=32, test_batch_size=64)\n",
    "        trainloader = hp.semisl.TrainDataLoaderSemi(sup_trainloader, unsup_trainloader)\n",
    "\n",
    "        results[size].append(hp.semisl.train_semisl(hypernet,\n",
    "                                          optimizer,\n",
    "                                          criterion,\n",
    "                                          (trainloader, testloader), \n",
    "                                          size,\n",
    "                                          epochs,\n",
    "                                          masks_no,\n",
    "                                          changing_beta=None,\n",
    "                                          log_to_comet=False,\n",
    "                                          tag='semisl_whole_dataset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaff6cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb058da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfde2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1005bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db453527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/z1157095/hypernet-cnn/hypernet\n"
     ]
    }
   ],
   "source": [
    "%cd hypernet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ef57058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3439415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment, Optimizer\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f81b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "411db77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabular_hypernet as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfbc97da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tabular_hypernet.training_utils.get_dataset(size=60000, masked=False, mask_no=200, mask_size=700, shared_mask=False, batch_size=32, test_batch_size=32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp.training_utils.get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35fd81c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UXrV5UxyhTK3cyQNG6BDuc4bE'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['COMET_KEY'] = 'UXrV5UxyhTK3cyQNG6BDuc4bE'\n",
    "os.environ.get(\"COMET_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884b2bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9fd4cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# TabSSLCrossEntropyLoss if confidence is high for both masks, add selfsl loss\n",
    "\n",
    "# Verify if masks always divided into pairs the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc4dc449",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabSSLCrossEntropyLoss(torch.nn.Module):\n",
    "    def __init__(self, beta=0.1, unsup_target_wrapper=torch.nn.functional.softmax, threshold=None):\n",
    "        super(TabSSLCrossEntropyLoss, self).__init__()\n",
    "        \n",
    "        self.y_f1 = torch.nn.CrossEntropyLoss()\n",
    "        self.y_f2 = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.f1_f2 = torch.nn.CrossEntropyLoss()\n",
    "        self.f2_f1 = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.beta = beta\n",
    "        self.unsup_target_wrapper = unsup_target_wrapper\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def is_observ_above_threshold(self, data):\n",
    "        mask = torch.any(data >= self.threshold, dim=1)\n",
    "        \n",
    "        return mask\n",
    "        \n",
    "    \n",
    "    def forward(self, sup_input, unsup_input):\n",
    "        sup_outputs1, sup_outputs2, sup_labels = sup_input\n",
    "        unsup_outputs1, unsup_outputs2 = unsup_input\n",
    "        \n",
    "        self.supervised_loss = self.y_f1(sup_outputs1, sup_labels) + self.y_f2(sup_outputs2, sup_labels)\n",
    "        \n",
    "        self.self_supervised_loss = 0\n",
    "        if self.beta:\n",
    "\n",
    "            if self.threshold:\n",
    "                unsup_outputs1_target = torch.nn.functional.softmax(unsup_outputs1, dim=1)\n",
    "                mask1 = self.is_observ_above_threshold(unsup_outputs1_target)\n",
    "\n",
    "                if len(unsup_outputs1_target[mask1]):\n",
    "                    unsup_outputs1_target = torch.argmax(unsup_outputs1_target[mask1], dim=1)\n",
    "                    self.self_supervised_loss += self.f2_f1(unsup_outputs2[mask1], unsup_outputs1_target)\n",
    "\n",
    "                unsup_outputs2_target = torch.nn.functional.softmax(unsup_outputs2, dim=1)\n",
    "                mask2 = self.is_observ_above_threshold(unsup_outputs2_target)\n",
    "\n",
    "                if len(unsup_outputs2_target[mask2]):\n",
    "                    unsup_outputs2_target = torch.argmax(unsup_outputs2_target[mask2], dim=1)\n",
    "                    self.self_supervised_loss += self.f1_f2(unsup_outputs1[mask2], unsup_outputs2_target)\n",
    "\n",
    "            else:\n",
    "                self.self_supervised_loss = self.f1_f2(unsup_outputs1, self.unsup_target_wrapper(unsup_outputs2, dim=1)) \\\n",
    "                                    + self.f2_f1(unsup_outputs2, self.unsup_target_wrapper(unsup_outputs1, dim=1))      \n",
    "        \n",
    "        return self.supervised_loss + self.beta * self.self_supervised_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6c13ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688384bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982c0ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823cc754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec000d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8c2df55",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd37710",
   "metadata": {},
   "source": [
    "### Setup for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afbc4d3",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59940b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fa50ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77a2b909",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5162270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = hp.semisl.get_train_test_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ce322f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "masks_no = 100\n",
    "\n",
    "\n",
    "results = defaultdict(list)\n",
    "size = (100, 59900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68697821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "527b9d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#68.6   1.78"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465b132b",
   "metadata": {},
   "source": [
    "### Test shuffle masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e6a4131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!! log to comet is True \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.ml https://www.comet.com/abulenok/semi-hypernetwork/88791f41efb34bc5939a2953992361c2\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████| 100/100 [38:09<00:00, 22.89s/it, loss=1.73, test_acc=75.8]\n",
      "COMET ERROR: Error sending a notification, make sure you have opted-in for notifications\n",
      "COMET INFO: Uploading metrics, params, and assets to Comet before program termination (may take several seconds)\n",
      "COMET INFO: The Python SDK has 3600 seconds to finish before aborting...\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n",
      "!! log to comet is True \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.ml https://www.comet.com/abulenok/semi-hypernetwork/499b5e9e77244d139b3598eba68a4a3c\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████| 100/100 [38:52<00:00, 23.32s/it, loss=1.74, test_acc=74.3]\n",
      "COMET ERROR: Error sending a notification, make sure you have opted-in for notifications\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n"
     ]
    }
   ],
   "source": [
    "for beta in [.1, 1.]:\n",
    "    for loss_threshold in [0.8]:\n",
    "        for lr in [3e-5]:\n",
    "\n",
    "\n",
    "            criterion = TabSSLCrossEntropyLoss(beta=beta, threshold=loss_threshold)\n",
    "\n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "\n",
    "            # dataset\n",
    "\n",
    "\n",
    "            hypernet = hp.Hypernetwork(\n",
    "                architecture=torch.nn.Sequential(\n",
    "                    torch.nn.Linear(784, 64), \n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(64, 256),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(256, 128),\n",
    "                ),\n",
    "                target_architecture=[(mask_size, 100), (100, 10)],\n",
    "                test_nodes=masks_no,\n",
    "            ).cuda()\n",
    "            \n",
    "\n",
    "            hypernet = hypernet.train()\n",
    "\n",
    "\n",
    "\n",
    "            optimizer = torch.optim.Adam(hypernet.parameters(), lr=lr)\n",
    "\n",
    "            # loaders\n",
    "            sup_trainloader, unsup_trainloader, testloader = hp.semisl.get_dataloaders(dataset=dataset, size=size, batch_size=32, test_batch_size=64)\n",
    "            trainloader = hp.semisl.TrainDataLoaderSemi(sup_trainloader, unsup_trainloader)\n",
    "\n",
    "            results[size].append(hp.semisl.train_semisl(hypernet,\n",
    "                                              optimizer,\n",
    "                                              criterion,\n",
    "                                              (trainloader, testloader), \n",
    "                                              size,\n",
    "                                              epochs,\n",
    "                                              masks_no,\n",
    "                                              changing_beta=None,\n",
    "                                              log_to_comet=True,\n",
    "                                              tags=['mask pairs shuffle'],\n",
    "                                              description=\"\"\"\n",
    "                                              compare masks shuffled and not shuffled after list is over\n",
    "                                              \"\"\",\n",
    "                                            log_params={'seed': seed, 'temp scheduler': 'none', 'shuffled masks': 'true'}\n",
    "                                            ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db34ab7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n",
      "!! log to comet is True \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.com/abulenok/semi-hypernetwork/4c6c9323a3884a7abd9bd4f1c312470a\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████| 100/100 [39:16<00:00, 23.57s/it, loss=1.73, test_acc=74.6]\n",
      "COMET ERROR: Error sending a notification, make sure you have opted-in for notifications\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n",
      "!! log to comet is True \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.ml https://www.comet.com/abulenok/semi-hypernetwork/3dd65adced804bd1a4e47939117550b3\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████| 100/100 [38:57<00:00, 23.38s/it, loss=1.76, test_acc=72.1]\n",
      "COMET ERROR: Error sending a notification, make sure you have opted-in for notifications\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n"
     ]
    }
   ],
   "source": [
    "for beta in [.1, 1.]:\n",
    "    for loss_threshold in [0.8]:\n",
    "        for lr in [3e-5]:\n",
    "\n",
    "\n",
    "            criterion = TabSSLCrossEntropyLoss(beta=beta, threshold=loss_threshold)\n",
    "\n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "\n",
    "            # dataset\n",
    "\n",
    "\n",
    "            hypernet = hp.Hypernetwork(\n",
    "                architecture=torch.nn.Sequential(\n",
    "                    torch.nn.Linear(784, 64), \n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(64, 256),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(256, 128),\n",
    "                ),\n",
    "                target_architecture=[(mask_size, 100), (100, 10)],\n",
    "                test_nodes=masks_no,\n",
    "            ).cuda()\n",
    "            \n",
    "\n",
    "            hypernet = hypernet.train()\n",
    "\n",
    "\n",
    "\n",
    "            optimizer = torch.optim.Adam(hypernet.parameters(), lr=lr)\n",
    "\n",
    "            # loaders\n",
    "            sup_trainloader, unsup_trainloader, testloader = hp.semisl.get_dataloaders(dataset=dataset, size=size, batch_size=32, test_batch_size=64)\n",
    "            trainloader = hp.semisl.TrainDataLoaderSemi(sup_trainloader, unsup_trainloader)\n",
    "\n",
    "            results[size].append(hp.semisl.train_semisl(hypernet,\n",
    "                                              optimizer,\n",
    "                                              criterion,\n",
    "                                              (trainloader, testloader), \n",
    "                                              size,\n",
    "                                              epochs,\n",
    "                                              masks_no,\n",
    "                                              changing_beta=None,\n",
    "                                              log_to_comet=True,\n",
    "                                              tags=['mask pairs shuffle'],\n",
    "                                              description=\"\"\"\n",
    "                                              compare masks shuffled and not shuffled after list is over\n",
    "                                              \"\"\",\n",
    "                                              shuffled_masks=False,\n",
    "                                            log_params={'seed': seed, 'temp scheduler': 'none', 'shuffled masks': 'false'}\n",
    "                                            ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40950f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "905bc017",
   "metadata": {},
   "source": [
    "##### Semi sl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5e5ebf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n",
      "!! log to comet is True \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.com/abulenok/semi-hypernetwork/21f4c841798c4579bdd2023b1a3f7a64\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [45:25<00:00, 27.26s/it, loss=1.77, test_acc=73.4]\n",
      "COMET ERROR: Error sending a notification, make sure you have opted-in for notifications\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n",
      "!! log to comet is True \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.com/abulenok/semi-hypernetwork/f102b0a009c44004ba15be053a60ac4d\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [45:41<00:00, 27.42s/it, loss=1.76, test_acc=73.6]\n",
      "COMET ERROR: Error sending a notification, make sure you have opted-in for notifications\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n",
      "!! log to comet is True \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.com/abulenok/semi-hypernetwork/89624e76248c4ee69b0b81b06b00208f\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [59:16<00:00, 35.57s/it, loss=1.78, test_acc=71.8]\n",
      "COMET ERROR: Error sending a notification, make sure you have opted-in for notifications\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n",
      "!! log to comet is True \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.com/abulenok/semi-hypernetwork/de229193a11e4980b321627806bd7add\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [44:54<00:00, 26.95s/it, loss=1.77, test_acc=72.4]\n",
      "COMET ERROR: Error sending a notification, make sure you have opted-in for notifications\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n"
     ]
    }
   ],
   "source": [
    "for beta in [1., 2.]:\n",
    "    for loss_threshold in [0.2, 0.4]:\n",
    "        for lr in [3e-5]:\n",
    "\n",
    "\n",
    "            criterion = TabSSLCrossEntropyLoss(beta=beta, threshold=loss_threshold)\n",
    "\n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "\n",
    "            # dataset\n",
    "\n",
    "\n",
    "            hypernet = hp.Hypernetwork(\n",
    "                architecture=torch.nn.Sequential(\n",
    "                    torch.nn.Linear(784, 64), \n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(64, 256),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(256, 128),\n",
    "                ),\n",
    "                target_architecture=[(mask_size, 100), (100, 10)],\n",
    "                test_nodes=masks_no,\n",
    "            ).cuda()\n",
    "            \n",
    "\n",
    "            hypernet = hypernet.train()\n",
    "\n",
    "\n",
    "\n",
    "            optimizer = torch.optim.Adam(hypernet.parameters(), lr=lr)\n",
    "\n",
    "            # loaders\n",
    "            sup_trainloader, unsup_trainloader, testloader = hp.semisl.get_dataloaders(dataset=dataset, size=size, batch_size=32, test_batch_size=64)\n",
    "            trainloader = hp.semisl.TrainDataLoaderSemi(sup_trainloader, unsup_trainloader)\n",
    "\n",
    "            results[size].append(hp.semisl.train_semisl(hypernet,\n",
    "                                              optimizer,\n",
    "                                              criterion,\n",
    "                                              (trainloader, testloader), \n",
    "                                              size,\n",
    "                                              epochs,\n",
    "                                              masks_no,\n",
    "                                              changing_beta=None,\n",
    "                                              log_to_comet=True,\n",
    "                                              tags=['fix different mask pairs during training bigger nodeHiddenSize 100'],\n",
    "                                              description=\"\"\"\n",
    "                                              before masks in training loop were selected sequentially without permuting\n",
    "                                              now they are gonna be permuted when we will finish iterating over masks\n",
    "                                              \"\"\",\n",
    "                                            log_params={'seed': seed, 'temp scheduler': 'none'}\n",
    "                                            ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a02b426",
   "metadata": {},
   "source": [
    "### Crazy hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "922b7d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n",
      "!! log to comet is True \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.com/abulenok/semi-hypernetwork/792f6915d7f540e2b0ae60dcb91d39d3\n",
      "\n",
      " 53%|█████████████████████████████████▉                              | 53/100 [25:40<22:45, 29.06s/it, loss=2.38, test_acc=9.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3397, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_3832898/3161500947.py\", line 38, in <cell line: 1>\n",
      "    results[size].append(hp.semisl.train_semisl(hypernet,\n",
      "  File \"/home/z1157095/hypernet-cnn/hypernet/tabular_hypernet/semisl.py\", line 247, in train_semisl\n",
      "  File \"/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/comet_ml/monkey_patching.py\", line 312, in wrapper\n",
      "    return_value = original(*args, **kwargs)\n",
      "  File \"/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/torch/_tensor.py\", line 363, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/torch/autograd/__init__.py\", line 173, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 1992, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/z1157095/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "for beta in [100.]:\n",
    "    for loss_threshold in [0.9]:\n",
    "        for lr in [3e-5]:\n",
    "\n",
    "\n",
    "            criterion = TabSSLCrossEntropyLoss(beta=beta, threshold=loss_threshold)\n",
    "\n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "\n",
    "            # dataset\n",
    "\n",
    "\n",
    "            hypernet = hp.Hypernetwork(\n",
    "                architecture=torch.nn.Sequential(\n",
    "                    torch.nn.Linear(784, 64), \n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(64, 256),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(256, 128),\n",
    "                ),\n",
    "                target_architecture=[(mask_size, 100), (100, 10)],\n",
    "                test_nodes=masks_no,\n",
    "            ).cuda()\n",
    "            \n",
    "\n",
    "            hypernet = hypernet.train()\n",
    "\n",
    "\n",
    "\n",
    "            optimizer = torch.optim.Adam(hypernet.parameters(), lr=lr)\n",
    "\n",
    "            # loaders\n",
    "            sup_trainloader, unsup_trainloader, testloader = hp.semisl.get_dataloaders(dataset=dataset, size=size, batch_size=32, test_batch_size=64)\n",
    "            trainloader = hp.semisl.TrainDataLoaderSemi(sup_trainloader, unsup_trainloader)\n",
    "\n",
    "            results[size].append(hp.semisl.train_semisl(hypernet,\n",
    "                                              optimizer,\n",
    "                                              criterion,\n",
    "                                              (trainloader, testloader), \n",
    "                                              size,\n",
    "                                              epochs,\n",
    "                                              masks_no,\n",
    "                                              changing_beta=None,\n",
    "                                              log_to_comet=True,\n",
    "                                              tags=['fix different mask pairs during training bigger nodeHiddenSize 100'],\n",
    "                                              description=\"\"\"\n",
    "                                              before masks in training loop were selected sequentially without permuting\n",
    "                                              now they are gonna be permuted when we will finish iterating over masks\n",
    "                                              \"\"\",\n",
    "                                            log_params={'seed': seed, 'temp scheduler': 'none'}\n",
    "                                            ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6832f7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad2ddcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a40764e2",
   "metadata": {},
   "source": [
    "##### Variance-based feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0aaff6cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n",
      "Hypernetwork(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (output_layer): Linear(in_features=128, out_features=320, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "<__main__.VarianceWithThresholdMasksSelector object at 0x7f514937b220>\n",
      "lol tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor(1000., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█▏               | 7/100 [02:37<34:56, 22.55s/it, loss=1.91, test_acc=67.1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m sup_trainloader, unsup_trainloader, testloader \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39msemisl\u001b[38;5;241m.\u001b[39mget_dataloaders(dataset\u001b[38;5;241m=\u001b[39mdataset, size\u001b[38;5;241m=\u001b[39msize, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, test_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m     37\u001b[0m trainloader \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39msemisl\u001b[38;5;241m.\u001b[39mTrainDataLoaderSemi(sup_trainloader, unsup_trainloader)\n\u001b[0;32m---> 39\u001b[0m results[size]\u001b[38;5;241m.\u001b[39mappend(\u001b[43mhp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msemisl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_semisl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhypernet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mmasks_no\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mchanging_beta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mlog_to_comet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmask variance selection with threshold\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;43m                                  masks are selected based on feature variance (above threshold) \u001b[39;49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;43m                                  \u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mlog_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mselector_threshold\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold_var\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                \u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/hypernet-cnn/hypernet/tabular_hypernet/semisl.py:222\u001b[0m, in \u001b[0;36mtrain_semisl\u001b[0;34m(hypernet, optimizer, criterion, loaders, data_size, epochs, masks_no, changing_beta, log_to_comet, experiment, tags, device, project_name, test_every, description, log_params)\u001b[0m\n\u001b[1;32m    219\u001b[0m mask_idx \u001b[38;5;241m=\u001b[39m (mask_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlen\u001b[39m(hypernet\u001b[38;5;241m.\u001b[39mtest_mask)\n\u001b[1;32m    221\u001b[0m \u001b[38;5;66;03m# supervised\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m sup_outputs2 \u001b[38;5;241m=\u001b[39m \u001b[43mhypernet\u001b[49m\u001b[43m(\u001b[49m\u001b[43msup_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;66;03m# unsupervised\u001b[39;00m\n\u001b[1;32m    225\u001b[0m unsup_outputs2 \u001b[38;5;241m=\u001b[39m hypernet(unsup_inputs, masks2)\n",
      "File \u001b[0;32m~/anaconda3/envs/hyper-mnist/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/hypernet-cnn/hypernet/tabular_hypernet/hypernetwork.py:121\u001b[0m, in \u001b[0;36mHypernetwork.forward\u001b[0;34m(self, data, mask)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrained \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m TrainingModes\u001b[38;5;241m.\u001b[39mSLOW_STEP \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m TrainingModes\u001b[38;5;241m.\u001b[39mCARTHESIAN:\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slow_step_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_mask(\u001b[38;5;28mlen\u001b[39m(data))\n",
      "File \u001b[0;32m~/hypernet-cnn/hypernet/tabular_hypernet/hypernetwork.py:80\u001b[0m, in \u001b[0;36mHypernetwork._slow_step_training\u001b[0;34m(self, data, mask)\u001b[0m\n\u001b[1;32m     78\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcraft_network(mask[:\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     79\u001b[0m mask \u001b[38;5;241m=\u001b[39m mask[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mbool)\n\u001b[0;32m---> 80\u001b[0m nn \u001b[38;5;241m=\u001b[39m \u001b[43mInsertableNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_architecture\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m masked_data \u001b[38;5;241m=\u001b[39m data[:, mask]\n\u001b[1;32m     86\u001b[0m res \u001b[38;5;241m=\u001b[39m nn(masked_data)\n",
      "File \u001b[0;32m~/hypernet-cnn/hypernet/tabular_hypernet/modules.py:64\u001b[0m, in \u001b[0;36mInsertableNet.__init__\u001b[0;34m(self, weights, shape)\u001b[0m\n\u001b[1;32m     60\u001b[0m _b_size \u001b[38;5;241m=\u001b[39m layer[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     62\u001b[0m _l \u001b[38;5;241m=\u001b[39m (weights[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset\u001b[38;5;241m+\u001b[39m_w_size]\u001b[38;5;241m.\u001b[39mreshape((layer[\u001b[38;5;241m1\u001b[39m], layer[\u001b[38;5;241m0\u001b[39m])),\n\u001b[1;32m     63\u001b[0m       weights[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset\u001b[38;5;241m+\u001b[39m_w_size:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset\u001b[38;5;241m+\u001b[39m_w_size\u001b[38;5;241m+\u001b[39m_b_size])\n\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m _w_size\u001b[38;5;241m+\u001b[39m_b_size\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mappend(_l)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for beta in [0.]:\n",
    "    for threshold_var in [0.2, 0.4, 0.7, 1]:\n",
    "        for lr in [3e-5]:\n",
    "            mask_selector = VarianceWithThresholdMasksSelector(dataset, mask_size=mask_size, threshold=threshold_var)\n",
    "            \n",
    "            criterion = TabSSLCrossEntropyLoss(beta=beta, threshold=None)\n",
    "            \n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "            \n",
    "            # dataset\n",
    "            \n",
    "            \n",
    "            hypernet = hp.Hypernetwork(\n",
    "                architecture=torch.nn.Sequential(\n",
    "                    torch.nn.Linear(784, 64), \n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(64, 256),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(256, 128),\n",
    "                ),\n",
    "                target_architecture=[(mask_size, 10), (10, 10)],\n",
    "                test_nodes=masks_no,\n",
    "            ).cuda()\n",
    "            hypernet._create_mask = None\n",
    "            hypernet.test_mask = mask_selector(hypernet, hypernet.test_nodes)\n",
    "\n",
    "            hypernet = hypernet.train()\n",
    "            \n",
    "            \n",
    "            \n",
    "            optimizer = torch.optim.Adam(hypernet.parameters(), lr=lr)\n",
    "\n",
    "            # loaders\n",
    "            sup_trainloader, unsup_trainloader, testloader = hp.semisl.get_dataloaders(dataset=dataset, size=size, batch_size=32, test_batch_size=64)\n",
    "            trainloader = hp.semisl.TrainDataLoaderSemi(sup_trainloader, unsup_trainloader)\n",
    "\n",
    "            results[size].append(hp.semisl.train_semisl(hypernet,\n",
    "                                              optimizer,\n",
    "                                              criterion,\n",
    "                                              (trainloader, testloader), \n",
    "                                              size,\n",
    "                                              epochs,\n",
    "                                              masks_no,\n",
    "                                              changing_beta=None,\n",
    "                                              log_to_comet=False,\n",
    "                                              tags=['mask variance selection with threshold'],\n",
    "                                              description=\"\"\"\n",
    "                                              masks are selected based on feature variance (above threshold) \n",
    "                                              \"\"\",\n",
    "                                            log_params={'seed': seed, 'selector_threshold': threshold_var}\n",
    "                                            ))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8df24f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypernet_with_selector = hypernet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c7c7c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b6bad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = hypernet.test_mask[0]\n",
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24708a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81037b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29ef9778",
   "metadata": {},
   "source": [
    "#### No variance-based feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfd1d236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.ml https://www.comet.com/abulenok/semi-hypernetwork/a5a1e7d1c6a444a8a6f3a7875b202f7e\n",
      "\n",
      "100%|████████████████| 100/100 [31:51<00:00, 19.11s/it, loss=1.8, test_acc=67.1]\n",
      "COMET ERROR: Error sending a notification, make sure you have opted-in for notifications\n",
      "COMET INFO: Uploading metrics, params, and assets to Comet before program termination (may take several seconds)\n",
      "COMET INFO: The Python SDK has 3600 seconds to finish before aborting...\n"
     ]
    }
   ],
   "source": [
    "for beta in [0.]:\n",
    "\n",
    "    for lr in [3e-5]:\n",
    "\n",
    "\n",
    "        criterion = TabSSLCrossEntropyLoss(beta=beta, threshold=None)\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        # dataset\n",
    "\n",
    "\n",
    "        hypernet = hp.Hypernetwork(\n",
    "            architecture=torch.nn.Sequential(\n",
    "                torch.nn.Linear(784, 64), \n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(64, 256),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(256, 128),\n",
    "            ),\n",
    "            target_architecture=[(mask_size, 10), (10, 10)],\n",
    "            test_nodes=masks_no,\n",
    "        ).cuda()\n",
    "        \n",
    "        hypernet = hypernet.train()\n",
    "\n",
    "\n",
    "\n",
    "        optimizer = torch.optim.Adam(hypernet.parameters(), lr=lr)\n",
    "\n",
    "        # loaders\n",
    "        sup_trainloader, unsup_trainloader, testloader = hp.semisl.get_dataloaders(dataset=dataset, size=size, batch_size=32, test_batch_size=64)\n",
    "        trainloader = hp.semisl.TrainDataLoaderSemi(sup_trainloader, unsup_trainloader)\n",
    "\n",
    "        results[size].append(hp.semisl.train_semisl(hypernet,\n",
    "                                          optimizer,\n",
    "                                          criterion,\n",
    "                                          (trainloader, testloader), \n",
    "                                          size,\n",
    "                                          epochs,\n",
    "                                          masks_no,\n",
    "                                          changing_beta=None,\n",
    "                                          log_to_comet=True,\n",
    "                                          tags=['mask variance selection softmax temp increment'],\n",
    "                                          description=\"\"\"\n",
    "                                          masks are selected based on feature variance with softmax and temp\n",
    "                                          \"\"\",\n",
    "                                        log_params={'seed': seed, 'temp scheduler': 'none: baseline'}\n",
    "                                        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39753de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d6cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = hypernet.test_mask[0]\n",
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ffca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1==m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32223427",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fcb953",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92783e7e-6365-4c18-a113-0ab96e908c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093e1cfc-0554-4973-bc83-734bf882b7ea",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84aefe8b-dd1a-48c7-91a4-dc53355c8745",
   "metadata": {},
   "outputs": [],
   "source": [
    "mods = [transforms.ToTensor(), \n",
    "        transforms.Normalize((0.1307,), (0.3081,)),    #mean and std of MNIST\n",
    "        transforms.Lambda(lambda x: torch.flatten(x))]\n",
    "mods = transforms.Compose(mods)\n",
    "\n",
    "trainset = datasets.MNIST(root='./data/train', train=True, download=True, transform=mods)\n",
    "testset = datasets.MNIST(root='./data/test', train=False, download=True, transform=mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfe29125-e9dd-453f-95c3-c24e7f9d97b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f662bab8-15f8-4ea7-bc93-5ba1708f7ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(trainset[0][0].reshape((28, 28)));\n",
    "plt.title(trainset[0][1]);\n",
    "plt.xticks([])\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67f07f8-aba0-4186-9a10-2c2f78964afd",
   "metadata": {},
   "source": [
    "## Prepare a single network module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3683f15-19a0-4a50-acc5-4defea5000e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNetwork(torch.nn.Module):\n",
    "    def __init__(self, inp_size, layers=[100]):\n",
    "        super().__init__()\n",
    "        self.layers = []\n",
    "        \n",
    "        self.inp = torch.nn.Linear(inp_size, layers[0])\n",
    "        self.output = torch.nn.Linear(layers[0], 10)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.inp(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.output(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1c7a4aa-32eb-49bc-b13d-a54c81390a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net, optimizer, epochs, verbose=False):\n",
    "    for epoch in range(epochs): \n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            correct += (outputs.argmax(1)==labels).float().sum()\n",
    "            total += outputs.shape[0]\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 0:    # print every 2000 mini-batches\n",
    "                if verbose:\n",
    "                    print('[%d, %5d] loss: %.3f acc: %.3f%%' %\n",
    "                          (epoch + 1, i, running_loss / 100, correct/total*100))\n",
    "                running_loss = 0.0\n",
    "                correct = 0\n",
    "                total=0\n",
    "\n",
    "        correct = 0\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        print(f\"Test acc: {correct/len(testset)*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75022978-980e-4acb-9b40-3963cd0de80b",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4f0ef37-5964-405a-ae93-16fe050fca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleNetwork(784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a74c7b50-57bb-4aff-b2b1-9e27081c6518",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31c8b792-931c-4097-870f-ae89bb637a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 95.78999999999999\n",
      "Test acc: 96.67999999999999\n",
      "Test acc: 97.02\n",
      "Test acc: 97.21\n",
      "Test acc: 97.02\n",
      "Test acc: 97.91\n",
      "Test acc: 98.07000000000001\n",
      "Test acc: 98.06\n",
      "Test acc: 98.16\n",
      "Test acc: 98.09\n",
      "CPU times: user 7min 4s, sys: 5.99 s, total: 7min 10s\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=3e-3)\n",
    "train_net(net, optimizer, 5)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=3e-4)\n",
    "train_net(net, optimizer, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41bc784-1d6c-48d7-b017-54ca8356e9a1",
   "metadata": {},
   "source": [
    "## Create simple network with insertable weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b19746d7-e05e-422c-a1a6-677d2d8a152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_parameters = []\n",
    "for layer in net.parameters():\n",
    "    flat_parameters.extend(torch.flatten(layer).detach().numpy())\n",
    "    \n",
    "flat_parameters = torch.from_numpy(np.array(flat_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ae174f8f-e5e2-4756-be75-50fa2e0dc2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsertableNet(SimpleNetwork):\n",
    "    def __init__(self, weights, inp_size, layers=[100]):\n",
    "        super().__init__(inp_size, layers)\n",
    "        with torch.no_grad():\n",
    "            input_w_size = inp_size*layers[0]\n",
    "            input_b_size = layers[0]\n",
    "            \n",
    "            hidden_w_size = layers[0]*10\n",
    "            hidden_b_size = 10\n",
    "            \n",
    "            inp_weights = weights[:input_w_size].reshape((layers[0], inp_size))\n",
    "            inp_bias = weights[input_w_size:input_w_size+input_b_size]\n",
    "            \n",
    "            output_weights = weights[input_w_size+input_b_size:input_w_size+input_b_size+hidden_w_size].reshape((10, layers[0]))\n",
    "            output_bias = weights[input_w_size+input_b_size+hidden_w_size:input_w_size+input_b_size+hidden_w_size+hidden_b_size]\n",
    "            \n",
    "            self.inp.weight.copy_(inp_weights)\n",
    "            self.inp.bias.copy_(inp_bias)        \n",
    "            self.output.weight.copy_(output_weights)\n",
    "            self.output.bias.copy_(output_bias)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ed18b7d6-f71f-4542-b244-f985aa030ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_net = InsertableNet(flat_parameters, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "82225727-12c7-4da9-86b8-5d208f4f993b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 98.09\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = insert_net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "print(f\"Test acc: {correct/len(testset)*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee06654-710e-4c65-8bf3-9910061f9707",
   "metadata": {},
   "source": [
    "### Create hypernet structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb71ab6-e54b-42ad-a4aa-814e9e8a9854",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hypernetwork(torch.nn.Module):\n",
    "    def __init__(self, inp_size=784, mask_size=20):\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_processing",
   "language": "python",
   "name": "image_processing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
